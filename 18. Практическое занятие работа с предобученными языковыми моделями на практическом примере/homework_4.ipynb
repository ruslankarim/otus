{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b63e16a-82fb-462c-a159-73901eb2ca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 4090 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84a66db-9ae7-409e-82c8-3a7af93fe0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество предложений: 7,869\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>error_type</th>\n",
       "      <th>detailed_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Вдруг решетка беззвучно поехала в сторону, и н...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Этим летом не никуда ездили.</td>\n",
       "      <td>0</td>\n",
       "      <td>Syntax</td>\n",
       "      <td>Rusgram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Только Иван выразил какую бы то ни было готовн...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Теперь ты видишь собственными глазами, как тут...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>На поверку вся теория оказалась полной чепухой.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>7864</td>\n",
       "      <td>Установки не было введено в действие.</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Paducheva2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7865</th>\n",
       "      <td>7865</td>\n",
       "      <td>Конечно, против такой системы ценностей решите...</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7866</th>\n",
       "      <td>7866</td>\n",
       "      <td>Симптомов болезни не исчезло.</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7867</th>\n",
       "      <td>7867</td>\n",
       "      <td>Послезавтра температура у больного снижается д...</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Rusgram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>7868</td>\n",
       "      <td>Говоря, например, о картине Александра Иванова...</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7869 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           sentence  acceptable  \\\n",
       "0        0  Вдруг решетка беззвучно поехала в сторону, и н...           1   \n",
       "1        1                       Этим летом не никуда ездили.           0   \n",
       "2        2  Только Иван выразил какую бы то ни было готовн...           1   \n",
       "3        3  Теперь ты видишь собственными глазами, как тут...           1   \n",
       "4        4    На поверку вся теория оказалась полной чепухой.           1   \n",
       "...    ...                                                ...         ...   \n",
       "7864  7864              Установки не было введено в действие.           0   \n",
       "7865  7865  Конечно, против такой системы ценностей решите...           0   \n",
       "7866  7866                      Симптомов болезни не исчезло.           0   \n",
       "7867  7867  Послезавтра температура у больного снижается д...           0   \n",
       "7868  7868  Говоря, например, о картине Александра Иванова...           0   \n",
       "\n",
       "     error_type detailed_source  \n",
       "0             0   Paducheva2004  \n",
       "1        Syntax         Rusgram  \n",
       "2             0   Paducheva2013  \n",
       "3             0   Paducheva2010  \n",
       "4             0   Paducheva2010  \n",
       "...         ...             ...  \n",
       "7864  Semantics   Paducheva2004  \n",
       "7865  Semantics   Paducheva2013  \n",
       "7866  Semantics   Paducheva2013  \n",
       "7867  Semantics         Rusgram  \n",
       "7868  Semantics   Paducheva2013  \n",
       "\n",
       "[7869 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./in_domain_train.csv\", delimiter=',')\n",
    "\n",
    "print('Количество предложений: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "df.sample(10)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08799cc4-1036-4fa2-ae08-9817fecf4bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>acceptable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5888</th>\n",
       "      <td>Если такой материал уже имеется, то сможете ли...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7734</th>\n",
       "      <td>Она воздержалась от всяких комментариев.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4591</th>\n",
       "      <td>Те, кто читал критическую статью Н. А.Добролюб...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>У воды есть кислород.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925</th>\n",
       "      <td>Арбитражный суд согласился под этим выводом.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  acceptable\n",
       "5888  Если такой материал уже имеется, то сможете ли...           0\n",
       "7734           Она воздержалась от всяких комментариев.           0\n",
       "4591  Те, кто читал критическую статью Н. А.Добролюб...           0\n",
       "1997                              У воды есть кислород.           0\n",
       "5925       Арбитражный суд согласился под этим выводом.           0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.acceptable == 0].sample(5)[['sentence', 'acceptable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a87420a-2940-407e-ad67-5f820a253184",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df.sentence.values\n",
    "labels = df.acceptable.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3db1274c-2ee4-4168-9610-f3e1c4a170b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('ai-forever/ruBert-large', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b76bda0b-7634-435b-a61c-9d53a4e3ca93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  Вдруг решетка беззвучно поехала в сторону, и на балконе возникла таинственная фигура, прячущаяся от лунного света, и погрозила Ивану пальцем.\n",
      "Tokenized:  ['вдруг', 'решетка', 'беззвучно', 'поехала', 'в', 'сторону', ',', 'и', 'на', 'балконе', 'возникла', 'таинственная', 'фигура', ',', 'прячу', '##щаяся', 'от', 'лунного', 'света', ',', 'и', 'погрозил', '##а', 'ива', '##ну', 'пальцем', '.']\n",
      "Token IDs:  [3014, 83321, 41548, 32350, 113, 2931, 121, 107, 660, 50354, 13779, 99183, 15226, 121, 94376, 19913, 700, 55918, 6412, 121, 107, 95640, 377, 104691, 717, 11420, 126]\n"
     ]
    }
   ],
   "source": [
    "print(' Original: ', sentences[0])\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2889a1c2-eac8-45ad-87db-f317e4496ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  45\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "for sent in sentences:\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc8ee385-e360-42f8-bee0-453b23d8daaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\Руслан\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Вдруг решетка беззвучно поехала в сторону, и на балконе возникла таинственная фигура, прячущаяся от лунного света, и погрозила Ивану пальцем.\n",
      "Token IDs: tensor([   101,   3014,  83321,  41548,  32350,    113,   2931,    121,    107,\n",
      "           660,  50354,  13779,  99183,  15226,    121,  94376,  19913,    700,\n",
      "         55918,   6412,    121,    107,  95640,    377, 104691,    717,  11420,\n",
      "           126,    102,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Руслан\\AppData\\Local\\Temp\\ipykernel_23376\\2249477459.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True, \n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b428fa39-11f9-4590-bf11-3002647c7fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,082 training samples\n",
      "  787 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14c07431-1011-4787-ab84-51925b8586ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4655e687-1d20-4b8f-8c9f-6b3b9db6f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruBert-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"ai-forever/ruBert-large\",\n",
    "    num_labels = 2,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54d5e0fd-3dcd-41dc-8077-327d190f2661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 393 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (120138, 1024)\n",
      "bert.embeddings.position_embeddings.weight               (512, 1024)\n",
      "bert.embeddings.token_type_embeddings.weight               (2, 1024)\n",
      "bert.embeddings.LayerNorm.weight                             (1024,)\n",
      "bert.embeddings.LayerNorm.bias                               (1024,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight        (1024, 1024)\n",
      "bert.encoder.layer.0.attention.self.query.bias               (1024,)\n",
      "bert.encoder.layer.0.attention.self.key.weight          (1024, 1024)\n",
      "bert.encoder.layer.0.attention.self.key.bias                 (1024,)\n",
      "bert.encoder.layer.0.attention.self.value.weight        (1024, 1024)\n",
      "bert.encoder.layer.0.attention.self.value.bias               (1024,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight      (1024, 1024)\n",
      "bert.encoder.layer.0.attention.output.dense.bias             (1024,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight       (1024,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias         (1024,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight          (4096, 1024)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (4096,)\n",
      "bert.encoder.layer.0.output.dense.weight                (1024, 4096)\n",
      "bert.encoder.layer.0.output.dense.bias                       (1024,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                 (1024,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                   (1024,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                (1024, 1024)\n",
      "bert.pooler.dense.bias                                       (1024,)\n",
      "classifier.weight                                          (2, 1024)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21ed19ac-cb7b-4a1d-bc8b-6f681c71a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                  eps = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fc21dac-f304-4a1c-84d1-f9bcb2532f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb0b251c-23f6-4ea5-8e00-e7243f66e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6f3b9bb-30d3-4eaa-990a-eee4881d2331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "def5da1a-73c0-40e5-ab08-23f23214776d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Руслан\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of    222.    Elapsed: 0:00:19.\n",
      "  Batch    80  of    222.    Elapsed: 0:00:34.\n",
      "  Batch   120  of    222.    Elapsed: 0:00:49.\n",
      "  Batch   160  of    222.    Elapsed: 0:01:04.\n",
      "  Batch   200  of    222.    Elapsed: 0:01:19.\n",
      "\n",
      "  Average training loss: 0.51\n",
      "  Training epcoh took: 0:01:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80\n",
      "  Validation Loss: 0.48\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    222.    Elapsed: 0:00:15.\n",
      "  Batch    80  of    222.    Elapsed: 0:00:30.\n",
      "  Batch   120  of    222.    Elapsed: 0:00:45.\n",
      "  Batch   160  of    222.    Elapsed: 0:01:00.\n",
      "  Batch   200  of    222.    Elapsed: 0:01:15.\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:01:24\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.78\n",
      "  Validation Loss: 0.55\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    222.    Elapsed: 0:00:15.\n",
      "  Batch    80  of    222.    Elapsed: 0:00:31.\n",
      "  Batch   120  of    222.    Elapsed: 0:00:46.\n",
      "  Batch   160  of    222.    Elapsed: 0:01:01.\n",
      "  Batch   200  of    222.    Elapsed: 0:01:16.\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:01:24\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80\n",
      "  Validation Loss: 0.74\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    222.    Elapsed: 0:00:15.\n",
      "  Batch    80  of    222.    Elapsed: 0:00:30.\n",
      "  Batch   120  of    222.    Elapsed: 0:00:45.\n",
      "  Batch   160  of    222.    Elapsed: 0:01:00.\n",
      "  Batch   200  of    222.    Elapsed: 0:01:15.\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:01:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.81\n",
      "  Validation Loss: 0.95\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:05:47 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss,\n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to\n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because\n",
    "        # accumulating the gradients is \"convenient while training RNNs\".\n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here:\n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        res = model(b_input_ids,\n",
    "                             token_type_ids=None,\n",
    "                             attention_mask=b_input_mask,\n",
    "                             labels=b_labels)\n",
    "        loss = res['loss']\n",
    "        logits = res['logits']\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value\n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which\n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here:\n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            res = model(b_input_ids,\n",
    "                                   token_type_ids=None,\n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = res['loss']\n",
    "        logits = res['logits']\n",
    "\n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6356a76e-b311-4b31-ba6d-586058c953a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.510490</td>\n",
       "      <td>0.475384</td>\n",
       "      <td>0.795724</td>\n",
       "      <td>0:01:27</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276571</td>\n",
       "      <td>0.554419</td>\n",
       "      <td>0.781974</td>\n",
       "      <td>0:01:24</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.124545</td>\n",
       "      <td>0.738616</td>\n",
       "      <td>0.802829</td>\n",
       "      <td>0:01:24</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056731</td>\n",
       "      <td>0.949572</td>\n",
       "      <td>0.813684</td>\n",
       "      <td>0:01:23</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1           0.510490     0.475384       0.795724       0:01:27         0:00:02\n",
       "2           0.276571     0.554419       0.781974       0:01:24         0:00:02\n",
       "3           0.124545     0.738616       0.802829       0:01:24         0:00:02\n",
       "4           0.056731     0.949572       0.813684       0:01:23         0:00:02"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11898eb0-a8d9-4946-8de3-1aa6c35bc866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "952876c5-65fd-4a59-9659-712aef884683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>error_type</th>\n",
       "      <th>detailed_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Иван вчера не позвонил.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>У многих туристов, кто посещают Кемер весной, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Syntax</td>\n",
       "      <td>USE8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Лесные запахи набегали волнами; в них смешалос...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>USE5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Вчера президент имел неофициальную беседу с ан...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Seliverstova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Коллега так и не признал вину за катастрофу пе...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Testelets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence  acceptable  \\\n",
       "0   0                            Иван вчера не позвонил.           1   \n",
       "1   1  У многих туристов, кто посещают Кемер весной, ...           0   \n",
       "2   2  Лесные запахи набегали волнами; в них смешалос...           1   \n",
       "3   3  Вчера президент имел неофициальную беседу с ан...           1   \n",
       "4   4  Коллега так и не признал вину за катастрофу пе...           1   \n",
       "\n",
       "  error_type detailed_source  \n",
       "0          0   Paducheva2013  \n",
       "1     Syntax            USE8  \n",
       "2          0            USE5  \n",
       "3          0    Seliverstova  \n",
       "4          0       Testelets  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"./in_domain_dev.csv\", delimiter=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d34df77-ceef-4a1e-9eb1-8de99b176eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 983\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Руслан\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Create sentence and label lists\n",
    "sentences = df.sentence.values\n",
    "labels = df.acceptable.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6144b620-8007-4b15-a875-1d5a4f4da860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 983 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict\n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  # Telling the model not to compute or store gradients, saving memory and\n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None,\n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "423661c8-f5ad-4bd1-a06b-620a79f3d60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 733 of 983 (74.57%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.acceptable.sum(), len(df.acceptable), (df.acceptable.sum() / len(df.acceptable) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df2fb303-0499-49a5-80d3-c4df06e5a317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "\n",
    "  # The predictions for this batch are a 2-column ndarray (one column for \"0\"\n",
    "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "  # in to a list of 0s and 1s.\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "\n",
    "  # Calculate and store the coef for this batch.\n",
    "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
    "  matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3b803bb-f0e3-44fc-a648-94785c90254a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MCC: 0.383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "# Combine the results across all batches.\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('Total MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed918a-76dd-41b7-896d-54c5aa3dd8bb",
   "metadata": {},
   "source": [
    "## RuGPT3 few-/zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e79d64a-1ad1-4409-9887-cf60b4226f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d14d927f-1828-48f4-ade5-c4f0531596a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1536)\n",
       "    (wpe): Embedding(2048, 1536)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2223af4f-4817-4c62-9985-b63e984503e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calc_loss(phrase: str,\n",
    "                        tokenizer,\n",
    "                        model):\n",
    "\n",
    "    phrase = tokenizer.encode(phrase)\n",
    "    # Если длина фразы 1 токен, то дальше ошибка вылезет :(\n",
    "    if len(phrase) == 1:\n",
    "         phrase.append(tokenizer.eos_token_id)\n",
    "    phrase = torch.tensor(phrase, dtype=torch.long, device=device)\n",
    "    phrase = phrase.unsqueeze(0)  # .repeat(num_samples, 1)\n",
    "    with torch.no_grad():\n",
    "        loss = model(phrase, labels=phrase)\n",
    "\n",
    "    loss[0].item()\n",
    "\n",
    "\n",
    "    return loss[0].item()\n",
    "\n",
    "def get_loss_num(text):\n",
    "    loss = calc_loss(phrase=text, model=model, tokenizer=tokenizer)\n",
    "    return loss\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub(r'\\((\\d+)\\)', '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0d7fa-81bc-4d50-acf8-e0eaa293dc9e",
   "metadata": {},
   "source": [
    "### Zero-shot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7ba3e902-f6c3-41a8-b60d-a81c80511121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Не думаю, что мосты уже сняли.'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8cd2072-bd9b-483b-9069-41a9b2871ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "470b2aac-70f8-4ba1-bac4-69652d1f7c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая затравка: Верно?, Не верно? - 698/1000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "promts_zero = [\n",
    "    (f'Эта фраза грамматически корректна?', f'Эта фраза грамматически не верна?'),\n",
    "    (f'Грамматически верное предложение?', f'Грамматически не верное предложение?'),\n",
    "    (f'Грамматически верное предложение', f'Грамматически не верное предложение'),\n",
    "    (f'Верно?', f'Не верно?')\n",
    "]\n",
    "rate_promt = {}\n",
    "sample_size = 1000\n",
    "for p in promts_zero:\n",
    "    correct = p[0]\n",
    "    in_correct = p[1]\n",
    "    rate_promt[f'{correct}, {in_correct}'] = 0\n",
    "    for i in random.sample(range(len(sentences)), sample_size):\n",
    "        estimate = get_loss_num(f'{correct} {sentences[i]}') < get_loss_num(f'{in_correct} {sentences[i]}')\n",
    "        if estimate == labels[i]:\n",
    "            rate_promt[f'{correct}, {in_correct}'] =  rate_promt[f'{correct}, {in_correct}'] + 1\n",
    "sorted_prompts = list(sorted(rate_promt.items(), key=lambda item: item[1], reverse=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c28288f-16b4-44ff-9b63-ecf94209f829",
   "metadata": {},
   "source": [
    "#### Рейтинг затравок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02f6d897-b2da-4063-8b56-7f5df2dc1a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Верно?, Не верно?\", 698/1000\n",
      "\"Грамматически верное предложение?, Грамматически не верное предложение?\", 492/1000\n",
      "\"Грамматически верное предложение, Грамматически не верное предложение\", 359/1000\n",
      "\"Эта фраза грамматически корректна?, Эта фраза грамматически не верна?\", 273/1000\n"
     ]
    }
   ],
   "source": [
    "for prompt in sorted_prompts:\n",
    "    print(f'\"{prompt[0]}\", {prompt[1]}/{sample_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd7c3c-a9a5-47ff-ba91-48e2a7652b9d",
   "metadata": {},
   "source": [
    "### Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "260fb15a-a046-4d35-ad14-efedd197cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Готовим примеры\n",
    "import random\n",
    "def get_few_shots_examples(num_examples):\n",
    "    few_shots = []\n",
    "    examples = ''\n",
    "    yOrN = {\n",
    "        0: 'Нет',\n",
    "        1: 'Да'\n",
    "    }\n",
    "    for i in range (num_examples):\n",
    "        k = random.randint(0, 1)\n",
    "        sentence = df.loc[df.acceptable == k].sample(1)[['sentence']].sentence.values[0]\n",
    "        few_shots.append(f'Предложение далее корректное? {sentence}  Ответ: {yOrN.get(labels[k])}.')\n",
    "    return '\\n'.join(few_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c54237a-0430-4dc4-8689-9d3eb9e824ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_promt = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e17c6df6-6da5-4008-a2fc-26a6b31b489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_few_shot(sample_size, num_examples):\n",
    "    examples = get_few_shots_examples(num_examples)\n",
    "    rate_promt[num_examples] = 0\n",
    "    for i in random.sample(range(len(sentences)), sample_size):\n",
    "        estimate = get_loss_num(f'{examples} Предложение далее корректное?  {sentences[i]} Ответ: да.') < get_loss_num(f'{examples} Предложение далее корректное?  {sentences[i]} Ответ: нет.')       \n",
    "        if estimate == labels[i]:\n",
    "            rate_promt[num_examples] =  rate_promt[num_examples] + 1\n",
    "    return rate_promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5734ac83-8b06-49fa-afd8-35bd49fbfe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество затравок: 4, число верных ответов: 13/30\n"
     ]
    }
   ],
   "source": [
    "sample_size = 30\n",
    "num_examples = 4\n",
    "estimate_few_shot(sample_size, num_examples)\n",
    "print(f'Количество затравок: {num_examples}, число верных ответов: {rate_promt.get(num_examples)}/{sample_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0be88a1-1cfc-40a4-b73e-e6591028c9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество затравок: 3, число верных ответов: 11/30\n"
     ]
    }
   ],
   "source": [
    "sample_size = 30\n",
    "num_examples = 3\n",
    "estimate_few_shot(sample_size, num_examples)\n",
    "print(f'Количество затравок: {num_examples}, число верных ответов: {rate_promt.get(num_examples)}/{sample_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05acfcd0-462e-48f5-8aaf-acd2288ab15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество затравок: 2, число верных ответов: 20/30\n"
     ]
    }
   ],
   "source": [
    "sample_size = 30\n",
    "num_examples = 2\n",
    "estimate_few_shot(sample_size, num_examples)\n",
    "print(f'Количество затравок: {num_examples}, число верных ответов: {rate_promt.get(num_examples)}/{sample_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d0b2db3-7464-4d98-bee2-c1684e316588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество затравок: 1, число верных ответов: 19/30\n"
     ]
    }
   ],
   "source": [
    "sample_size = 30\n",
    "num_examples = 1\n",
    "estimate_few_shot(sample_size, num_examples)\n",
    "print(f'Количество затравок: {num_examples}, число верных ответов: {rate_promt.get(num_examples)}/{sample_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43925dfd-9f3c-4cc2-b013-cafa7c574e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество затравок: 0, число верных ответов: 14/30\n"
     ]
    }
   ],
   "source": [
    "sample_size = 30\n",
    "num_examples = 0\n",
    "estimate_few_shot(sample_size, num_examples)\n",
    "print(f'Количество затравок: {num_examples}, число верных ответов: {rate_promt.get(num_examples)}/{sample_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd7b5b-2956-4ac6-b9bc-4f9deb99e1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "475ca6b5-82a7-4751-bc79-a23a56eb231a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to load vocabulary from file. Please check that the provided vocabulary is accessible and not corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2336\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2335\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2336\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:151\u001b[0m, in \u001b[0;36mT5Tokenizer.__init__\u001b[1;34m(self, vocab_file, eos_token, unk_token, pad_token, extra_ids, additional_special_tokens, sp_model_kwargs, legacy, add_prefix_space, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msp_model \u001b[38;5;241m=\u001b[39m spm\u001b[38;5;241m.\u001b[39mSentencePieceProcessor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msp_model_kwargs)\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msp_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m additional_special_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentencepiece\\__init__.py:961\u001b[0m, in \u001b[0;36mSentencePieceProcessor.Load\u001b[1;34m(self, model_file, model_proto)\u001b[0m\n\u001b[0;32m    960\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLoadFromSerializedProto(model_proto)\n\u001b[1;32m--> 961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentencepiece\\__init__.py:316\u001b[0m, in \u001b[0;36mSentencePieceProcessor.LoadFromFile\u001b[1;34m(self, arg)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadFromFile\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sentencepiece\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentencePieceProcessor_LoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: Not found: \"C:\\Users\\Руслан\\.cache\\huggingface\\hub\\models--sberbank-ai--ruT5-large\\snapshots\\b3321d48aefe45ffd70ea2f649570b91441e0055\\spiece.model\": No such file or directory Error #2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m T5ForConditionalGeneration,T5Tokenizer\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m=\u001b[39mT5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msberbank-ai/ruT5-large\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m tokenizer\u001b[38;5;241m=\u001b[39m\u001b[43mT5Tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msberbank-ai/ruT5-large\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2110\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2107\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2108\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2113\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2119\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2122\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2338\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2336\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39minit_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs)\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m-> 2338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m   2339\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load vocabulary from file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2340\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check that the provided vocabulary is accessible and not corrupted.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2341\u001b[0m     )\n\u001b[0;32m   2343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m added_tokens_decoder \u001b[38;5;241m!=\u001b[39m {} \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlist\u001b[39m(added_tokens_decoder\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mvocab_size:\n\u001b[0;32m   2344\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_advice(\n\u001b[0;32m   2345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2346\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m fine-tuned or trained.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2347\u001b[0m     )\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to load vocabulary from file. Please check that the provided vocabulary is accessible and not corrupted."
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "model=T5ForConditionalGeneration.from_pretrained('sberbank-ai/ruT5-large')\n",
    "tokenizer=T5Tokenizer.from_pretrained('sberbank-ai/ruT5-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fcb002-4075-4551-af4d-c8ee7a1b768c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
