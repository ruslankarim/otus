{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "253e20f90ea74401879a0c750bdd5b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7b1fe3952144e90af557eb2c7437b31",
              "IPY_MODEL_4e04872604ec4de6b8610950eba0bd83",
              "IPY_MODEL_3db21e9635fb4168b9edd90b75b36277"
            ],
            "layout": "IPY_MODEL_7f013dbaea9844b5a3dc8c0fad4c262a"
          }
        },
        "b7b1fe3952144e90af557eb2c7437b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b8c96d49d0f42588f29c56c006cd1c8",
            "placeholder": "​",
            "style": "IPY_MODEL_9cf57bbf49304c5da3af58933e5b6839",
            "value": "Downloading: 100%"
          }
        },
        "4e04872604ec4de6b8610950eba0bd83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_637cb5022bec4f17be99533118693ed2",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b2d1b666d0d4ff2b815f5ce901f1c00",
            "value": 1042301
          }
        },
        "3db21e9635fb4168b9edd90b75b36277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9f9aac8eb7e4635bafce655eed53039",
            "placeholder": "​",
            "style": "IPY_MODEL_5f0a7c73dbff49fca7b9afe837f9f961",
            "value": " 0.99M/0.99M [00:01&lt;00:00, 1.05MB/s]"
          }
        },
        "7f013dbaea9844b5a3dc8c0fad4c262a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b8c96d49d0f42588f29c56c006cd1c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cf57bbf49304c5da3af58933e5b6839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "637cb5022bec4f17be99533118693ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b2d1b666d0d4ff2b815f5ce901f1c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9f9aac8eb7e4635bafce655eed53039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f0a7c73dbff49fca7b9afe837f9f961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "739e04bcadde4474b861a87da17d95cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a348b2f6bb74159a9e4a9911c6ee0a3",
              "IPY_MODEL_368de67c4ba240e7af45243877d132bf",
              "IPY_MODEL_df96cb774f3145af90b4bc6703bc2cbf"
            ],
            "layout": "IPY_MODEL_8b7fba7f423f4cc8bdeb35cd920febab"
          }
        },
        "3a348b2f6bb74159a9e4a9911c6ee0a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d855f08bcc1b42bf85d69fc2b82231d1",
            "placeholder": "​",
            "style": "IPY_MODEL_a65006733b7f44a38b4e0f1995dcd899",
            "value": "Downloading: 100%"
          }
        },
        "368de67c4ba240e7af45243877d132bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b114b05aa6624d34ad9cf9f88dbc15df",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a1052c3514d4ddbbc4d8a4595098257",
            "value": 456318
          }
        },
        "df96cb774f3145af90b4bc6703bc2cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e1d9db39e894f48bcb7e561285f4a7a",
            "placeholder": "​",
            "style": "IPY_MODEL_a883448e4c704ff5896c5848817e897c",
            "value": " 446k/446k [00:01&lt;00:00, 505kB/s]"
          }
        },
        "8b7fba7f423f4cc8bdeb35cd920febab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d855f08bcc1b42bf85d69fc2b82231d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a65006733b7f44a38b4e0f1995dcd899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b114b05aa6624d34ad9cf9f88dbc15df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a1052c3514d4ddbbc4d8a4595098257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e1d9db39e894f48bcb7e561285f4a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a883448e4c704ff5896c5848817e897c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b62bf739218a4d1fbad666d074fe1426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b021e19c31c941b7b390645523da1e93",
              "IPY_MODEL_877d655533d54f87848c4323435212bf",
              "IPY_MODEL_918479d919d64bcfbae55b54d56752a1"
            ],
            "layout": "IPY_MODEL_cdc5e57fc83842ebbbc906d4788845b7"
          }
        },
        "b021e19c31c941b7b390645523da1e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_765abc24fd024492b95b64c83b9abfa8",
            "placeholder": "​",
            "style": "IPY_MODEL_58648eb5e25a4aa58d2dbb71ae19a9ae",
            "value": "Downloading: 100%"
          }
        },
        "877d655533d54f87848c4323435212bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11f0bb8ceb3f439b99b908aee803c062",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95c5946ee1fb490da454e0ce948e3525",
            "value": 665
          }
        },
        "918479d919d64bcfbae55b54d56752a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_404b7446b2754865bcb3083df292deed",
            "placeholder": "​",
            "style": "IPY_MODEL_1fe3d55e19664eb2b1ec0b9d5a5c7ba8",
            "value": " 665/665 [00:00&lt;00:00, 8.97kB/s]"
          }
        },
        "cdc5e57fc83842ebbbc906d4788845b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "765abc24fd024492b95b64c83b9abfa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58648eb5e25a4aa58d2dbb71ae19a9ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11f0bb8ceb3f439b99b908aee803c062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95c5946ee1fb490da454e0ce948e3525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "404b7446b2754865bcb3083df292deed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fe3d55e19664eb2b1ec0b9d5a5c7ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c33b43902e6942bba3ecc4034ede35e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27e6bc67f99e4b328b073d1e2b3f8d5f",
              "IPY_MODEL_719cf3951b884bc18395c87f88e17513",
              "IPY_MODEL_1db4b47cd4da4b62b5556438728eecf4"
            ],
            "layout": "IPY_MODEL_6e55841b56d943d0b3aaaf3c7ad57e4c"
          }
        },
        "27e6bc67f99e4b328b073d1e2b3f8d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41a1878709e24d73a0a0ece77f14a87d",
            "placeholder": "​",
            "style": "IPY_MODEL_e904453bbe6447aabc6378ef45602f2e",
            "value": "Downloading: 100%"
          }
        },
        "719cf3951b884bc18395c87f88e17513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_172171d1498740829aae8b2b7de47a44",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72a14e5afa2443acb6a3adadb21e0005",
            "value": 548118077
          }
        },
        "1db4b47cd4da4b62b5556438728eecf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9198953cc6dc4f9e9c2b0afb93a6942a",
            "placeholder": "​",
            "style": "IPY_MODEL_eb2a1e0626ea4758bd976bf02c4ba03b",
            "value": " 523M/523M [00:12&lt;00:00, 56.4MB/s]"
          }
        },
        "6e55841b56d943d0b3aaaf3c7ad57e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41a1878709e24d73a0a0ece77f14a87d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e904453bbe6447aabc6378ef45602f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "172171d1498740829aae8b2b7de47a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72a14e5afa2443acb6a3adadb21e0005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9198953cc6dc4f9e9c2b0afb93a6942a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb2a1e0626ea4758bd976bf02c4ba03b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp3XPuaTu9jl"
      },
      "source": [
        "# Стратегии генерации\n",
        "\n",
        "\n",
        "(based on https://github.com/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxLvv6UaPa33"
      },
      "source": [
        "### **Введение**\n",
        "\n",
        "В последние годы растет интерес к языковой генерации благодаря появлению больших языковых моделей на основе трансформеров, обучаемых на миллионах веб-страниц, таких как знаменитая OpenAI [GPT2 model](https://openai.com/blog/better-language-models/). Результаты впечатляют, e.g. [GPT2 on unicorns](https://openai.com/blog/better-language-models/#samples), [XLNet](https://medium.com/@amanrusia/xlnet-speaks-comparison-to-gpt-2-ea1a4e9ba39e), [Controlled language with CTRL](https://blog.einstein.ai/introducing-a-conditional-transformer-language-model-for-controllable-generation/). Помимо улучшенной архитектуры transformer и большого объема обучающих данных, важную роль также сыграли улучшенные методы декодирования.\n",
        "\n",
        "В этом блокноте дается краткий обзор различных стратегий декодирования и, что более важно, показано, как * вы * можете реализовать их с минимальными усилиями, используя популярную библиотеку `transformers`!\n",
        "\n",
        "Все следующие функциональные возможности могут быть использованы для **авторегрессионной** генерации языка ([тут](http://jalammar.github.io/illustrated-gpt2/) как это делается). Если коротко, *авторегрессионная* генерация языка основана на предположении, что распределение вероятностей последовательности слов может быть разложено на произведение следующих условных вероятностей:\n",
        "$$ P(w_{1:T} | W_0 ) = \\prod_{t=1}^T P(w_{t} | w_{1: t-1}, W_0) \\text{ ,with }  w_{1: 0} = \\emptyset, $$\n",
        "\n",
        "\n",
        "Авторегрессивная генерация языка теперь доступна для `GPT2`, `XLNet`, `OpenAi-GPT`, `CTRL`, `TransfoXL`, `XLM`, `Bart`, `T5`!\n",
        "\n",
        "Мы проведем экскурсию по наиболее известным в настоящее время методам декодирования, главным образом *Greedy search*, *Beam search*, *Top-K sampling*  и *Top-p sampling*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbzZ_IVTtoQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e3a39c9-62f2-49c6-97c1-90a0b5126806"
      },
      "source": [
        "#!pip install -q git+https://github.com/huggingface/transformers.git  # the bleeding edge version \n",
        "#!pip install -q tensorflow==2.1\n",
        "!pip install transformers==4.18.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.18.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 33.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 56.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.18.0) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 30.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.18.0) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.18.0) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.18.0) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.18.0) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.18.0) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.18.0) (2022.6.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 13.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers==4.18.0) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.18.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.18.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.18.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.18.0) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.18.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.18.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.18.0) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=9ac6948671ff96bc858f18478331ba20bdfc1d7e3ef42150151186ce34f40203\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL5Ky2ESXOzz"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue2kOQhXTAMU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144,
          "referenced_widgets": [
            "253e20f90ea74401879a0c750bdd5b04",
            "b7b1fe3952144e90af557eb2c7437b31",
            "4e04872604ec4de6b8610950eba0bd83",
            "3db21e9635fb4168b9edd90b75b36277",
            "7f013dbaea9844b5a3dc8c0fad4c262a",
            "3b8c96d49d0f42588f29c56c006cd1c8",
            "9cf57bbf49304c5da3af58933e5b6839",
            "637cb5022bec4f17be99533118693ed2",
            "7b2d1b666d0d4ff2b815f5ce901f1c00",
            "e9f9aac8eb7e4635bafce655eed53039",
            "5f0a7c73dbff49fca7b9afe837f9f961",
            "739e04bcadde4474b861a87da17d95cb",
            "3a348b2f6bb74159a9e4a9911c6ee0a3",
            "368de67c4ba240e7af45243877d132bf",
            "df96cb774f3145af90b4bc6703bc2cbf",
            "8b7fba7f423f4cc8bdeb35cd920febab",
            "d855f08bcc1b42bf85d69fc2b82231d1",
            "a65006733b7f44a38b4e0f1995dcd899",
            "b114b05aa6624d34ad9cf9f88dbc15df",
            "7a1052c3514d4ddbbc4d8a4595098257",
            "6e1d9db39e894f48bcb7e561285f4a7a",
            "a883448e4c704ff5896c5848817e897c",
            "b62bf739218a4d1fbad666d074fe1426",
            "b021e19c31c941b7b390645523da1e93",
            "877d655533d54f87848c4323435212bf",
            "918479d919d64bcfbae55b54d56752a1",
            "cdc5e57fc83842ebbbc906d4788845b7",
            "765abc24fd024492b95b64c83b9abfa8",
            "58648eb5e25a4aa58d2dbb71ae19a9ae",
            "11f0bb8ceb3f439b99b908aee803c062",
            "95c5946ee1fb490da454e0ce948e3525",
            "404b7446b2754865bcb3083df292deed",
            "1fe3d55e19664eb2b1ec0b9d5a5c7ba8",
            "c33b43902e6942bba3ecc4034ede35e0",
            "27e6bc67f99e4b328b073d1e2b3f8d5f",
            "719cf3951b884bc18395c87f88e17513",
            "1db4b47cd4da4b62b5556438728eecf4",
            "6e55841b56d943d0b3aaaf3c7ad57e4c",
            "41a1878709e24d73a0a0ece77f14a87d",
            "e904453bbe6447aabc6378ef45602f2e",
            "172171d1498740829aae8b2b7de47a44",
            "72a14e5afa2443acb6a3adadb21e0005",
            "9198953cc6dc4f9e9c2b0afb93a6942a",
            "eb2a1e0626ea4758bd976bf02c4ba03b"
          ]
        },
        "outputId": "de8e15fa-3d3c-4570-b7a5-3dc3976038da"
      },
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# add the EOS token as PAD token to avoid warnings\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "253e20f90ea74401879a0c750bdd5b04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "739e04bcadde4474b861a87da17d95cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b62bf739218a4d1fbad666d074fe1426"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c33b43902e6942bba3ecc4034ede35e0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Y7cgu9ohXP"
      },
      "source": [
        "### **Greedy Search**\n",
        "\n",
        "Жадный поиск просто выбирает слово с наибольшей вероятностью в качестве следующего слова: $w_t = argmax_{w}P(w | w_{1:t-1})$ на каждом временном шаге $t$. На следующем рисунке показан Greedy Search.\n",
        "\n",
        "![Greedy Search](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/greedy_search.png)\n",
        "\n",
        "Начиная со слова $\\text{\"The\"}$, алгоритм\n",
        "жадно выбирает следующее слово с наибольшей вероятностью $\\text{\"nice\"}$ и так далее, так что конечная сгенерированная последовательность слов будет $\\text{\"The\", \"nice\", \"woman\"}$ с общей вероятностью $0.5 \\times 0.4 = 0.2$.\n",
        "\n",
        "В дальнейшем мы будем генерировать последовательности слов, используя GPT2 в контексте $(\\text{\"I\", \"enjoy\", \"walking\", \"with\", \"my\", \"cute\", \"dog\"})$. Давайте посмотрим, как можно использовать жадный поиск в \"трансформерах\" следующим образом\n",
        ":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWLd_J6lXz_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0c1d42-a40c-4d49-c885-72f3c9a5c130"
      },
      "source": [
        "# encode context the generation is conditioned on\n",
        "input_ids = tokenizer.encode('I enjoy walking with my cute dog', return_tensors='pt')\n",
        "\n",
        "# generate text until the output length (which includes the context length) reaches 50\n",
        "greedy_output = model.generate(input_ids, max_length=50)\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
            "\n",
            "I'm not sure if I'll\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBn1ePmJvhrl"
      },
      "source": [
        "Хорошо! Мы сгенерировали наш первый короткий текст с помощью GPT2 😊. Сгенерированные слова, следующие контексту, разумны, но модель быстро начинает повторяться! Это очень распространенная проблема при генерации языка в целом и, по-видимому, еще более распространена при grid / beam search'e - проверьте [Vijayakumar et al., 2016](https://arxiv.org/abs/1610.02424) and [Shao et al., 2017](https://arxiv.org/abs/1701.03185).\n",
        "\n",
        "Однако основным недостатком жадного поиска является то, что он пропускает слова с высокой вероятностью, скрытые за словом с низкой вероятностью, как видно из нашего наброска выше:\n",
        "\n",
        "Слово $\\text{\"has\"}$ с его высокой условной вероятностью $0,9$ скрыто за словом $\\text{\"dog\"}$, которое имеет только вторую по величине условную вероятность, так что жадный поиск пропускает последовательность слов $\\text{\"The\"}, \\text{\"dog\"}, \\text{\"has\"}$.\n",
        "\n",
        "К счастью, у нас есть beam search, чтобы решить эту проблему!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8DnXZ1WiuNd"
      },
      "source": [
        "### **Beam search**\n",
        "\n",
        "Поиск по лучу (beam search) снижает риск пропуска скрытых последовательностей слов с высокой вероятностью, сохраняя наиболее вероятные \"num_beams\" гипотез на каждом временном шаге и в конечном итоге выбирая гипотезу, имеющую в целом наибольшую вероятность. Давайте проиллюстрируем это с помощью `num_beams=2`:\n",
        "\n",
        "![Beam search](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/beam_search.png)\n",
        "\n",
        "На временном шаге $1$, помимо наиболее вероятной гипотезы $\\text{\"The\", \"woman\"}$, beam search также отслеживает вторую наиболее вероятную гипотезу $\\text{\"The\", \"dog\"}$. На временном шаге $2$ поиск по лучу обнаруживает, что последовательность слов $\\text{\"The\", \"dog\", \"has\"}$ имеет вероятность $0,36$ более высокую, чем $\\text{\"The\", \"nice\", \"woman\"}$, которая имеет $0,2$. Отлично, он нашел наиболее вероятную последовательность слов в нашем примере!\n",
        "\n",
        "Поиск по лучу всегда найдет выходную последовательность с большей вероятностью, чем жадный поиск, но не гарантирует нахождения наиболее вероятного результата. \n",
        "\n",
        "Давайте посмотрим, как поиск по лучу можно использовать в \"трансформерах\". Мы устанавливаем `num_beams > 1` и `early_stopping=True`, чтобы генерация завершалась, когда все гипотезы луча достигали токена EOS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1R5kx30Ynej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed025bf-3704-44ee-f7b8-d7dbbcd5f998"
      },
      "source": [
        "# activate beam search and early_stopping\n",
        "beam_output = model.generate(\n",
        "    input_ids,  \n",
        "    max_length=50, \n",
        "    num_beams=5, \n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I'm not sure if I'll ever be able to walk with him again. I'm not sure if I'll\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ6xs-KLi9jT"
      },
      "source": [
        "Хотя результат, возможно, более плавный, выход по-прежнему включает повторения одних и тех же последовательностей слов.  \n",
        "Простое решение состоит в том, чтобы ввести штрафы за *n-граммы* (*также известные как последовательности слов из $n$ слов), как это было введено [Paulus et al. (2017)](https://arxiv.org/abs/1705.04304 ) и [Klein et al. (2017)](https://arxiv.org/abs/1701.02810 ). Наиболее распространенный штраф *n-граммов* гарантирует, что ни один *n-грамм* не появится дважды, вручную устанавливая вероятность следующих слов, которые могли бы создать уже встречавшийся *n-грамм*, равной $0$.\n",
        "\n",
        "Давайте попробуем это, установив `no_repeat_n gram_size=2`, чтобы ни один *2-gramm* не появлялся дважды:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy3iVJgfnkMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a31dec0-50e6-499d-be2e-1560ecef80af"
      },
      "source": [
        "# set no_repeat_ngram_size to 2\n",
        "beam_output = model.generate(\n",
        "    input_ids, \n",
        "    max_length=50, \n",
        "    num_beams=5, \n",
        "    no_repeat_ngram_size=2, \n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to take a break\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxsksOGDpmA0"
      },
      "source": [
        "Мило, это выглядит намного лучше! Мы можем видеть, что повторение больше не появляется. Тем не менее, *n-граммовые* штрафы следует использовать с осторожностью. В статье, сгенерированной о городе *Нью-Йорк*, не следует использовать штраф в размере *2-gramms* или название города будет встречаться только один раз во всем тексте!\n",
        "\n",
        "Еще одной важной особенностью поиска луча является то, что мы можем сравнить верхние лучи после генерации и выбрать сгенерированный луч, который лучше всего соответствует нашей цели. \n",
        "\n",
        "В `transformers` мы просто устанавливаем параметр `num_return_sequences` на количество лучей с наибольшим количеством баллов, которые должны быть возвращены. Убедитесь, однако, что `num_return_sequences <= num_beams`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ClO3VphqGp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7fe276c-5ad5-4fd4-baf0-3593645f91e5"
      },
      "source": [
        "# set return_num_sequences > 1\n",
        "beam_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length=50, \n",
        "    num_beams=5, \n",
        "    no_repeat_ngram_size=2, \n",
        "    num_return_sequences=5, \n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "# now we have 3 output sequences\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, beam_output in enumerate(beam_outputs):\n",
        "  print(\"{}: {}\\n\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to take a break\n",
            "\n",
            "1: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to get back to\n",
            "\n",
            "2: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to take a break\n",
            "\n",
            "3: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to get back to\n",
            "\n",
            "4: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to take a step\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbbIyK84wHq6"
      },
      "source": [
        "## **Sampling**\n",
        "\n",
        "В своей самой простой форме sampling означает случайный выбор следующего слова $w_t$ в соответствии с его условным распределением вероятностей:\n",
        "\n",
        "$$w_t \\sim P(w|w_{1:t-1})$$\n",
        "\n",
        "Используя приведенный выше пример, на следующем рисунке визуализируется генерация языка при выборке.\n",
        "\n",
        "![vanilla_sampling](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/sampling_search.png)\n",
        "\n",
        "Становится очевидным, что генерация языка с использованием sampling больше не является \"детерминированной\". Cлово \n",
        "$\\text{\"car\"}$ выбирается из условного распределения вероятностей $P(w |\\text{\"The\"})$, за которым следует sampling $\\text{\"drives\"}$ из $P(w |\\text{\"The\"}, \\text{\"car\"})$.\n",
        "\n",
        "В `transformers` мы устанавливаем `do_sample=True` и деактивируем sampling *Top-K* (подробнее об этом позже) через `top_k=0`. Не стесняйтесь изменять `random_seed`, чтобы поиграть с моделью."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRAz4D-Ks0_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5bc1ef-acbb-4b97-de61-3170f3125129"
      },
      "source": [
        "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
        "torch.random.manual_seed(1)\n",
        "\n",
        "# activate sampling and deactivate top_k by setting top_k sampling to 0\n",
        "sample_output = model.generate(\n",
        "    input_ids, \n",
        "    do_sample=True, \n",
        "    max_length=50, \n",
        "    top_k=0\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog up playground. It's so happy seeing humans happy, I totally get it. I love it when everyone from the park to the state dislikes carving up campsites and going and attacking people trying to get their dogs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQHuo911wfT-"
      },
      "source": [
        "Интересно! Текст кажется нормальным, но при ближайшем рассмотрении оказывается, что он не очень связный. Слова *new hand sense* и *local batte harness* очень странные и звучат не так, как будто они были написаны человеком. Это большая проблема при выборке последовательностей слов: модели часто генерируют бессвязную тарабарщину, *ср.* [Ари Хольцман и др. (2019)](https://arxiv.org/abs/1904.09751 ).\n",
        "\n",
        "Хитрость заключается в том, чтобы сделать распределение $P(w|w_{1:t-1})$ более четким (увеличивая вероятность слов с высокой вероятностью и уменьшая вероятность слов с низкой вероятностью), понизив так называемую \"температуру\" [softmax](https://en.wikipedia.org/wiki/Softmax_function#Smooth_arg_max ). \n",
        "\n",
        "$q = \\frac{exp(z_i / T)}{\\sum_j exp(z_j / T)}$\n",
        "\n",
        "Иллюстрация применения температуры к нашему примеру, приведенному выше, может выглядеть следующим образом.\n",
        "\n",
        "![top_p_sampling](https://github.com/patrickvonplaten/scientific_images/blob/master/sampling_search_with_temp.png?raw=true)\n",
        "\n",
        "Условное распределение следующего слова на шаге $t = 1$ становится намного более четким, практически не оставляя шансов для выбора слова $\\text{\"car\"}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgJredc-0j0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eacd9ba1-90a9-427d-9116-ff97d0d81f5c"
      },
      "source": [
        "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
        "torch.random.manual_seed(0)\n",
        "\n",
        "# use temperature to decrease the sensitivity to low probability candidates\n",
        "sample_output = model.generate(\n",
        "    input_ids, \n",
        "    do_sample=True, \n",
        "    max_length=50, \n",
        "    top_k=0, \n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog along the trail. He's taken my dog home for the week and that's been a fantastic experience.\"\n",
            "\n",
            "Plus, the shearer has been given a small sailboat and he can sail through the Quarry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "binNTroyzQBu"
      },
      "source": [
        "## **Top-K Sampling**\n",
        "\n",
        "[Fan et. al (2018)](https://arxiv.org/pdf/1805.04833.pdf ) ввел простую, но очень мощную схему выборки, называемую выборкой ***Top-K***. В выборке *Top-K* фильтруются *K* наиболее вероятных следующих слов, и масса вероятности перераспределяется только между этими *K* следующими словами. \n",
        "GPT2 принял эту схему выборки, что стало одной из причин его успеха. \n",
        "\n",
        "Мы расширили диапазон слов, используемых для обоих этапов выборки в приведенном выше примере, с 3 слов до 10 слов, чтобы лучше проиллюстрировать выборку *Top-K*.\n",
        "\n",
        "![top_k_sampling](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/top_k_sampling.png)\n",
        "\n",
        "Установив $K = 6$, на обоих этапах выборки мы ограничиваем наш пул выборок 6 словами. В то время как 6 наиболее вероятных слов, определенных как $V_ {\\text{top-K}}$, охватывают только *около* двух третей всей массы вероятности на первом шаге, они включают почти всю массу вероятности на втором шаге. Тем не менее, мы видим, что он успешно устраняет довольно странных кандидатов $\\text{\"not\", \"the\", \"small\", \"told\"}$ \n",
        "на втором этапе отбора проб.\n",
        "\n",
        "\n",
        "Давайте посмотрим, как *Top-K* можно использовать в библиотеке, установив `top_k=50`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBtDOdD0wx3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e812bb-9b3c-49a9-94df-7590b7572c41"
      },
      "source": [
        "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
        "torch.random.manual_seed(0)\n",
        "\n",
        "# set top_k to 50\n",
        "sample_output = model.generate(\n",
        "    input_ids, \n",
        "    do_sample=True, \n",
        "    max_length=50, \n",
        "    top_k=50\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog, but it's pretty much just my usual dog routine.\n",
            "\n",
            "In the evening I have one of those little dog-loving cat ladies playing in the backyard.\n",
            "\n",
            "And with our kids there I often get\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y77H5m4ZmhEX"
      },
      "source": [
        "Совсем неплохо! Этот текст, пожалуй, самый \"человечный\" на сегодняшний день. \n",
        "Однако одна проблема с выборкой *Top-K* заключается в том, что она динамически не адаптирует количество слов, которые отфильтровываются из распределения вероятности следующего слова $P (w |w_ {1:t-1})$.\n",
        "Это может быть проблематично, поскольку некоторые слова могут быть выбраны из очень четкого распределения (распределение справа на графике выше), в то время как другие - из гораздо более плоского распределения (распределение слева на графике выше). \n",
        "\n",
        "На шаге $t=1$, *Top-K* исключает возможность \n",
        "примеров $\\text{\"people\", \"big\", \"house\", \"cat\"}$, которые кажутся разумными кандидатами. С другой стороны, на шаге $t= 2$ метод включает, возможно, неправильно подобранные слова $\\text{\"down\", \"a\"}$ в выборку слов. Таким образом, ограничение пула выборок фиксированным размером *K* может привести к тому, что модель будет выдавать тарабарщину для четких распределений и ограничит творческий потенциал модели для плоского распределения.\n",
        "Эта интуиция привела [Ari Holtzman et al. (2019)](https://arxiv.org/abs/1904.09751 ) для создания ***Top-p*** - или ***nucleus***-sampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki9LAaexzV3H"
      },
      "source": [
        "## **Sampling Top-p (nucleus)**\n",
        "\n",
        "Вместо выборки только из наиболее вероятных *K* слов, в выборке *Top-p* выбирается из наименьшего возможного набора слов, совокупная вероятность которых превышает вероятность *p*. Затем масса вероятности перераспределяется между этим набором слов. Таким образом, размер набора слов (количество слов в наборе) может динамически увеличиваться и уменьшаться в соответствии с распределением вероятности следующего слова. Ладно, это было очень многословно, давайте визуализируем.\n",
        "\n",
        "![top_p_sampling](https://github.com/patrickvonplaten/scientific_images/blob/master/top_p_sampling.png?raw=true)\n",
        "\n",
        "Установив $p=0.92$, выборка *Top-p* выбирает *минимальное* количество слов, которое в совокупности должно превышать $p=92\\%$ от массы вероятности, определяемой как $V_{\\text{top-p}}$. В первом примере это включало 9 наиболее вероятных слов, тогда как во втором примере нужно выбрать только 3 лучших слова, чтобы их вероятностная масса превысила 92%. На самом деле все очень просто! Можно видеть, что стратегия сохраняет широкий диапазон слов, где следующее слово, возможно, менее предсказуемо, *например* $P(w | \\text{\"The\"})$, и только несколько слов, когда следующее слово кажется более предсказуемым, *например* $P(w | \\text{\"The\", \"car\"})$.\n",
        "\n",
        "Мы активируем выборку *Top-p*, установив `0 < top_p < 1`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvwIc7YAx77F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3f9ca7-34c2-479e-bbc9-a593bb31deae"
      },
      "source": [
        "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
        "torch.random.manual_seed(3)\n",
        "\n",
        "# deactivate top_k sampling and sample only from 92% most likely words\n",
        "sample_output = model.generate(\n",
        "    input_ids, \n",
        "    do_sample=True, \n",
        "    max_length=50, \n",
        "    top_p=0.92, \n",
        "    top_k=0\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog.\n",
            "\n",
            "Meet Szybras:\n",
            "\n",
            "Szybras has been married seven years and is a chronic participant in church and outdoors activities. The family has been looking for a home and she has been\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn-8gLaR4lat"
      },
      "source": [
        "Отлично, звучит так, словно это мог бы написать человек. Ну, может быть, еще не совсем. \n",
        "\n",
        "Хотя в теории *Top-p* кажется более элегантным, чем *Top-K*, оба метода хорошо работают на практике. *Top-p* также можно использовать в сочетании с *Top-K*, что позволяет избежать слов с очень низким скором, обеспечивая при этом некоторый динамический выбор.\n",
        "\n",
        "Наконец, чтобы получить несколько независимо отобранных выходных данных, мы можем установить параметр `num_return_sequences > 1`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kY8P9VG8Gi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce6eb04-7baf-4efe-847a-1552903c082e"
      },
      "source": [
        "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
        "torch.random.manual_seed(0)\n",
        "\n",
        "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
        "sample_outputs = model.generate(\n",
        "    input_ids,\n",
        "    do_sample=True, \n",
        "    max_length=50, \n",
        "    top_k=50, \n",
        "    top_p=0.95, \n",
        "    num_return_sequences=3\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0: I enjoy walking with my cute dog, and she is the perfect animal companion to me. She helps me get on my feet as often as possible. I love sharing my love and care with all of my dogs. I have the highest respect for them\n",
            "1: I enjoy walking with my cute dog when he is around my neck,\" she said. \"I'm just doing it. It's not something that's easy for me to do when I'm the leader.\"\n",
            "\n",
            "The family is just beginning to see\n",
            "2: I enjoy walking with my cute dog, and we are both very pleased by his behavior. He seems to be extremely curious about the world around him, and just as he is searching for his place of origin he is able to spot and find it easily\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constrained generation"
      ],
      "metadata": {
        "id": "oZpN3QTweA0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для лучшей читаемости мы будем использовать end-of-line в качестве токена EOS, вместо того, чтобы просто всегда генерировать 50 токенов."
      ],
      "metadata": {
        "id": "QYsyCeBUJAVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "END_OF_LINE = tokenizer('\\n').input_ids[0]\n",
        "print(END_OF_LINE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUK1B7WsJCpM",
        "outputId": "b31c93be-f5b1-4626-bbec-f7f883539b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поиск по базовому лучу выдает очень похожие предложения; все они содержат \"not sure\" или \"don't think\"."
      ],
      "metadata": {
        "id": "yBATNPrxJwPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beam_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length=50, \n",
        "    num_beams=5, \n",
        "    no_repeat_ngram_size=2, \n",
        "    num_return_sequences=5, \n",
        "    early_stopping=True,\n",
        "    eos_token_id=END_OF_LINE,\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, beam_output in enumerate(beam_outputs):\n",
        "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgsoFsmOI9Pe",
        "outputId": "24088fbd-de4c-4aa1-9d45-727237770b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "1: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n",
            "\n",
            "2: I enjoy walking with my cute dog, but I don't think I'll ever be able to walk with her again.\n",
            "\n",
            "3: I enjoy walking with my cute dog, but I don't think I'll ever be able to walk with him again.\n",
            "\n",
            "4: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again. I don't know what to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что произойдет, если мы запретим модели использовать эти фразы?\n",
        "\n"
      ],
      "metadata": {
        "id": "xj3S7FkgI9lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beam_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length=50, \n",
        "    num_beams=5, \n",
        "    no_repeat_ngram_size=2, \n",
        "    num_return_sequences=5, \n",
        "    early_stopping=True,\n",
        "    eos_token_id=END_OF_LINE,\n",
        "    bad_words_ids=tokenizer(['sure', 'think', 'thundersnatch'], add_prefix_space=True)['input_ids'],\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, beam_output in enumerate(beam_outputs):\n",
        "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-nlHOYzJ_bP",
        "outputId": "9c59a908-2a05-4d45-af7f-52f81197e93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0: I enjoy walking with my cute dog, but I don't like to walk alone.\n",
            "\n",
            "1: I enjoy walking with my cute dog, but I don't want to have to go through the hassle of going to the vet.\n",
            "\n",
            "2: I enjoy walking with my cute dog, but I don't want to have to go through the hassle of going to the vet to get a new dog.\n",
            "\n",
            "3: I enjoy walking with my cute dog, but I don't want to have to go through the hassle of going to the vet to get a new one.\n",
            "\n",
            "4: I enjoy walking with my cute dog, but I don't want to have to go through the hassle of going to the vet to see if my dog is sick.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(['sure', ' sure', ' I am not sure'])['input_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng2xaRxaMSXS",
        "outputId": "5671fd36-92cd-4fdb-ea42-98cf611da417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[19532], [1654], [314, 716, 407, 1654]]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы видим, что смысл этих текстов сильно изменился – но каким-то непредсказуемым образом. \n",
        "\n",
        "Можем ли мы заставить модель написать текст с участием \"cat\"?"
      ],
      "metadata": {
        "id": "J16fr3qDKOz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beam_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length=50, \n",
        "    num_beams=5, \n",
        "    no_repeat_ngram_size=2, \n",
        "    num_return_sequences=5, \n",
        "    early_stopping=True,\n",
        "    eos_token_id=END_OF_LINE,\n",
        "    bad_words_ids=tokenizer(['sure', 'think'], add_prefix_space=True)['input_ids'],\n",
        "    force_words_ids=[tokenizer(['cat'], add_prefix_space=True, add_special_tokens=False).input_ids],\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, beam_output in enumerate(beam_outputs):\n",
        "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsOq5q5PKspB",
        "outputId": "0b2a8701-a534-4c78-bcd0-ca5e7897a8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0: I enjoy walking with my cute dog, but I'm not a cat person.\n",
            "\n",
            "1: I enjoy walking with my cute dog, but I'm not a cat person.\"\n",
            "\n",
            "2: I enjoy walking with my cute dog, but I'm not a cat person, so I don't know what to do with him.\"\n",
            "\n",
            "3: I enjoy walking with my cute dog, but I'm not a cat person, so I don't know what to do with him. He's my best friend.\"\n",
            "\n",
            "4: I enjoy walking with my cute dog, but I'm not a cat person, so I don't know what to do with him. He's my best friend.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Уточнение: **force_words_ids** - это список ограничений. Каждое ограничение представляет собой список выражений, таких, что по крайней мере одно выражение должно быть включено в сгенерированный текст. И каждое выражение - это просто список токенов. \n",
        "\n",
        "Смотрите обсуждение в [the HF pull request](https://github.com/huggingface/transformers/issues/14081 ), или прочтите статью \"[Guided Generation of Cause and Effect](https://www.ijcai.org/proceedings/2020/0502.pdf )\" Ли и др., где был предложен алгоритм.  \n",
        "\n",
        "Чтобы оценить силу этих ограничений, давайте заставим модель включить мышь (или даже много мышей) в текст. Мы также можем ослабить ограничение \"кошка\", разрешив вместо него использовать слова \"кошки\", \"котенок\" или \"кошачий\"."
      ],
      "metadata": {
        "id": "40lA3WrhK726"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beam_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length=50, \n",
        "    num_beams=5, \n",
        "    no_repeat_ngram_size=2, \n",
        "    num_return_sequences=5, \n",
        "    early_stopping=True,\n",
        "    eos_token_id=END_OF_LINE,\n",
        "    bad_words_ids=tokenizer(['sure', 'think'], add_prefix_space=True)['input_ids'],\n",
        "    force_words_ids = [\n",
        "        tokenizer(['cat', 'cats', 'kitten', 'feline', 'Cat', 'Cats'], add_prefix_space=True, add_special_tokens=False).input_ids,\n",
        "        tokenizer(['mouse', 'mice'], add_prefix_space=True, add_special_tokens=False).input_ids,\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, beam_output in enumerate(beam_outputs):\n",
        "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXvaYLFFLQWT",
        "outputId": "e5808853-1bdf-4af2-d089-228ca68208d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0: I enjoy walking with my cute dog. I love feline companionship and I like mice.\"\n",
            "\n",
            "1: I enjoy walking with my cute dog. I love feline companionship and I like mice.\n",
            "\n",
            "2: I enjoy walking with my cute dog. I love feline companionship and I like mice and cats.\n",
            "\n",
            "3: I enjoy walking with my cute dog. I love feline companionship and I like to mouse my way around the house.\n",
            "\n",
            "4: I enjoy walking with my cute dog. I love feline companionship and I like to mouse my way through the world.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsWd7e98Vcs3"
      },
      "source": [
        "## **Заключение**\n",
        "\n",
        "Методы декодирования *ad-hoc*, выборка *top-p* и *top-K*, по-видимому, обеспечивают более плавный текст, чем традиционный *жадный* и *лучевой* поиск при генерации открытого языка. \n",
        "Однако в последнее время появилось больше доказательств того, что очевидные недостатки *жадного* и *лучевого* поиска - в основном генерирующие повторяющиеся последовательности слов - вызваны моделью (особенно способом обучения модели), а не методом декодирования,  [Уэллек и др. (2019)](https://arxiv.org/pdf/1908.04319.pdf ). Кроме того, как показано в [Welleck et al. (2020)](https://arxiv.org/abs/2002.02492 ), похоже, что выборки *top-K* и *top-p* также страдают от генерации повторяющихся последовательностей слов.\n",
        "\n",
        "В [Welleck et al. (2019)](https://arxiv.org/pdf/1908.04319.pdf ), авторы показывают, что, согласно человеческим оценкам, поиск *beam* может генерировать более плавный текст, чем выборка *Top-p*, при адаптации цели обучения модели.\n",
        "\n",
        "Генерация открытого языка - быстро развивающаяся область исследований, и, как это часто бывает, здесь нет универсального метода, поэтому нужно посмотреть, что лучше всего работает в конкретном случае использования.\n",
        "\n",
        "Хорошо, что *вы* можете опробовать все различные методы декодирования в \"трансфомерах\" 🤗. \n",
        "\n",
        "Это было краткое введение о том, как использовать различные методы декодирования в \"трансформерах\", и о последних тенденциях в создании языков с открытым исходным кодом. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4CYi91h11yd"
      },
      "source": [
        "## **Приложение**\n",
        "\n",
        "Есть пара дополнительных параметров для метода `generate`, которые не были упомянуты выше. Мы кратко объясним их здесь!\n",
        "\n",
        "- `min_length` можно использовать, чтобы заставить модель не выдавать токен EOS (= не заканчивать предложение) до достижения `min_length`. Это довольно часто используется при суммаризации, но может быть полезно в целом, если пользователь хочет получить более длинные выходные данные.\n",
        "- `repetition_penalty` может использоваться для \"наказания\" слов, которые уже были сгенерированы или принадлежат контексту. Впервые он был представлен [Kesker et al. (2019)](https://arxiv.org/abs/1909.05858 ) и также используется в цели обучения в [Welleck et al. (2019)](https://arxiv.org/pdf/1908.04319.pdf ). Это может быть довольно эффективно для предотвращения повторений, но, по-видимому, очень чувствительно к различным моделям и вариантам использования, *например* смотрите это [обсуждение](https://github.com/huggingface/transformers/pull/2303 ) на Github.\n",
        "\n",
        "- `attention_mask` можно использовать для маскировки дополненных токенов\n",
        "- `pad_token_id`, `bos_token_id`, `eos_token_id`: Если в модели по умолчанию нет этих токенов, пользователь может вручную выбрать другие идентификаторы токенов для их представления.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bxjHF8KfqrKi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}