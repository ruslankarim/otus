{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация текста с помощью RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle,\n",
    "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
    "\n",
    "# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
    "# import sys; sys.path.append('./stepik-dl-nlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:20:34.854793Z",
     "start_time": "2019-11-05T18:20:34.372865Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "import codecs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:03.509714Z",
     "start_time": "2019-11-05T18:21:03.491489Z"
    }
   },
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "data = None\n",
    "with open('./datasets/anek.txt', encoding=\"utf8\") as input_file:\n",
    "    try:\n",
    "        data = input_file.read()[:-1].split('\\n')\n",
    "    except UnicodeDecodeError:\n",
    "        print('Error')\n",
    "    data = [line.replace('<|startoftext|>', ' ') for line in data if len(line) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124166"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:03.946758Z",
     "start_time": "2019-11-05T18:21:03.938432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' - Тетя Сара, а ваш маленький Изя ест газету...- Пускай ест, она вчерашняя...',\n",
       " ' Кажется, я недостаточно тупой, чтобы быть счастливым...',\n",
       " ' Первоначально Герасим планировал крестить Муму...',\n",
       " ' Не так страшна мама, как ее рисуют первоклассники.',\n",
       " ' Вам же неприятно, когда ваши знакомые несут бред и ахинею, так что представьте, какая сложная работа у депутатов.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение длин:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:05.420060Z",
     "start_time": "2019-11-05T18:21:05.179513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('length distribution')\n",
    "plt.hist(list(map(len, data)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:07.335188Z",
     "start_time": "2019-11-05T18:21:07.320148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tokens =  211\n"
     ]
    }
   ],
   "source": [
    "#all unique characters go here\n",
    "tokens = sorted(set(''.join(data)))\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "print ('num_tokens = ', num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ч', 'а', 'М', 'Ь', 'c', 'я', '举', '老', '☺', '。', 'P', '»', 'g', 'n', 'Ш']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(tokens, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Символы -> id\n",
    "\n",
    "Создадим словарь < символ > -> < id >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:07.674548Z",
     "start_time": "2019-11-05T18:21:07.671129Z"
    }
   },
   "outputs": [],
   "source": [
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '\"': 2,\n",
       " '#': 3,\n",
       " '$': 4,\n",
       " '%': 5,\n",
       " '&': 6,\n",
       " \"'\": 7,\n",
       " '*': 8,\n",
       " '+': 9,\n",
       " ',': 10,\n",
       " '-': 11,\n",
       " '.': 12,\n",
       " '/': 13,\n",
       " '0': 14,\n",
       " '1': 15,\n",
       " '2': 16,\n",
       " '3': 17,\n",
       " '4': 18,\n",
       " '5': 19,\n",
       " '6': 20,\n",
       " '7': 21,\n",
       " '8': 22,\n",
       " '9': 23,\n",
       " ':': 24,\n",
       " ';': 25,\n",
       " '=': 26,\n",
       " '>': 27,\n",
       " '?': 28,\n",
       " '@': 29,\n",
       " 'A': 30,\n",
       " 'B': 31,\n",
       " 'C': 32,\n",
       " 'D': 33,\n",
       " 'E': 34,\n",
       " 'F': 35,\n",
       " 'G': 36,\n",
       " 'H': 37,\n",
       " 'I': 38,\n",
       " 'J': 39,\n",
       " 'K': 40,\n",
       " 'L': 41,\n",
       " 'M': 42,\n",
       " 'N': 43,\n",
       " 'O': 44,\n",
       " 'P': 45,\n",
       " 'Q': 46,\n",
       " 'R': 47,\n",
       " 'S': 48,\n",
       " 'T': 49,\n",
       " 'U': 50,\n",
       " 'V': 51,\n",
       " 'W': 52,\n",
       " 'X': 53,\n",
       " 'Y': 54,\n",
       " 'Z': 55,\n",
       " '^': 56,\n",
       " '_': 57,\n",
       " '`': 58,\n",
       " 'a': 59,\n",
       " 'b': 60,\n",
       " 'c': 61,\n",
       " 'd': 62,\n",
       " 'e': 63,\n",
       " 'f': 64,\n",
       " 'g': 65,\n",
       " 'h': 66,\n",
       " 'i': 67,\n",
       " 'j': 68,\n",
       " 'k': 69,\n",
       " 'l': 70,\n",
       " 'm': 71,\n",
       " 'n': 72,\n",
       " 'o': 73,\n",
       " 'p': 74,\n",
       " 'q': 75,\n",
       " 'r': 76,\n",
       " 's': 77,\n",
       " 't': 78,\n",
       " 'u': 79,\n",
       " 'v': 80,\n",
       " 'w': 81,\n",
       " 'x': 82,\n",
       " 'y': 83,\n",
       " 'z': 84,\n",
       " '°': 85,\n",
       " '²': 86,\n",
       " '»': 87,\n",
       " '¿': 88,\n",
       " '×': 89,\n",
       " 'Ø': 90,\n",
       " 'ë': 91,\n",
       " 'ö': 92,\n",
       " '́': 93,\n",
       " '̆': 94,\n",
       " '̈': 95,\n",
       " 'ο': 96,\n",
       " 'π': 97,\n",
       " 'Ё': 98,\n",
       " 'А': 99,\n",
       " 'Б': 100,\n",
       " 'В': 101,\n",
       " 'Г': 102,\n",
       " 'Д': 103,\n",
       " 'Е': 104,\n",
       " 'Ж': 105,\n",
       " 'З': 106,\n",
       " 'И': 107,\n",
       " 'Й': 108,\n",
       " 'К': 109,\n",
       " 'Л': 110,\n",
       " 'М': 111,\n",
       " 'Н': 112,\n",
       " 'О': 113,\n",
       " 'П': 114,\n",
       " 'Р': 115,\n",
       " 'С': 116,\n",
       " 'Т': 117,\n",
       " 'У': 118,\n",
       " 'Ф': 119,\n",
       " 'Х': 120,\n",
       " 'Ц': 121,\n",
       " 'Ч': 122,\n",
       " 'Ш': 123,\n",
       " 'Щ': 124,\n",
       " 'Ъ': 125,\n",
       " 'Ы': 126,\n",
       " 'Ь': 127,\n",
       " 'Э': 128,\n",
       " 'Ю': 129,\n",
       " 'Я': 130,\n",
       " 'а': 131,\n",
       " 'б': 132,\n",
       " 'в': 133,\n",
       " 'г': 134,\n",
       " 'д': 135,\n",
       " 'е': 136,\n",
       " 'ж': 137,\n",
       " 'з': 138,\n",
       " 'и': 139,\n",
       " 'й': 140,\n",
       " 'к': 141,\n",
       " 'л': 142,\n",
       " 'м': 143,\n",
       " 'н': 144,\n",
       " 'о': 145,\n",
       " 'п': 146,\n",
       " 'р': 147,\n",
       " 'с': 148,\n",
       " 'т': 149,\n",
       " 'у': 150,\n",
       " 'ф': 151,\n",
       " 'х': 152,\n",
       " 'ц': 153,\n",
       " 'ч': 154,\n",
       " 'ш': 155,\n",
       " 'щ': 156,\n",
       " 'ъ': 157,\n",
       " 'ы': 158,\n",
       " 'ь': 159,\n",
       " 'э': 160,\n",
       " 'ю': 161,\n",
       " 'я': 162,\n",
       " 'ё': 163,\n",
       " '\\u200b': 164,\n",
       " '’': 165,\n",
       " '“': 166,\n",
       " '”': 167,\n",
       " '″': 168,\n",
       " '€': 169,\n",
       " '№': 170,\n",
       " '−': 171,\n",
       " '▒': 172,\n",
       " '☺': 173,\n",
       " '☻': 174,\n",
       " '。': 175,\n",
       " '为': 176,\n",
       " '举': 177,\n",
       " '事': 178,\n",
       " '人': 179,\n",
       " '代': 180,\n",
       " '任': 181,\n",
       " '会': 182,\n",
       " '副': 183,\n",
       " '名': 184,\n",
       " '命': 185,\n",
       " '已': 186,\n",
       " '并': 187,\n",
       " '应': 188,\n",
       " '成': 189,\n",
       " '手': 190,\n",
       " '接': 191,\n",
       " '数': 192,\n",
       " '新': 193,\n",
       " '最': 194,\n",
       " '果': 195,\n",
       " '然': 196,\n",
       " '理': 197,\n",
       " '由': 198,\n",
       " '的': 199,\n",
       " '直': 200,\n",
       " '经': 201,\n",
       " '结': 202,\n",
       " '给': 203,\n",
       " '老': 204,\n",
       " '虽': 205,\n",
       " '表': 206,\n",
       " '选': 207,\n",
       " '长': 208,\n",
       " '\\ufeff': 209,\n",
       " '，': 210}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:07.838814Z",
     "start_time": "2019-11-05T18:21:07.833611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "\n",
    "for i in range(num_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item(str_, ind):\n",
    "    try:\n",
    "        return str_[ind]\n",
    "    except IndexError:\n",
    "        return ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_matrix(data, token_to_id, max_len=None, dtype='int32', batch_first = True):\n",
    "    \"\"\"Casts a list of samples into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, data))\n",
    "    data_ix = np.zeros([len(data), max_len], dtype)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        for j in range(max_len):\n",
    "            line_ix = token_to_id[get_item(data[i], j)]\n",
    "            data_ix[i, j] = line_ix\n",
    "        \n",
    "    if not batch_first: # convert [batch, time] into [time, batch]\n",
    "        data_ix = np.transpose(data_ix)\n",
    "\n",
    "    return data_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = to_matrix(data[:2], token_to_id, max_len=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 150)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 117, 145, 142, 159, 141, 145,   0, 138, 131, 143, 136, 149,\n",
       "        139, 142,  10,   0, 154, 149, 145,   0, 148, 142, 145, 133, 145,\n",
       "          0,   2, 146,  29, 147, 144, 145,   2,   0, 144, 131, 132, 139,\n",
       "        147, 131, 136, 149, 148, 162,   0, 148, 131, 143, 139, 143, 139,\n",
       "          0, 153, 136, 144, 149, 147, 131, 142, 159, 144, 158, 143, 139,\n",
       "          0, 141, 142, 131, 133, 139, 155, 131, 143, 139,  12,   0, 109,\n",
       "        131, 141,   0, 133, 148, 136,   0, 146, 147, 145, 135, 150, 143,\n",
       "        131, 144, 145,  10,   0, 132, 142, 139, 144,   1,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0, 103, 147, 150, 138, 159, 162,   0, 143, 145, 139,  10,   0,\n",
       "        154, 149, 145, 132, 158,   0, 148, 145, 145, 149, 133, 136, 149,\n",
       "        148, 149, 133, 145, 133, 131, 149, 159,   0, 133, 131, 143,  10,\n",
       "          0, 162,   0, 134, 145, 149, 145, 133,   0, 148, 135, 136, 142,\n",
       "        131, 149, 159,   0, 144, 131, 135,   0, 148, 145, 132, 145, 140,\n",
       "          0, 150, 148, 139, 142, 139, 136,   0, 139,   0, 148, 149, 131,\n",
       "        149, 159,   0, 142, 150, 154, 155, 136,  12,   0, 112, 145,   0,\n",
       "        149, 145, 134, 135, 131,   0, 139,   0, 133, 158,   0, 148, 149,\n",
       "        131, 144, 159, 149, 136,   0, 144, 136, 143, 144, 145, 134, 145,\n",
       "          0, 152, 150, 137, 136,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:08.136936Z",
     "start_time": "2019-11-05T18:21:08.131609Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекуррентные нейронные сети\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:10.739438Z",
     "start_time": "2019-11-05T18:21:09.661222Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:10.751862Z",
     "start_time": "2019-11-05T18:21:10.741772Z"
    }
   },
   "outputs": [],
   "source": [
    "class CharRNNCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement the scheme above as torch module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens=len(tokens), embedding_size=16, hidden_dim=64):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        self.rnn_update = nn.Linear(embedding_size + hidden_dim, hidden_dim)\n",
    "        self.rnn_to_logits = nn.Linear(hidden_dim, num_tokens)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "        \n",
    "        :param x: batch of character ids, variable containing vector of int64\n",
    "        :param h_prev: previous rnn hidden states, variable containing matrix [batch, rnn_num_units] of float32\n",
    "        \"\"\"\n",
    "        # get vector embedding of x\n",
    "        x_emb = self.embedding(x)\n",
    "        \n",
    "        # compute next hidden state using self.rnn_update\n",
    "        x_and_h = torch.cat([x_emb, h_prev], dim=1) \n",
    "        h_next = self.rnn_update(x_and_h) \n",
    "        \n",
    "        h_next = F.tanh(h_next)\n",
    "        \n",
    "        assert h_next.size() == h_prev.size()\n",
    "        \n",
    "        #compute logits for next character probs\n",
    "        logits = self.rnn_to_logits(h_next)\n",
    "        \n",
    "        return h_next, F.log_softmax(logits, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
    "        return Variable(torch.zeros(batch_size, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(F.log_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:11.071002Z",
     "start_time": "2019-11-05T18:21:11.052377Z"
    }
   },
   "outputs": [],
   "source": [
    "char_rnn = CharRNNCell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNNCell(\n",
       "  (embedding): Embedding(211, 16)\n",
       "  (rnn_update): Linear(in_features=80, out_features=64, bias=True)\n",
       "  (rnn_to_logits): Linear(in_features=64, out_features=211, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([211, 16])\n",
      "torch.Size([64, 80])\n",
      "torch.Size([64])\n",
      "torch.Size([211, 64])\n",
      "torch.Size([211])\n"
     ]
    }
   ],
   "source": [
    "for parameter in char_rnn.parameters():\n",
    "    print(parameter.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22275"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(char_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тренировка сети, RNN loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:11.521078Z",
     "start_time": "2019-11-05T18:21:11.510175Z"
    }
   },
   "outputs": [],
   "source": [
    "def rnn_loop(rnn, batch_index):\n",
    "    \"\"\"\n",
    "    Computes log P(next_character) for all time-steps in data_ix\n",
    "    :param batch_index: an int32 matrix of shape [batch, time], output of to_matrix(data)\n",
    "    \"\"\"\n",
    "    batch_size, max_length = batch_index.size()\n",
    "    hid_state = rnn.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "    for x_t in batch_index.transpose(0,1):\n",
    "        hid_state, logp_next = rnn(x_t, hid_state)  \n",
    "        logprobs.append(logp_next)\n",
    "        \n",
    "    return torch.stack(logprobs, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тренировка сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:12.120106Z",
     "start_time": "2019-11-05T18:21:12.109585Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "char_rnn = CharRNNCell()\n",
    "\n",
    "opt = torch.optim.Adam(char_rnn.parameters())\n",
    "\n",
    "history1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124166"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3880.1875"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:23.521061Z",
     "start_time": "2019-11-05T18:21:12.302892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 32s, sys: 23.3 s, total: 9min 56s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "MAX_LENGTH = 150\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_ix = to_matrix(sample(data, 32), token_to_id, max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "    \n",
    "    logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "    \n",
    "    # compute loss\n",
    "    predictions_logp = logp_seq[:, :-1]\n",
    "    actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "    loss = -torch.mean(torch.gather(predictions_logp, dim=2, index=actual_next_tokens.unsqueeze(-1)))\n",
    "    \n",
    "    # train with backprop\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    # visualizing training process\n",
    "    history1.append(loss.data.numpy())\n",
    "    if (i + 1) % 50 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history1,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history1[:100]) > np.mean(history1[-100:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7297142"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history1[-30:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN: генерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:23.540765Z",
     "start_time": "2019-11-05T18:21:23.524503Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
    "    hid_state = char_rnn.initial_state(batch_size=1)\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        hid_state, logp_next = char_rnn(x_sequence[:, -1], hid_state)\n",
    "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0]\n",
    "        \n",
    "        # sample next token and push it back into x_sequence\n",
    "        next_ix = np.random.choice(len(tokens), p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:23.625562Z",
     "start_time": "2019-11-05T18:21:23.544968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Сенку к недал коронии бали одолев кой деста модельна в на торорень женко на зосталито стоваты ма ном батить   о труком мени прене сталь дера, серной \n",
      "\n",
      " - Правако моня ивато стичет о менния дазалит ротель в не дасто ето подилого балака в поратили в какостом оплик дарастее не Аглаю растиннають?- В срав\n",
      "\n",
      " - Помони слвирое подилото стое корутой ракостования месла равевале, что порумо правоной на ведта тат посто мудра!                                    \n",
      "\n",
      " - Не у мону стади проботу сеской ководаю быхорона чина лосе мукой у полелик соботь в гатла назя прорино мари реровак равал поря сжено потелина в прон\n",
      "\n",
      " Веднаю сторамто кара, се тобикь порого сов красте бажетровака онари емальный Воме.- Сы калино кохо гостествае да простот что снаки парете в слоблюдил\n",
      "\n",
      " - Но не убле, фоль в е мене пороволит пов веть начить блеши меля севирость сади ва и побулего не совакы Дама облини х это поничита бизаманой в нам де\n",
      "\n",
      " Падомот?                                                                                                                                             \n",
      "\n",
      " Но почазале в воринь доллидовак равутя волах на стото стонь.                                                                                         \n",
      "\n",
      " - Семетне пому пороше пожет поко торакали сена празна..- Члоболое помеди сто у нобивак, заши высту не - вачилься не морито та достал нодиная ним на с\n",
      "\n",
      " - Касто празиленвенны сезоху заскушила ласто не погоповте сточели, на поврах далько ка тобилься на дутия погово деть помое такому и некоразать сы на \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(char_rnn, temperature=0.6), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:23.702249Z",
     "start_time": "2019-11-05T18:21:23.629226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Как-то Маша вить не ки поло попрувени, с призасны оне поримне о приравеней басто \"родолички, кобить слочил мамы.                                     \n",
      "\n",
      " Как-то Маша нустой Баты колько стоси не не не выличад, оне мна негдеро новоны.                                                                       \n",
      "\n",
      " Как-то Маша оно не поскам петалатя.                                                                                                                  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    print(generate_sample(char_rnn, seed_phrase=' Как-то Маша ', temperature=0.6), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Готовые модули\n",
    "\n",
    "* `nn.RNNCell(emb_size, rnn_num_units)` - шаг RNN. Алгоритм: concat-linear-tanh\n",
    "* `nn.RNN(emb_size, rnn_num_units` - весь rnn_loop.\n",
    "\n",
    "Кроме того, в PyTorch есть `nn.LSTMCell`, `nn.LSTM`, `nn.GRUCell`, `nn.GRU`, etc. etc.\n",
    "\n",
    "Перепишем наш пример с генерацией имен с помощью средств PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что еще можно генерировать?\n",
    "\n",
    "* Повести/романы/поэзию/песни любимого автора\n",
    "* Новостные заголовки\n",
    "* Программный код\n",
    "* Молекулы в формате [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system)\n",
    "* Музыку\n",
    "* Названия мебели из ИКЕА\n",
    "* Мотивационные лозунги\n",
    "* etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Встроенные модули Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/nn.html#recurrent-layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Жена в сердцах кричит мужу:- Я по горло сыта твоей ревностью! Неужели ты думаешь, что я не знаю, что ты приставил ко мне детектива - этого высокого блондина с зелеными глазами, очень милого, хотя и слегка стеснительного... поначалу...',\n",
       " ' Женщины однозначно хитрющие. Ложась смотреть фильм вместе, возбудят мужчину, причем так ухищренно, чтобы он думал, что он инициатор, а потом после секса бурчат недовольно, мол с тобой не один фильм нормально не посмотришь.',\n",
       " ' Скользкий пол в ЗАГСе сделал ответ жениха еще ярче.',\n",
       " ' Наша Раша - это Единая Россия глазами избирателей.',\n",
       " ' Три вещи в мире невозможно оторвать: торчащую нитку от кофты, наклейку от фруктов и жопу от дивана.']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN_GRU(nn.Module):\n",
    "    def __init__(self, num_tokens=len(tokens), emb_size=16, hidden_dim=64):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_size, hidden_dim, num_layers=3, batch_first=True, dropout=0.3)\n",
    "        \n",
    "        self.hid_to_logits = nn.Linear(hidden_dim, num_tokens)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert isinstance(x, Variable) and isinstance(x.data, torch.LongTensor)\n",
    "        h_seq, _ = self.rnn(self.emb(x))\n",
    "        next_logits = self.hid_to_logits(h_seq)\n",
    "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "        return next_logp\n",
    "    \n",
    "model = CharRNN_GRU()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([211, 16])\n",
      "torch.Size([192, 16])\n",
      "torch.Size([192, 64])\n",
      "torch.Size([192])\n",
      "torch.Size([192])\n",
      "torch.Size([192, 64])\n",
      "torch.Size([192, 64])\n",
      "torch.Size([192])\n",
      "torch.Size([192])\n",
      "torch.Size([192, 64])\n",
      "torch.Size([192, 64])\n",
      "torch.Size([192])\n",
      "torch.Size([192])\n",
      "torch.Size([211, 64])\n",
      "torch.Size([211])\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(parameter.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82755"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27585.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GRU in module torch.nn.modules.rnn:\n",
      "\n",
      "class GRU(RNNBase)\n",
      " |  GRU(*args, **kwargs)\n",
      " |  \n",
      " |  Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n",
      " |  \n",
      " |  \n",
      " |  For each element in the input sequence, each layer computes the following\n",
      " |  function:\n",
      " |  \n",
      " |  .. math::\n",
      " |      \\begin{array}{ll}\n",
      " |          r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n",
      " |          z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n",
      " |          n_t = \\tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n",
      " |          h_t = (1 - z_t) * n_t + z_t * h_{(t-1)}\n",
      " |      \\end{array}\n",
      " |  \n",
      " |  where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is the input\n",
      " |  at time `t`, :math:`h_{(t-1)}` is the hidden state of the layer\n",
      " |  at time `t-1` or the initial hidden state at time `0`, and :math:`r_t`,\n",
      " |  :math:`z_t`, :math:`n_t` are the reset, update, and new gates, respectively.\n",
      " |  :math:`\\sigma` is the sigmoid function, and :math:`*` is the Hadamard product.\n",
      " |  \n",
      " |  In a multilayer GRU, the input :math:`x^{(l)}_t` of the :math:`l` -th layer\n",
      " |  (:math:`l >= 2`) is the hidden state :math:`h^{(l-1)}_t` of the previous layer multiplied by\n",
      " |  dropout :math:`\\delta^{(l-1)}_t` where each :math:`\\delta^{(l-1)}_t` is a Bernoulli random\n",
      " |  variable which is :math:`0` with probability :attr:`dropout`.\n",
      " |  \n",
      " |  Args:\n",
      " |      input_size: The number of expected features in the input `x`\n",
      " |      hidden_size: The number of features in the hidden state `h`\n",
      " |      num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n",
      " |          would mean stacking two GRUs together to form a `stacked GRU`,\n",
      " |          with the second GRU taking in outputs of the first GRU and\n",
      " |          computing the final results. Default: 1\n",
      " |      bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
      " |          Default: ``True``\n",
      " |      batch_first: If ``True``, then the input and output tensors are provided\n",
      " |          as `(batch, seq, feature)` instead of `(seq, batch, feature)`.\n",
      " |          Note that this does not apply to hidden or cell states. See the\n",
      " |          Inputs/Outputs sections below for details.  Default: ``False``\n",
      " |      dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n",
      " |          GRU layer except the last layer, with dropout probability equal to\n",
      " |          :attr:`dropout`. Default: 0\n",
      " |      bidirectional: If ``True``, becomes a bidirectional GRU. Default: ``False``\n",
      " |  \n",
      " |  Inputs: input, h_0\n",
      " |      * **input**: tensor of shape :math:`(L, H_{in})` for unbatched input,\n",
      " |        :math:`(L, N, H_{in})` when ``batch_first=False`` or\n",
      " |        :math:`(N, L, H_{in})` when ``batch_first=True`` containing the features of\n",
      " |        the input sequence.  The input can also be a packed variable length sequence.\n",
      " |        See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n",
      " |        :func:`torch.nn.utils.rnn.pack_sequence` for details.\n",
      " |      * **h_0**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` or\n",
      " |        :math:`(D * \\text{num\\_layers}, N, H_{out})`\n",
      " |        containing the initial hidden state for the input sequence. Defaults to zeros if not provided.\n",
      " |  \n",
      " |      where:\n",
      " |  \n",
      " |      .. math::\n",
      " |          \\begin{aligned}\n",
      " |              N ={} & \\text{batch size} \\\\\n",
      " |              L ={} & \\text{sequence length} \\\\\n",
      " |              D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n",
      " |              H_{in} ={} & \\text{input\\_size} \\\\\n",
      " |              H_{out} ={} & \\text{hidden\\_size}\n",
      " |          \\end{aligned}\n",
      " |  \n",
      " |  Outputs: output, h_n\n",
      " |      * **output**: tensor of shape :math:`(L, D * H_{out})` for unbatched input,\n",
      " |        :math:`(L, N, D * H_{out})` when ``batch_first=False`` or\n",
      " |        :math:`(N, L, D * H_{out})` when ``batch_first=True`` containing the output features\n",
      " |        `(h_t)` from the last layer of the GRU, for each `t`. If a\n",
      " |        :class:`torch.nn.utils.rnn.PackedSequence` has been given as the input, the output\n",
      " |        will also be a packed sequence.\n",
      " |      * **h_n**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` or\n",
      " |        :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the final hidden state\n",
      " |        for the input sequence.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight_ih_l[k] : the learnable input-hidden weights of the :math:`\\text{k}^{th}` layer\n",
      " |          (W_ir|W_iz|W_in), of shape `(3*hidden_size, input_size)` for `k = 0`.\n",
      " |          Otherwise, the shape is `(3*hidden_size, num_directions * hidden_size)`\n",
      " |      weight_hh_l[k] : the learnable hidden-hidden weights of the :math:`\\text{k}^{th}` layer\n",
      " |          (W_hr|W_hz|W_hn), of shape `(3*hidden_size, hidden_size)`\n",
      " |      bias_ih_l[k] : the learnable input-hidden bias of the :math:`\\text{k}^{th}` layer\n",
      " |          (b_ir|b_iz|b_in), of shape `(3*hidden_size)`\n",
      " |      bias_hh_l[k] : the learnable hidden-hidden bias of the :math:`\\text{k}^{th}` layer\n",
      " |          (b_hr|b_hz|b_hn), of shape `(3*hidden_size)`\n",
      " |  \n",
      " |  .. note::\n",
      " |      All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
      " |      where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
      " |  \n",
      " |  .. note::\n",
      " |      For bidirectional GRUs, forward and backward are directions 0 and 1 respectively.\n",
      " |      Example of splitting the output layers when ``batch_first=False``:\n",
      " |      ``output.view(seq_len, batch, num_directions, hidden_size)``.\n",
      " |  \n",
      " |  .. note::\n",
      " |      ``batch_first`` argument is ignored for unbatched inputs.\n",
      " |  \n",
      " |  .. include:: ../cudnn_persistent_rnn.rst\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> rnn = nn.GRU(10, 20, 2)\n",
      " |      >>> input = torch.randn(5, 3, 10)\n",
      " |      >>> h0 = torch.randn(2, 3, 20)\n",
      " |      >>> output, hn = rnn(input, h0)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GRU\n",
      " |      RNNBase\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  forward(self, input, hx=None)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from RNNBase:\n",
      " |  \n",
      " |  __setattr__(self, attr, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, d)\n",
      " |  \n",
      " |  check_forward_args(self, input: torch.Tensor, hidden: torch.Tensor, batch_sizes: Union[torch.Tensor, NoneType])\n",
      " |  \n",
      " |  check_hidden_size(self, hx: torch.Tensor, expected_hidden_size: Tuple[int, int, int], msg: str = 'Expected hidden size {}, got {}') -> None\n",
      " |  \n",
      " |  check_input(self, input: torch.Tensor, batch_sizes: Union[torch.Tensor, NoneType]) -> None\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  flatten_parameters(self) -> None\n",
      " |      Resets parameter data pointer so that they can use faster code paths.\n",
      " |      \n",
      " |      Right now, this works only if the module is on the GPU and cuDNN is enabled.\n",
      " |      Otherwise, it's a no-op.\n",
      " |  \n",
      " |  get_expected_hidden_size(self, input: torch.Tensor, batch_sizes: Union[torch.Tensor, NoneType]) -> Tuple[int, int, int]\n",
      " |  \n",
      " |  permute_hidden(self, hx: torch.Tensor, permutation: Union[torch.Tensor, NoneType])\n",
      " |  \n",
      " |  reset_parameters(self) -> None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from RNNBase:\n",
      " |  \n",
      " |  all_weights\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from RNNBase:\n",
      " |  \n",
      " |  __annotations__ = {'batch_first': <class 'bool'>, 'bias': <class 'bool...\n",
      " |  \n",
      " |  __constants__ = ['mode', 'input_size', 'hidden_size', 'num_layers', 'b...\n",
      " |  \n",
      " |  __jit_unused_properties__ = ['all_weights']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  add_module(self, name: str, module: Union[ForwardRef('Module'), NoneType]) -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Returns the buffer given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |  \n",
      " |  get_extra_state(self) -> Any\n",
      " |      Returns any extra state to include in the module's state_dict.\n",
      " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
      " |      if you need to store extra state. This function is called when building the\n",
      " |      module's `state_dict()`.\n",
      " |      \n",
      " |      Note that extra state should be pickleable to ensure working serialization\n",
      " |      of the state_dict. We only provide provide backwards compatibility guarantees\n",
      " |      for serializing Tensors; other objects may break backwards compatibility if\n",
      " |      their serialized pickled form changes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: Any extra state to store in the module's state_dict\n",
      " |  \n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Returns the parameter given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |  \n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Returns the submodule given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |      \n",
      " |      .. code-block:: text\n",
      " |      \n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |      \n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |      \n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Module``\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  ipu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the IPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on IPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |      \n",
      " |      Note:\n",
      " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      " |          ``RuntimeError``.\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Union[Set[ForwardRef('Module')], NoneType] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |              or not\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Union[torch.Tensor, NoneType], persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to a module\n",
      " |      are computed, i.e. the hook will execute if and only if the gradients with\n",
      " |      respect to module outputs are computed. The hook should have the following\n",
      " |      signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_load_state_dict_post_hook(self, hook)\n",
      " |      Registers a post hook to be run after module's ``load_state_dict``\n",
      " |      is called.\n",
      " |      \n",
      " |      It should have the following signature::\n",
      " |          hook(module, incompatible_keys) -> None\n",
      " |      \n",
      " |      The ``module`` argument is the current module that this hook is registered\n",
      " |      on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\n",
      " |      of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\n",
      " |      is a ``list`` of ``str`` containing the missing keys and\n",
      " |      ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\n",
      " |      \n",
      " |      The given incompatible_keys can be modified inplace if needed.\n",
      " |      \n",
      " |      Note that the checks performed when calling :func:`load_state_dict` with\n",
      " |      ``strict=True`` are affected by modifications the hook makes to\n",
      " |      ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\n",
      " |      set of keys will result in an error being thrown when ``strict=True``, and\n",
      " |      clearning out both missing and unexpected keys will avoid an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_module(self, name: str, module: Union[ForwardRef('Module'), NoneType]) -> None\n",
      " |      Alias for :func:`add_module`.\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Union[torch.nn.parameter.Parameter, NoneType]) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter or None): parameter to be added to the module. If\n",
      " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      " |              are ignored. If ``None``, the parameter is **not** included in the\n",
      " |              module's :attr:`state_dict`.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  set_extra_state(self, state: Any)\n",
      " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
      " |      found within the `state_dict`. Implement this function and a corresponding\n",
      " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
      " |      `state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state (dict): Extra state from the `state_dict`\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`\n",
      " |  \n",
      " |  state_dict(self, *args, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing references to the whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      Parameters and buffers set to ``None`` are not included.\n",
      " |      \n",
      " |      .. note::\n",
      " |          The returned object is a shallow copy. It contains references\n",
      " |          to the module's parameters and buffers.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Currently ``state_dict()`` also accepts positional arguments for\n",
      " |          ``destination``, ``prefix`` and ``keep_vars`` in order. However,\n",
      " |          this is being deprecated and keyword arguments will be enforced in\n",
      " |          future releases.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Please avoid the use of argument ``destination`` as it is not\n",
      " |          designed for end-users.\n",
      " |      \n",
      " |      Args:\n",
      " |          destination (dict, optional): If provided, the state of module will\n",
      " |              be updated into the dict and the same object is returned.\n",
      " |              Otherwise, an ``OrderedDict`` will be created and returned.\n",
      " |              Default: ``None``.\n",
      " |          prefix (str, optional): a prefix added to parameter and buffer\n",
      " |              names to compose the keys in state_dict. Default: ``''``.\n",
      " |          keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\n",
      " |              returned in the state dict are detached from autograd. If it's\n",
      " |              set to ``True``, detaching will not be performed.\n",
      " |              Default: ``False``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  to_empty(self: ~T, *, device: Union[str, torch.device]) -> ~T\n",
      " |      Moves the parameters and buffers to the specified device without copying storage.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = False) -> None\n",
      " |      Sets gradients of all model parameters to zero. See similar function\n",
      " |      under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model applies over the batch\n",
    "batch_ix = to_matrix(sample(data, 32), token_to_id, max_len=MAX_LENGTH)\n",
    "batch_ix = Variable(torch.LongTensor(batch_ix))\n",
    "\n",
    "logp_seq = model(batch_ix)\n",
    "\n",
    "# compute loss\n",
    "loss = F.nll_loss(logp_seq[:, 1:].contiguous().view(-1, num_tokens), \n",
    "                  batch_ix[:, :-1].contiguous().view(-1))\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 150, 211])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp_seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.4164, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 42s, sys: 1min 2s, total: 24min 44s\n",
      "Wall time: 3min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "MAX_LENGTH = 150\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_ix = to_matrix(sample(data, 32), token_to_id, max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "    \n",
    "    logp_seq = model(batch_ix)\n",
    "    \n",
    "    # compute loss\n",
    "    predictions_logp = logp_seq[:, :-1]\n",
    "    actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "    loss = -torch.mean(torch.gather(predictions_logp, dim=2, index=actual_next_tokens.unsqueeze(-1)))\n",
    "    \n",
    "    # train with backprop\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    # visualizing training process\n",
    "    history.append(loss.data.numpy())\n",
    "    if (i + 1) % 50 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:30]) > np.mean(history[-30:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8507321"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history[-30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
    "\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        with torch.no_grad():\n",
    "            logp_next = model(x_sequence)\n",
    "\n",
    "        logp_next = logp_next.squeeze(0)[-1]\n",
    "\n",
    "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()\n",
    "\n",
    "        next_ix = np.random.choice(len(tokens), 1, p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64).squeeze(0)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "\n",
    "\n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNN_GRU(\n",
       "  (emb): Embedding(211, 16)\n",
       "  (rnn): GRU(16, 64, num_layers=3, batch_first=True, dropout=0.3)\n",
       "  (hid_to_logits): Linear(in_features=64, out_features=211, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-998e2869b532>:22: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  next_ix = torch.tensor([[next_ix]], dtype=torch.int64).squeeze(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Борамн сотохталкодь эвовевьтуБта l пыгпуго. е орнееУла.                                                                                              '"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -                                                                                                                                                    \n",
      "\n",
      " - Слобаро асс.                                                                                                                                       \n",
      "\n",
      " Моросты врати побать нонь бованитя чсваличая помек седо отодавел вотили верикь воралто счеме и стели тови жоляснии и спозиборь  постотод, вум влавалв\n",
      "\n",
      " - Вчорилешит с снорат лено.                                                                                                                          \n",
      "\n",
      " - Де пазен озолно те лорет вевия, сельно стоть им тели вопели палото и па плалокь на ноть поросто  вовос ного дотое редомрить пулелес.-              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(generate(model, temperature=0.5), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как-то Маша волоролания и  вотом волать ато потовно толити мом слалеть онити вока пототь стотатить сотоноть.                                          \n",
      "\n",
      "Как-то Маша нотол кротать но тота ни стать те помороло поколи нони вонита не стесто столья дет слоста, но петань вати тоста вонил вого сели пононо на \n",
      "\n",
      "Как-то Маша пастость вона зорости достали сети но пестим восто пань ношо потавитеть стоки поритотая стести вонить пестатить перольно но вотити и сено \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    print(generate(model, seed_phrase='Как-то Маша ', temperature=0.3), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
