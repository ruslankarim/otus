{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253dbded-f507-4c1f-9b2b-0b001400d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220fda62-deb1-48ac-8bbc-0a152c8f80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('poslo.txt', encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52848dbe-41bc-4b05-8071-7bda0ee18f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'А где щи, тут и нас ищи.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "126703f5-7acd-4ada-a01f-44a00da94108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(line):\n",
    "    return ' '.join(w.lower() for w in (''.join(ch for ch in word if ch.isalpha()) for word in line.split()) if w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0fc04a1-b666-478f-abbd-8b1204cd7be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'а где щи тут и нас ищи'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ecee5dc-f7cc-41f6-9de7-08aff676c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lines,\n",
    "    ):\n",
    "        self.lines = lines\n",
    "        self.pad_token = '<PAD>'\n",
    "        self.bos_token = '<BOS>'\n",
    "        self.eos_token = '<EOS>'\n",
    "        self.uniq_words = [self.pad_token, self.bos_token, self.eos_token] + self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.pad_token_id = self.word_to_index['<PAD>']\n",
    "        self.bos_token_id = self.word_to_index['<BOS>']\n",
    "        self.eos_token_id = self.word_to_index['<EOS>']\n",
    "\n",
    "        self.tokenized = [[self.word_to_index[w] for w in line.split()] for line in self.lines]\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(word for line in self.lines for word in line.split())\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.LongTensor([self.bos_token_id] + self.tokenized[index]),\n",
    "            torch.LongTensor(self.tokenized[index] + [self.eos_token_id]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98019582-81ae-40cd-b246-e8e2cd4ad15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset([preprocess(line) for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4eace38-f0ef-4b9d-bc8d-5fe30291c53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1,   4,  25, 310, 197,   5,  56, 311]),\n",
       " tensor([  4,  25, 310, 197,   5,  56, 311,   2]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd3ba6d7-5929-4d1b-9733-d6db8fe29684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    y_lens = [len(y) for y in yy]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=dataset.pad_token_id)\n",
    "    yy_pad = pad_sequence(yy, batch_first=True, padding_value=dataset.pad_token_id)\n",
    "\n",
    "    return xx_pad, yy_pad, x_lens, y_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "518d85be-307e-4f97-b2de-d14c741997a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=512, collate_fn=pad_collate, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb31f3d1-5e43-4ccf-947f-032d2f53e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_len):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = 256\n",
    "        self.embedding_dim = 256\n",
    "        self.num_layers = 3\n",
    "\n",
    "        vocab_len = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_len,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "            padding_idx=0,\n",
    "        )\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.hidden_size, vocab_len)\n",
    "\n",
    "    def forward(self, x, lens=None, prev_state=None):\n",
    "        embed = self.embedding(x)\n",
    "        if lens is None:\n",
    "            output, state = self.rnn(embed, prev_state)\n",
    "        else:\n",
    "            embed_packed = pack_padded_sequence(embed, lens, batch_first=True, enforce_sorted=False)\n",
    "            output_packed, state = self.rnn(embed_packed, prev_state)\n",
    "            output, _ = pad_packed_sequence(output_packed, batch_first=True)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1be8fc86-ae1b-467d-9245-de0822e9a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = Model(len(dataset.uniq_words)).to(DEVICE).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b89cc4b2-027a-44e1-944c-fa3120bb356f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5319291"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1d9d33c-73e7-4828-a94b-e0b48486d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=dataset.pad_token_id)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ca8dcea-bf49-4c52-9337-7744fcdc3d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, epochs):\n",
    "    losses = []\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for x, y, x_lens, y_lens in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, _ = model(x.to(DEVICE), x_lens)\n",
    "            loss = criterion(y_pred.transpose(1, 2), y.to(DEVICE))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        if epoch % 10 == 0:\n",
    "            print({ 'epoch': epoch, 'loss': losses[-1] })\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57b03454-b825-44e2-a60c-71224b2bf290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'loss': 7.377316474914551}\n",
      "{'epoch': 10, 'loss': 6.221266269683838}\n",
      "{'epoch': 20, 'loss': 5.7292375564575195}\n",
      "{'epoch': 30, 'loss': 5.315099239349365}\n",
      "{'epoch': 40, 'loss': 4.718502521514893}\n",
      "{'epoch': 50, 'loss': 4.299665451049805}\n",
      "{'epoch': 60, 'loss': 3.903717041015625}\n",
      "{'epoch': 70, 'loss': 3.482243776321411}\n",
      "{'epoch': 80, 'loss': 3.0355379581451416}\n",
      "{'epoch': 90, 'loss': 2.7317733764648438}\n",
      "{'epoch': 100, 'loss': 2.4760231971740723}\n",
      "{'epoch': 110, 'loss': 2.2514090538024902}\n",
      "{'epoch': 120, 'loss': 2.0736277103424072}\n",
      "{'epoch': 130, 'loss': 1.8672949075698853}\n",
      "{'epoch': 140, 'loss': 1.7959599494934082}\n",
      "{'epoch': 150, 'loss': 1.6400595903396606}\n",
      "{'epoch': 160, 'loss': 1.5234030485153198}\n",
      "{'epoch': 170, 'loss': 1.5439362525939941}\n",
      "{'epoch': 180, 'loss': 1.4565234184265137}\n",
      "{'epoch': 190, 'loss': 1.3894922733306885}\n",
      "{'epoch': 200, 'loss': 1.4020274877548218}\n",
      "{'epoch': 210, 'loss': 1.372261881828308}\n",
      "{'epoch': 220, 'loss': 1.3907551765441895}\n",
      "{'epoch': 230, 'loss': 1.2821142673492432}\n",
      "{'epoch': 240, 'loss': 1.2497448921203613}\n"
     ]
    }
   ],
   "source": [
    "loss_history = train(model, dataloader, criterion, optimizer, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f09c7b96-f575-4ae7-acd2-2a4653bbc862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2503a883950>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49cd196b-e66c-49c6-95c3-d70bf9f7c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(value):\n",
    "    return [dataset.bos_token_id]+[dataset.word_to_index[word.lower()] for word in value.split()]\n",
    "\n",
    "\n",
    "def decode(token_ids):\n",
    "    return ' '.join(dataset.index_to_word[token_id] for token_id in token_ids)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(prompt, max_tokens=20):\n",
    "    model.eval()\n",
    "    response = []\n",
    "    state = None\n",
    "    prompt_tokens = tokenize(prompt)\n",
    "    model_input = torch.LongTensor([prompt_tokens]).to(DEVICE)\n",
    "    for _ in range(max_tokens):\n",
    "        logits, state = model(model_input, prev_state=state)\n",
    "        token_argmax = logits[0, -1].argmax()\n",
    "        response.append(token_argmax.item())\n",
    "        if response[-1] == dataset.eos_token_id:\n",
    "            break\n",
    "        model_input = token_argmax.view(1, 1)\n",
    "\n",
    "    return decode(prompt_tokens + response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eccf90b9-82c8-455c-b828-4d09f9377fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<BOS> рука руку моет а две руки лицо <EOS>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate('рука')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28409eb8-f07f-4217-9f4d-b91e77046d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(prompt, max_tokens=20):\n",
    "    model.eval()\n",
    "    response = []\n",
    "    state = None\n",
    "    prompt_tokens = tokenize(prompt)\n",
    "    model_input = torch.LongTensor([prompt_tokens]).to(DEVICE)\n",
    "    for _ in range(max_tokens):\n",
    "        logits, state = model(model_input, prev_state=state)\n",
    "        token_probs = F.softmax(logits[0, -1], dim=-1).cpu().numpy()\n",
    "        sampled_token = np.random.choice(len(token_probs), p=token_probs)\n",
    "        response.append(sampled_token)\n",
    "        if response[-1] == dataset.eos_token_id:\n",
    "            break\n",
    "        model_input = torch.LongTensor([[sampled_token]]).to(DEVICE)\n",
    "\n",
    "    return decode(prompt_tokens + response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a257f00e-c474-48fe-b473-9c3614dcf9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<BOS> без мужа в беде головы сам в аптека не годится <EOS>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample('без')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e4320eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tf-keras) (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.26.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\руслан\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB 330.3 kB/s eta 0:00:06\n",
      "    --------------------------------------- 0.0/1.7 MB 393.8 kB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.1/1.7 MB 655.4 kB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.2/1.7 MB 833.5 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.7 MB 1.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.3/1.7 MB 1.0 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.3/1.7 MB 1.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.5/1.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.7 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.6/1.7 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.7/1.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.7/1.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.8/1.7 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.9/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.7 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.1/1.7 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.2/1.7 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.4/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.5/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.6/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.7/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63394261-b324-44c6-910a-3341ea3cc5dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to load vocabulary from file. Please check that the provided vocabulary is accessible and not corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2336\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._from_pretrained\u001B[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001B[0m\n\u001B[0;32m   2335\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 2336\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minit_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2337\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:151\u001B[0m, in \u001B[0;36mT5Tokenizer.__init__\u001B[1;34m(self, vocab_file, eos_token, unk_token, pad_token, extra_ids, additional_special_tokens, sp_model_kwargs, legacy, add_prefix_space, **kwargs)\u001B[0m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msp_model \u001B[38;5;241m=\u001B[39m spm\u001B[38;5;241m.\u001B[39mSentencePieceProcessor(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msp_model_kwargs)\n\u001B[1;32m--> 151\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msp_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLoad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvocab_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m additional_special_tokens \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentencepiece\\__init__.py:961\u001B[0m, in \u001B[0;36mSentencePieceProcessor.Load\u001B[1;34m(self, model_file, model_proto)\u001B[0m\n\u001B[0;32m    960\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLoadFromSerializedProto(model_proto)\n\u001B[1;32m--> 961\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLoadFromFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_file\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentencepiece\\__init__.py:316\u001B[0m, in \u001B[0;36mSentencePieceProcessor.LoadFromFile\u001B[1;34m(self, arg)\u001B[0m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mLoadFromFile\u001B[39m(\u001B[38;5;28mself\u001B[39m, arg):\n\u001B[1;32m--> 316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_sentencepiece\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSentencePieceProcessor_LoadFromFile\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mOSError\u001B[0m: Not found: \"C:\\Users\\Руслан\\.cache\\huggingface\\hub\\models--ai-forever--ruT5-large\\snapshots\\b3321d48aefe45ffd70ea2f649570b91441e0055\\spiece.model\": No such file or directory Error #2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForSeq2SeqLM, T5Tokenizer, RobertaTokenizer\n\u001B[1;32m----> 3\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mT5Tokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mai-forever/ruT5-large\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2110\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001B[0m\n\u001B[0;32m   2107\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2108\u001B[0m         logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloading file \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m from cache at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresolved_vocab_files[file_id]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 2110\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_from_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2111\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresolved_vocab_files\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2113\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit_configuration\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2114\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minit_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2118\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2119\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_is_local\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_local\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2120\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2121\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2122\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2338\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._from_pretrained\u001B[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001B[0m\n\u001B[0;32m   2336\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;241m*\u001B[39minit_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minit_kwargs)\n\u001B[0;32m   2337\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[1;32m-> 2338\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[0;32m   2339\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnable to load vocabulary from file. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2340\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease check that the provided vocabulary is accessible and not corrupted.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2341\u001B[0m     )\n\u001B[0;32m   2343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m added_tokens_decoder \u001B[38;5;241m!=\u001B[39m {} \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mlist\u001B[39m(added_tokens_decoder\u001B[38;5;241m.\u001B[39mkeys())[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m>\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mvocab_size:\n\u001B[0;32m   2344\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning_advice(\n\u001B[0;32m   2345\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2346\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m fine-tuned or trained.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2347\u001B[0m     )\n",
      "\u001B[1;31mOSError\u001B[0m: Unable to load vocabulary from file. Please check that the provided vocabulary is accessible and not corrupted."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5Tokenizer, RobertaTokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"ai-forever/ruT5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8277a347-c5a3-4d9e-9b23-dda2bc7e2df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Руслан\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7a5683100d40a297f6f8b92d6517be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1097c91cfb954310bc4afc2c9e07d586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/20.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2067f6e20d349aca7aa5943af94b3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b5d108be124be0b9f2fb32711e8b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "Unable to load vocabulary from file. Please check that the provided vocabulary is accessible and not corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2336\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._from_pretrained\u001B[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001B[0m\n\u001B[0;32m   2335\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 2336\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minit_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2337\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:151\u001B[0m, in \u001B[0;36mT5Tokenizer.__init__\u001B[1;34m(self, vocab_file, eos_token, unk_token, pad_token, extra_ids, additional_special_tokens, sp_model_kwargs, legacy, add_prefix_space, **kwargs)\u001B[0m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msp_model \u001B[38;5;241m=\u001B[39m spm\u001B[38;5;241m.\u001B[39mSentencePieceProcessor(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msp_model_kwargs)\n\u001B[1;32m--> 151\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msp_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLoad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvocab_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m additional_special_tokens \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentencepiece\\__init__.py:961\u001B[0m, in \u001B[0;36mSentencePieceProcessor.Load\u001B[1;34m(self, model_file, model_proto)\u001B[0m\n\u001B[0;32m    960\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLoadFromSerializedProto(model_proto)\n\u001B[1;32m--> 961\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLoadFromFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_file\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentencepiece\\__init__.py:316\u001B[0m, in \u001B[0;36mSentencePieceProcessor.LoadFromFile\u001B[1;34m(self, arg)\u001B[0m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mLoadFromFile\u001B[39m(\u001B[38;5;28mself\u001B[39m, arg):\n\u001B[1;32m--> 316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_sentencepiece\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSentencePieceProcessor_LoadFromFile\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mOSError\u001B[0m: Not found: \"C:\\Users\\Руслан\\.cache\\huggingface\\hub\\models--sberbank-ai--ruT5-base\\snapshots\\e7529ab6ad41978ed21a532aa25da58d5f01338b\\spiece.model\": No such file or directory Error #2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# ruT5-base example\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pipeline\n\u001B[1;32m----> 5\u001B[0m generator \u001B[38;5;241m=\u001B[39m \u001B[43mpipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtext2text-generation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msberbank-ai/ruT5-base\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m generator(\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mТекст: С мая 2021 в России \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      8\u001B[0m )\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# ruT5-large example \u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:1005\u001B[0m, in \u001B[0;36mpipeline\u001B[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001B[0m\n\u001B[0;32m   1002\u001B[0m             tokenizer_kwargs \u001B[38;5;241m=\u001B[39m model_kwargs\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m   1003\u001B[0m             tokenizer_kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch_dtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m-> 1005\u001B[0m         tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mAutoTokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1006\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtokenizer_identifier\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_fast\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_fast\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_from_pipeline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtokenizer_kwargs\u001B[49m\n\u001B[0;32m   1007\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1009\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m load_image_processor:\n\u001B[0;32m   1010\u001B[0m     \u001B[38;5;66;03m# Try to infer image processor from model or config name (if provided as str)\u001B[39;00m\n\u001B[0;32m   1011\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m image_processor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:880\u001B[0m, in \u001B[0;36mAutoTokenizer.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m    876\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tokenizer_class \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    877\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    878\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTokenizer class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtokenizer_class_candidate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not exist or is not currently imported.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    879\u001B[0m         )\n\u001B[1;32m--> 880\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtokenizer_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    882\u001B[0m \u001B[38;5;66;03m# Otherwise we have to be creative.\u001B[39;00m\n\u001B[0;32m    883\u001B[0m \u001B[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001B[39;00m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, EncoderDecoderConfig):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2110\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001B[0m\n\u001B[0;32m   2107\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2108\u001B[0m         logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloading file \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m from cache at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresolved_vocab_files[file_id]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 2110\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_from_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2111\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresolved_vocab_files\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2113\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit_configuration\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2114\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minit_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2118\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2119\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_is_local\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_local\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2120\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2121\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2122\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2148\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._from_pretrained\u001B[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001B[0m\n\u001B[0;32m   2145\u001B[0m \u001B[38;5;66;03m# If one passes a GGUF file path to `gguf_file` there is no need for this check as the tokenizer will be\u001B[39;00m\n\u001B[0;32m   2146\u001B[0m \u001B[38;5;66;03m# loaded directly from the GGUF file.\u001B[39;00m\n\u001B[0;32m   2147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (from_slow \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_tokenizer_file) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mslow_tokenizer_class \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m gguf_file:\n\u001B[1;32m-> 2148\u001B[0m     slow_tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mslow_tokenizer_class\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_from_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2149\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresolved_vocab_files\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2150\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2151\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43minit_configuration\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2152\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minit_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2153\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2154\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2155\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2156\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_commit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2157\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2158\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2159\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2160\u001B[0m     slow_tokenizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2338\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._from_pretrained\u001B[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001B[0m\n\u001B[0;32m   2336\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;241m*\u001B[39minit_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minit_kwargs)\n\u001B[0;32m   2337\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[1;32m-> 2338\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[0;32m   2339\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnable to load vocabulary from file. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2340\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease check that the provided vocabulary is accessible and not corrupted.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2341\u001B[0m     )\n\u001B[0;32m   2343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m added_tokens_decoder \u001B[38;5;241m!=\u001B[39m {} \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mlist\u001B[39m(added_tokens_decoder\u001B[38;5;241m.\u001B[39mkeys())[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m>\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mvocab_size:\n\u001B[0;32m   2344\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning_advice(\n\u001B[0;32m   2345\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2346\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m fine-tuned or trained.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2347\u001B[0m     )\n",
      "\u001B[1;31mOSError\u001B[0m: Unable to load vocabulary from file. Please check that the provided vocabulary is accessible and not corrupted."
     ]
    }
   ],
   "source": [
    "# ruT5-base example\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text2text-generation\", model=\"sberbank-ai/ruT5-base\")\n",
    "generator(\n",
    "    \"Текст: С мая 2021 в России \"\n",
    ")\n",
    "\n",
    "# ruT5-large example \n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "\n",
    "model=T5ForConditionalGeneration.from_pretrained('sberbank-ai/ruT5-large')\n",
    "\n",
    "tokenizer=T5Tokenizer.from_pretrained('sberbank-ai/ruT5-large',)\n",
    "input_ids = tokenizer('Снижение цен <extra_id_0> в Москве возможно только при <extra_id_1>. Это условие названо в аналитической заметке агентства <extra_id_2>, поступившей в редакцию <extra_id_3>', return_tensors='pt').input_ids\n",
    "\n",
    "out_ids=model.generate(input_ids=input_ids,\n",
    "                        max_length=30,\n",
    "                        eos_token_id=tokenizer.eos_token_id, \n",
    "                        early_stopping=True)\n",
    "\n",
    "tokenizer.decode(out_ids[0][1:])\n",
    "\n",
    "#<extra_id_0> на бензин<extra_id_1> условии сохранения текущей ситуации<extra_id_2> ТАСС<extra_id_3>.</s>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323b496e-02d2-4724-a9d1-f019db09edb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/w7/r_mz1frd4hbdbnlm1hh0c7xxhz1_lw/T/ipykernel_20334/4114504567.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muniq_words\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "len(dataset.uniq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c85f495-a703-49a7-b2e8-765ff525c270",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/w7/r_mz1frd4hbdbnlm1hh0c7xxhz1_lw/T/ipykernel_50059/836816688.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m             \u001B[0mpreprocess\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mline\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m             \u001B[0madd_special_tokens\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m         )['input_ids'] for line in lines\n\u001B[0m\u001B[1;32m      7\u001B[0m     ) for x in tokens\n\u001B[1;32m      8\u001B[0m ))))\n",
      "\u001B[0;32m/var/folders/w7/r_mz1frd4hbdbnlm1hh0c7xxhz1_lw/T/ipykernel_50059/836816688.py\u001B[0m in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      1\u001B[0m len(set(((\n\u001B[0;32m----> 2\u001B[0;31m     x for tokens in (\n\u001B[0m\u001B[1;32m      3\u001B[0m         tokenizer(\n\u001B[1;32m      4\u001B[0m             \u001B[0mpreprocess\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mline\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m             \u001B[0madd_special_tokens\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/w7/r_mz1frd4hbdbnlm1hh0c7xxhz1_lw/T/ipykernel_50059/836816688.py\u001B[0m in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      4\u001B[0m             \u001B[0mpreprocess\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mline\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m             \u001B[0madd_special_tokens\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m         )['input_ids'] for line in lines\n\u001B[0m\u001B[1;32m      7\u001B[0m     ) for x in tokens\n\u001B[1;32m      8\u001B[0m ))))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "len(set(((\n",
    "    x for tokens in (\n",
    "        tokenizer(\n",
    "            preprocess(line),\n",
    "            add_special_tokens=False,\n",
    "        )['input_ids'] for line in lines\n",
    "    ) for x in tokens\n",
    "))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c3b0d-a3fe-4901-bf60-29ef55e8886f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}