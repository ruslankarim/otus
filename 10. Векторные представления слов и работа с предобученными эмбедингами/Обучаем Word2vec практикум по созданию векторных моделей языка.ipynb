{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e724447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/sysblok/rusvectores_tutorial/blob/master/rusvectores_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deff42e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp311-cp311-macosx_10_9_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m250.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m240.5 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m459.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m511.1 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.0.5-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Downloading gensim-4.3.3-cp311-cp311-macosx_10_9_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m572.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m314.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-macosx_10_9_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m419.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.0.5-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m447.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp311-cp311-macosx_10_9_x86_64.whl (37 kB)\n",
      "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.0.5 wrapt-1.16.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install ufal.udpipe\n",
    "# !pip install wget\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2327f5-0312-4484-b9ae-fb602046283d",
   "metadata": {},
   "source": [
    "Кусок кода ниже скачает рассказ О’Генри и модель UDPipe для лингвистической предобработки.\n",
    "Модель весит 40 мегабайт, поэтому ячейка может выполнятся некоторое время,\n",
    "особенно если у вас небыстрый интернет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275e77c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..............................................................................] 25649 / 25649"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import sys\n",
    "\n",
    "udpipe_url = 'https://rusvectores.org/static/models/udpipe_syntagrus.model'\n",
    "text_url = 'https://rusvectores.org/static/henry_sobolya.txt'\n",
    "\n",
    "modelfile = wget.download(udpipe_url)\n",
    "textfile = wget.download(text_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9c1522",
   "metadata": {},
   "outputs": [],
   "source": [
    "Приступим к собственно предобработке текста. Попробуем лемматизировать текст\n",
    "и добавить частеречные тэги при помощи этой функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7206a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(pipeline, text='Строка', keep_pos=True, keep_punct=False):\n",
    "    entities = {'PROPN'}\n",
    "    named = False\n",
    "    memory = []\n",
    "    mem_case = None\n",
    "    mem_number = None\n",
    "    tagged_propn = []\n",
    "\n",
    "    # обрабатываем текст, получаем результат в формате conllu:\n",
    "    processed = pipeline.process(text)\n",
    "\n",
    "    # пропускаем строки со служебной информацией:\n",
    "    content = [l for l in processed.split('\\n') if not l.startswith('#')]\n",
    "\n",
    "    # извлекаем из обработанного текста леммы, тэги и морфологические характеристики\n",
    "    tagged = [w.split('\\t') for w in content if w]\n",
    "\n",
    "    for t in tagged:\n",
    "        if len(t) != 10:\n",
    "            continue\n",
    "        (word_id, token, lemma, pos, xpos, feats, head, deprel, deps, misc) = t\n",
    "        if not lemma or not token:\n",
    "            continue\n",
    "        if pos in entities:\n",
    "            if '|' not in feats:\n",
    "                tagged_propn.append('%s_%s' % (lemma, pos))\n",
    "                continue\n",
    "            morph = {el.split('=')[0]: el.split('=')[1] for el in feats.split('|')}\n",
    "            if 'Case' not in morph or 'Number' not in morph:\n",
    "                tagged_propn.append('%s_%s' % (lemma, pos))\n",
    "                continue\n",
    "            if not named:\n",
    "                named = True\n",
    "                mem_case = morph['Case']\n",
    "                mem_number = morph['Number']\n",
    "            if morph['Case'] == mem_case and morph['Number'] == mem_number:\n",
    "                memory.append(lemma)\n",
    "                if 'SpacesAfter=\\\\n' in misc or 'SpacesAfter=\\s\\\\n' in misc:\n",
    "                    named = False\n",
    "                    past_lemma = '::'.join(memory)\n",
    "                    memory = []\n",
    "                    tagged_propn.append(past_lemma + '_PROPN ')\n",
    "            else:\n",
    "                named = False\n",
    "                past_lemma = '::'.join(memory)\n",
    "                memory = []\n",
    "                tagged_propn.append(past_lemma + '_PROPN ')\n",
    "                tagged_propn.append('%s_%s' % (lemma, pos))\n",
    "        else:\n",
    "            if not named:\n",
    "                if pos == 'NUM' and token.isdigit():  # Заменяем числа на xxxxx той же длины\n",
    "                    lemma = num_replace(token)\n",
    "                tagged_propn.append('%s_%s' % (lemma, pos))\n",
    "            else:\n",
    "                named = False\n",
    "                past_lemma = '::'.join(memory)\n",
    "                memory = []\n",
    "                tagged_propn.append(past_lemma + '_PROPN ')\n",
    "                tagged_propn.append('%s_%s' % (lemma, pos))\n",
    "\n",
    "    if not keep_punct:\n",
    "        tagged_propn = [word for word in tagged_propn if word.split('_')[1] != 'PUNCT']\n",
    "    if not keep_pos:\n",
    "        tagged_propn = [word.split('_')[0] for word in tagged_propn]\n",
    "    return tagged_propn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33b481-e2b0-4c4d-a266-c0860a4caaee",
   "metadata": {},
   "source": [
    "Теперь загружаем модель UDPipe, читаем текстовый файл и обрабатываем его при помощи нашей функции.\n",
    "В файле должен содержаться необработанный текст (одно предложение на строку или один абзац на строку).\n",
    "Этот текст токенизируется, лемматизируется и размечается по частям речи с использованием UDPipe.\n",
    "На выход мы получаем последовательность разделенных пробелами лемм с частями речи (\"зеленый_NOUN трамвай_NOUN\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "956d94d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ufal.udpipe import Model, Pipeline\n",
    "import os\n",
    "import re\n",
    "\n",
    "def tag_ud(text='Текст нужно передать функции в виде строки!', modelfile='udpipe_syntagrus.model'):\n",
    "    udpipe_model_url = 'https://rusvectores.org/static/models/udpipe_syntagrus.model'\n",
    "    udpipe_filename = udpipe_model_url.split('/')[-1]\n",
    "\n",
    "    if not os.path.isfile(modelfile):\n",
    "        print('UDPipe model not found. Downloading...', file=sys.stderr)\n",
    "        wget.download(udpipe_model_url)\n",
    "\n",
    "    print('\\nLoading the model...', file=sys.stderr)\n",
    "    model = Model.load(modelfile)\n",
    "    process_pipeline = Pipeline(model, 'tokenize', Pipeline.DEFAULT, Pipeline.DEFAULT, 'conllu')\n",
    "\n",
    "    print('Processing input...', file=sys.stderr)\n",
    "    lines = text.split('\\n')\n",
    "    tagged = []\n",
    "    for line in lines:\n",
    "        # line = unify_sym(line.strip()) # здесь могла бы быть ваша функция очистки текста\n",
    "        output = process(process_pipeline, text=line)\n",
    "        tagged_line = ' '.join(output)\n",
    "        tagged.append(tagged_line)\n",
    "    return '\\n'.join(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d0af5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the model...\n",
      "Processing input...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "русский_PROPN  соболь_NOUN о.::генри_PROPN \n",
      "когда_SCONJ синий_ADJ как_SCONJ ночь_NOUN глаз_NOUN Молли_VERB Мак-Кивер_PROPN  класть_VERB малыш::Брэди_PROPN  на_ADP оба_NUM лопатка_NOUN он_PRON вынужденный_ADJ быть_AUX покидать_VERB ряд_NOUN банда_NOUN «Дымовый_ADJ труба»_NOUN таков_ADJ власть_NOUN нежный_ADJ укор_NOUN подружка_NOUN и_CCONJ она_PRON \n"
     ]
    }
   ],
   "source": [
    "text = open(textfile, 'r', encoding='utf-8').read()\n",
    "processed_text = tag_ud(text=text, modelfile=modelfile)\n",
    "print(processed_text[:350])\n",
    "with open('my_text.txt', 'w', encoding='utf-8') as out:\n",
    "    out.write(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19e46601-2dbd-49b1-9b51-a7ff7f4350c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eda3aa-fb46-4663-bbca-7d834db45f75",
   "metadata": {},
   "source": [
    "На вход модели мы даем наш обработанный текстовый файл (либо любой другой текст, важно лишь, что каждое предложение должно быть на отдельной строчке)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7c380ef-a106-49e9-8d1e-83b85ed2f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'my_text.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d2184-7bec-4f62-b12e-85c8bf7187ee",
   "metadata": {},
   "source": [
    "Инициализируем модель. Параметры в скобочках:\n",
    "\n",
    "data - данные,\n",
    "size - размер вектора,\n",
    "window - размер окна наблюдения,\n",
    "min_count - мин. частотность слова в корпусе, которое мы берем,\n",
    "sg - используемый алгоритм обучение (0 - CBOW, 1 - Skip-gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f026459a-aaf1-414a-8696-56e5f0d32306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 21:24:18,704 : INFO : collecting all words and their counts\n",
      "2024-10-11 21:24:18,708 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-10-11 21:24:18,712 : INFO : collected 981 word types from a corpus of 2085 raw words and 65 sentences\n",
      "2024-10-11 21:24:18,713 : INFO : Creating a fresh vocabulary\n",
      "2024-10-11 21:24:18,714 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 252 unique words (25.69% of original 981, drops 729)', 'datetime': '2024-10-11T21:24:18.714909', 'gensim': '4.3.3', 'python': '3.11.10 (main, Oct 10 2024, 20:25:53) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-13.6.9-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-10-11 21:24:18,715 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 1356 word corpus (65.04% of original 2085, drops 729)', 'datetime': '2024-10-11T21:24:18.715878', 'gensim': '4.3.3', 'python': '3.11.10 (main, Oct 10 2024, 20:25:53) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-13.6.9-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-10-11 21:24:18,718 : INFO : deleting the raw counts dictionary of 981 items\n",
      "2024-10-11 21:24:18,719 : INFO : sample=0.001 downsamples 89 most-common words\n",
      "2024-10-11 21:24:18,720 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 801.9147957961445 word corpus (59.1%% of prior 1356)', 'datetime': '2024-10-11T21:24:18.720522', 'gensim': '4.3.3', 'python': '3.11.10 (main, Oct 10 2024, 20:25:53) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-13.6.9-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-10-11 21:24:18,727 : INFO : estimated required memory for 252 words and 500 dimensions: 1134000 bytes\n",
      "2024-10-11 21:24:18,728 : INFO : resetting layer weights\n",
      "2024-10-11 21:24:18,733 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-10-11T21:24:18.733684', 'gensim': '4.3.3', 'python': '3.11.10 (main, Oct 10 2024, 20:25:53) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-13.6.9-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2024-10-11 21:24:18,734 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 252 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2024-10-11T21:24:18.734825', 'gensim': '4.3.3', 'python': '3.11.10 (main, Oct 10 2024, 20:25:53) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-13.6.9-x86_64-i386-64bit', 'event': 'train'}\n",
      "2024-10-11 21:24:18,749 : INFO : EPOCH 0: training on 2085 raw words (785 effective words) took 0.0s, 75558 effective words/s\n",
      "2024-10-11 21:24:18,761 : INFO : EPOCH 1: training on 2085 raw words (816 effective words) took 0.0s, 109416 effective words/s\n",
      "2024-10-11 21:24:18,769 : INFO : EPOCH 2: training on 2085 raw words (814 effective words) took 0.0s, 158103 effective words/s\n",
      "2024-10-11 21:24:18,783 : INFO : EPOCH 3: training on 2085 raw words (815 effective words) took 0.0s, 87964 effective words/s\n",
      "2024-10-11 21:24:18,797 : INFO : EPOCH 4: training on 2085 raw words (791 effective words) took 0.0s, 133376 effective words/s\n",
      "2024-10-11 21:24:18,799 : INFO : Word2Vec lifecycle event {'msg': 'training on 10425 raw words (4021 effective words) took 0.1s, 63600 effective words/s', 'datetime': '2024-10-11T21:24:18.799554', 'gensim': '4.3.3', 'python': '3.11.10 (main, Oct 10 2024, 20:25:53) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-13.6.9-x86_64-i386-64bit', 'event': 'train'}\n",
      "2024-10-11 21:24:18,801 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=252, vector_size=500, alpha=0.025>', 'datetime': '2024-10-11T21:24:18.801824', 'gensim': '4.3.3', 'python': '3.11.10 (main, Oct 10 2024, 20:25:53) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-13.6.9-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(data, vector_size=500, window=10, min_count=2, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d25b95f6-8022-4a96-8237-937ead4ee513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w7/r_mz1frd4hbdbnlm1hh0c7xxhz1_lw/T/ipykernel_18646/1992334471.py:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n",
      "2024-10-11 21:25:11,866 : WARNING : destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65b262fe-5647-4aaa-bb2e-964a4c84c659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n"
     ]
    }
   ],
   "source": [
    "print(len(model.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38643137-acf7-4db1-8cca-5c1cf490570f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 21:26:11,933 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'my.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-10-11T21:26:11.933725', 'gensim': '4.3.3', 'python': '3.11.10 (main, Oct 10 2024, 20:25:53) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-13.6.9-x86_64-i386-64bit', 'event': 'saving'}\n",
      "2024-10-11 21:26:11,935 : INFO : not storing attribute cum_table\n",
      "2024-10-11 21:26:11,947 : INFO : saved my.model\n"
     ]
    }
   ],
   "source": [
    "model.save('my.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58c009-9be6-40bd-bac4-2fe8cd2ca158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
