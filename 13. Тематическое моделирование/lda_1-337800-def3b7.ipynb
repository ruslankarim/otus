{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA, LSI с Gensim и похожие по тематике тексты\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gensim\n",
    "import pymorphy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AtireBM25Model',\n",
       " 'AuthorTopicModel',\n",
       " 'BackMappingTranslationMatrix',\n",
       " 'CoherenceModel',\n",
       " 'Doc2Vec',\n",
       " 'EnsembleLda',\n",
       " 'FAST_VERSION',\n",
       " 'FastText',\n",
       " 'HdpModel',\n",
       " 'KeyedVectors',\n",
       " 'LdaModel',\n",
       " 'LdaMulticore',\n",
       " 'LdaSeqModel',\n",
       " 'LogEntropyModel',\n",
       " 'LsiModel',\n",
       " 'LuceneBM25Model',\n",
       " 'Nmf',\n",
       " 'NormModel',\n",
       " 'OkapiBM25Model',\n",
       " 'Phrases',\n",
       " 'RpModel',\n",
       " 'TfidfModel',\n",
       " 'TranslationMatrix',\n",
       " 'VocabTransform',\n",
       " 'Word2Vec',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_fasttext_bin',\n",
       " 'atmodel',\n",
       " 'basemodel',\n",
       " 'bm25model',\n",
       " 'callbacks',\n",
       " 'coherencemodel',\n",
       " 'doc2vec',\n",
       " 'doc2vec_corpusfile',\n",
       " 'doc2vec_inner',\n",
       " 'ensemblelda',\n",
       " 'fasttext',\n",
       " 'fasttext_corpusfile',\n",
       " 'fasttext_inner',\n",
       " 'hdpmodel',\n",
       " 'interfaces',\n",
       " 'keyedvectors',\n",
       " 'ldamodel',\n",
       " 'ldamulticore',\n",
       " 'ldaseqmodel',\n",
       " 'logentropy_model',\n",
       " 'lsimodel',\n",
       " 'nmf',\n",
       " 'nmf_pgd',\n",
       " 'normmodel',\n",
       " 'phrases',\n",
       " 'rpmodel',\n",
       " 'tfidfmodel',\n",
       " 'translation_matrix',\n",
       " 'utils',\n",
       " 'word2vec',\n",
       " 'word2vec_corpusfile',\n",
       " 'word2vec_inner']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(gensim.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy3.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачан датасет c https://tatianashavrina.github.io/taiga_site/news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = '../NPlus1/texts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7696"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20150928kc46a.txt',\n",
       " '20151001acoustic-diod.txt',\n",
       " '20150528planetary-fail.txt',\n",
       " '20160610reboot.txt',\n",
       " '20161011viknano.txt',\n",
       " '20161229Amazon-go-ahead.txt',\n",
       " '20170116all-resistant.txt',\n",
       " '20160425tunnelberyl.txt',\n",
       " '20160217china-gravitational-wave-projects.txt',\n",
       " '20150818superconducting-h2s.txt']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40M\t../NPlus1/texts\r\n"
     ]
    }
   ],
   "source": [
    "! du -sh ../NPlus1/texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Математики из Университета Северной Каролины обнаружили, что\n",
      "распределение вещества внутри трубы зависит от формы ее сечения гораздо\n",
      "сложнее, чем ранее предполагалось. Так, в круглых и эллиптических трубах концентрация гипотетического красителя, введенного в ток жидкости будет распределяться\n",
      "симметрично, но, при переходе к квадратному сечению, эта симметрия исказится.\n",
      "Авторы выяснили, что симметричным потоком, аналогичным у круглых труб, будут\n",
      "обладать каналы прямоугольной формы с примерным соотношением ширины и высоты\n",
      "два к одному. Исследование опубликовано в журнале Physical Review Letters, кратко о нем рассказывает журнал Physics.\n",
      "Авторы работы проводили компьютерное моделирование того, как\n",
      "будет меняться форма плоской прослойки красителя при движении по трубе. Из-за\n",
      "того, что скорость потока в центре, например, круглой трубы, выше, чем  ее стенок, будет наблюдаться «выпучивание»\n",
      "центральной части прослойки. Важным параметром, за которым следили\n",
      "исследователи, была так называемая «скошенность», определявшая меру\n",
      "несимметричности распределения красителя. \n",
      "Этот параметр определял то, насколько равномерно распределялось вещество в потоке. К примеру, большая отрицательная «скошенность» приводила к\n",
      "появлению большого хвоста позади основной массы условного красителя. В то же время\n",
      "положительная «скошенность» приводила к медленному постепенному нарастанию концентрации красителя\n",
      "вдоль трубы, благодаря большой доле вещества, «обогнавшего» прослойку, но подразумевала отсутствие хвоста.\n",
      "Оказалось что как эллиптические, так и круглые трубы\n",
      "обладают практически нулевой «скошенностью» — вещество в такой трубе выливалось\n",
      "бы с равномерно нарастающей и падающей концентрацией. Вместе с тем,\n",
      "симметричной скошенностью среди «угловатых», как оказалось, обладают не\n",
      "квадратные, а прямоугольные каналы, отношение ширины и высоты в которых равны\n",
      "1.87:1. \n",
      "Знание того, как вещество распределяется в каналах важно не\n",
      "только с фундаментальной точки зрения. Например, в химических реакторах важно точно знать какие концентрации веществ попадают в реакционную смесь. Эти приборы могут требовать либо постепенного, либо резкого ввода реагентов, что, как показала новая работа, можно контролировать с  помощью формы сечения труб.Владимир Королёв\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(dataset_folder, files[1000]), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поднимем в память датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for f in files:\n",
    "    with open(os.path.join(dataset_folder, f), 'r') as fo:\n",
    "        texts.append(fo.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Группа китайских археологов подняла новые фрагменты останков бронепалубного крейсера «Чжиюань», затонувшего в 1894 году в Желтом море в ходе Японо-китайской войны. Об этом сообщает China News Service.Останки крейсера находятся в 59 километрах от устья реки Ялуцзян, неподалеку от городского округа Даньдун в провинции Ляонин. Всего со дна Желтого моря археологи подняли на поверхность останки тел семерых членов экипажа и около ста артефактов, включающих в себя детали орудийных установок крейсера, фрагменты обшивки и личные предметы матросов. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(texts[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(t):\n",
    "    t = str(t).lower()\n",
    "    t = t.replace('\\n', ' ')\n",
    "    t = t.replace('.', '. ')\n",
    "    t = t.replace(',', ', ')\n",
    "    t = t.replace('xa0', ' ')\n",
    "        \n",
    "    return ' '.join(re.findall('[a-zа-яё]+', t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_cleared = [clear_text(t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'первый полностью укомплектованный всеми системами прототип перспективного американского самолета заправщика kc a pegasus совершил первый полет как сообщает defense news первый полет состоялся вечером сентября года на аэродроме концерна boeing в сиэтле в воздухе на самолете была проверена работа двигателей систем управления и систем создания искусственного климата в герметизированных отсеках общая продолжительность полета составила четыре часа в ближайшее время boeing занимающийся разработкой kc a намерен провести еще несколько испытательных полетов танкера в ходе которых он будет выпускать заправочную штангу и шланги будет проверяться влияние этих систем перекачки топлива на управляемость самолета затем данные предварительных испытаний прототипов будут переданы ввс сша а после этого транспортник будет участвовать в проверках на дозаправку других летательных аппаратов разработка kc a ведется на базе перспективного гражданского грузового самолета boeing c с года на танкер будут установлены полностью цифровые кабина пилотов и место оператора заправочного оборудования самолет сможет развивать скорость до километров в час и совершать полеты на расстояние до тысячи километров kc a сможет перевозить до тонн топлива действующим графиком предусмотрено строительство новых самолетов заправщиков к августу года поскольку разработка kc a ведется с использованием уже существующих технологий в рамках проектах прототипы танкера совершали несколько первых полетов в разном оснащении так в декабре года в воздух впервые поднялся самолет b c планер танкера без каких либо специальных систем строительство этого самолета велось с конца года в июне года первый полет совершил b c с системами дозаправки правильным первым полетом следует считать сентябрьский года прототип собран полностью'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_cleared[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lens = [len(t.split()) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(text_lens, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'на сайте nasa началась прямая трансляция шестичасового выхода в открытый космос членов экипажа мкс командир экипажа геннадий падалка и бортинженер михаил корниенко покинут шлюз в по московскому времени космонавты займутся инспекцией обшивки международной космической станции и монтажом вспомогательных мостков на обшивке станции для облегчения будущих выходов в космос также членам экипажа предстоит снять данные с оборудования установленного на мкс в рамках эксперимента обстановка произвести монтаж новой телекоммуникационной антенны и очистить от налета иллюминаторы служебного модуля звезда для бортинженера михаил корниенко это второй выход в открытый космос а для командира экипажа мкс уже десятый геннадий падалка провел в открытом космосе больше времени чем любой космонавт в истории'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_cleared[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_tokenized = [t.split() for t in texts_cleared]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['международная',\n",
       " 'группа',\n",
       " 'исследователей',\n",
       " 'разработала',\n",
       " 'метод',\n",
       " 'аутентификации',\n",
       " 'при',\n",
       " 'помощи',\n",
       " 'данных',\n",
       " 'об',\n",
       " 'использовании',\n",
       " 'смартфона',\n",
       " 'статья',\n",
       " 'опубликована',\n",
       " 'в',\n",
       " 'acm',\n",
       " 'digital',\n",
       " 'library',\n",
       " 'система',\n",
       " 'получившая',\n",
       " 'имя',\n",
       " 'activpass',\n",
       " 'анализирует',\n",
       " 'на',\n",
       " 'телефоне',\n",
       " 'пользователя',\n",
       " 'историю',\n",
       " 'браузера',\n",
       " 'посты',\n",
       " 'на',\n",
       " 'facebook',\n",
       " 'и',\n",
       " 'sms',\n",
       " 'сообщения',\n",
       " 'и',\n",
       " 'использует',\n",
       " 'полученные',\n",
       " 'данные',\n",
       " 'для',\n",
       " 'того',\n",
       " 'чтобы',\n",
       " 'задавать',\n",
       " 'вопросы',\n",
       " 'при',\n",
       " 'аутентификации',\n",
       " 'на',\n",
       " 'некоторых',\n",
       " 'сервисах',\n",
       " 'и',\n",
       " 'сайтах',\n",
       " 'например',\n",
       " 'система',\n",
       " 'может',\n",
       " 'поинтересоваться',\n",
       " 'кому',\n",
       " 'первому',\n",
       " 'сегодня',\n",
       " 'отправлено',\n",
       " 'sms',\n",
       " 'с',\n",
       " 'телефона',\n",
       " 'всего',\n",
       " 'для',\n",
       " 'успешного',\n",
       " 'логина',\n",
       " 'нужно',\n",
       " 'ответить',\n",
       " 'на',\n",
       " 'три',\n",
       " 'вопроса',\n",
       " 'связанных',\n",
       " 'с',\n",
       " 'недавними',\n",
       " 'действиями',\n",
       " 'пользователя',\n",
       " 'в',\n",
       " 'смартфоне',\n",
       " 'когда',\n",
       " 'вы',\n",
       " 'что',\n",
       " 'то',\n",
       " 'делаете',\n",
       " 'через',\n",
       " 'свой',\n",
       " 'смартфон',\n",
       " 'это',\n",
       " 'известно',\n",
       " 'только',\n",
       " 'вам',\n",
       " 'и',\n",
       " 'телефону',\n",
       " 'именно',\n",
       " 'поэтому',\n",
       " 'такие',\n",
       " 'данные',\n",
       " 'можно',\n",
       " 'использовать',\n",
       " 'для',\n",
       " 'аутентификации',\n",
       " 'объясняет',\n",
       " 'рой',\n",
       " 'чоудхури',\n",
       " 'один',\n",
       " 'из',\n",
       " 'соавторов',\n",
       " 'исследования']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tokenized[-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stop_words.txt', 'r') as f:\n",
    "    stop_words = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_ = \"\"\"или, но, дабы, затем, потом, лишь только, он, мы, его, вы, вам, вас, ее, что, \n",
    "который, их, все, они, я, весь, мне, меня, таким, для, на, по, со, из, от, до, без, над, под, за, при, после, во,\n",
    "же, то, бы, всего, итого, даже, да, нет, ой, ого, эх, браво, здравствуйте, спасибо, извините,\n",
    "скажем, может, допустим, честно говоря, например, на самом деле, однако, вообще, в, общем, вероятно, очень, \n",
    "минимально, максимально, абсолютно, огромный, предельно, сильно, слабо, самый, сайт, давать, всегда, однако, и, а, но, да, если, что, когда, потому, что, так, как, как, будто, \n",
    "вследствие, того, что, с, тех, пор, как, в, то, время, как, для, того, чтобы, ни, то, ли, но, зато, от, и, к, the\"\"\"\n",
    "\n",
    "stop_words_1  = set(stop_words + stop_words_.replace('\\n','').split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'the',\n",
       " 'а',\n",
       " 'абсолютно',\n",
       " 'без',\n",
       " 'более',\n",
       " 'больше',\n",
       " 'браво',\n",
       " 'буд',\n",
       " 'будет',\n",
       " 'будто',\n",
       " 'бы',\n",
       " 'быв',\n",
       " 'был',\n",
       " 'была',\n",
       " 'были',\n",
       " 'было',\n",
       " 'быть',\n",
       " 'в',\n",
       " 'вам',\n",
       " 'вами',\n",
       " 'вас',\n",
       " 'вдруг',\n",
       " 'ведь',\n",
       " 'вероятно',\n",
       " 'весь',\n",
       " 'во',\n",
       " 'во,же',\n",
       " 'вообще',\n",
       " 'вот',\n",
       " 'впрочем',\n",
       " 'время',\n",
       " 'все',\n",
       " 'всегда',\n",
       " 'всего',\n",
       " 'всей',\n",
       " 'всем',\n",
       " 'всеми',\n",
       " 'всему',\n",
       " 'всех',\n",
       " 'всею',\n",
       " 'вследствие',\n",
       " 'всю',\n",
       " 'вся',\n",
       " 'вы',\n",
       " 'где',\n",
       " 'говорил',\n",
       " 'да',\n",
       " 'дабы',\n",
       " 'давать',\n",
       " 'даже',\n",
       " 'два',\n",
       " 'дел',\n",
       " 'для',\n",
       " 'до',\n",
       " 'долж',\n",
       " 'допустим',\n",
       " 'другой',\n",
       " 'его',\n",
       " 'ее',\n",
       " 'ей',\n",
       " 'ему',\n",
       " 'если',\n",
       " 'есть',\n",
       " 'еще',\n",
       " 'ею',\n",
       " 'ж',\n",
       " 'же',\n",
       " 'жизнь',\n",
       " 'за',\n",
       " 'затем',\n",
       " 'зато',\n",
       " 'зачем',\n",
       " 'здесь',\n",
       " 'здравствуйте',\n",
       " 'и',\n",
       " 'из',\n",
       " 'извините,скажем',\n",
       " 'извинитескажем',\n",
       " 'или',\n",
       " 'им',\n",
       " 'име',\n",
       " 'ими',\n",
       " 'иногда',\n",
       " 'итого',\n",
       " 'их',\n",
       " 'к',\n",
       " 'кажется',\n",
       " 'как',\n",
       " 'какая',\n",
       " 'какой',\n",
       " 'когда',\n",
       " 'конечно',\n",
       " 'который',\n",
       " 'кто',\n",
       " 'куда',\n",
       " 'ли',\n",
       " 'лишь только',\n",
       " 'лучше',\n",
       " 'максимально',\n",
       " 'между',\n",
       " 'меня',\n",
       " 'минимально',\n",
       " 'мне',\n",
       " 'много',\n",
       " 'мной',\n",
       " 'мною',\n",
       " 'мог',\n",
       " 'мож',\n",
       " 'может',\n",
       " 'можн',\n",
       " 'можно',\n",
       " 'мой',\n",
       " 'мочь',\n",
       " 'моя',\n",
       " 'мы',\n",
       " 'на',\n",
       " 'на самом деле',\n",
       " 'над',\n",
       " 'надо',\n",
       " 'наконец',\n",
       " 'нам',\n",
       " 'нами',\n",
       " 'например',\n",
       " 'нас',\n",
       " 'находится',\n",
       " 'не',\n",
       " 'него',\n",
       " 'нее',\n",
       " 'ней',\n",
       " 'нельзя',\n",
       " 'нему',\n",
       " 'нет',\n",
       " 'нею',\n",
       " 'ни',\n",
       " 'нибудь',\n",
       " 'никогда',\n",
       " 'ним',\n",
       " 'ними',\n",
       " 'них',\n",
       " 'ничего',\n",
       " 'но',\n",
       " 'ну',\n",
       " 'нужн',\n",
       " 'нэи',\n",
       " 'о',\n",
       " 'об',\n",
       " 'общем',\n",
       " 'ого',\n",
       " 'огромный',\n",
       " 'один',\n",
       " 'однако',\n",
       " 'ой',\n",
       " 'он',\n",
       " 'она',\n",
       " 'они',\n",
       " 'оно',\n",
       " 'опять',\n",
       " 'от',\n",
       " 'очень',\n",
       " 'перед',\n",
       " 'по',\n",
       " 'под',\n",
       " 'пор',\n",
       " 'после',\n",
       " 'потом',\n",
       " 'потому',\n",
       " 'почему',\n",
       " 'почти',\n",
       " 'предельно',\n",
       " 'при',\n",
       " 'про',\n",
       " 'раз',\n",
       " 'разве',\n",
       " 'с',\n",
       " 'сайт',\n",
       " 'сам',\n",
       " 'сама',\n",
       " 'сами',\n",
       " 'самим',\n",
       " 'самими',\n",
       " 'самих',\n",
       " 'само',\n",
       " 'самого',\n",
       " 'самой',\n",
       " 'самом',\n",
       " 'самому',\n",
       " 'самою',\n",
       " 'саму',\n",
       " 'самый',\n",
       " 'свой',\n",
       " 'свою',\n",
       " 'себе',\n",
       " 'себя',\n",
       " 'сегодня',\n",
       " 'сейчас',\n",
       " 'сильно',\n",
       " 'сказал',\n",
       " 'сказала',\n",
       " 'сказать',\n",
       " 'слабо',\n",
       " 'со',\n",
       " 'собой',\n",
       " 'собою',\n",
       " 'совсем',\n",
       " 'спасибо',\n",
       " 'суть',\n",
       " 'та',\n",
       " 'так',\n",
       " 'такая',\n",
       " 'такие',\n",
       " 'таким',\n",
       " 'такое',\n",
       " 'такой',\n",
       " 'там',\n",
       " 'те',\n",
       " 'тебе',\n",
       " 'тебя',\n",
       " 'тем',\n",
       " 'теми',\n",
       " 'теперь',\n",
       " 'тех',\n",
       " 'то',\n",
       " 'тобой',\n",
       " 'тобою',\n",
       " 'тогда',\n",
       " 'того',\n",
       " 'тоже',\n",
       " 'той',\n",
       " 'только',\n",
       " 'том',\n",
       " 'тому',\n",
       " 'тот',\n",
       " 'тою',\n",
       " 'три',\n",
       " 'ту',\n",
       " 'тут',\n",
       " 'ты',\n",
       " 'у',\n",
       " 'уж',\n",
       " 'уже',\n",
       " 'уме',\n",
       " 'хорошо',\n",
       " 'хот',\n",
       " 'хоть',\n",
       " 'хоч',\n",
       " 'чего',\n",
       " 'человек',\n",
       " 'чем',\n",
       " 'через',\n",
       " 'честно говоря',\n",
       " 'что',\n",
       " 'чтоб',\n",
       " 'чтобы',\n",
       " 'чуть',\n",
       " 'эта',\n",
       " 'эти',\n",
       " 'этим',\n",
       " 'этими',\n",
       " 'этих',\n",
       " 'это',\n",
       " 'этого',\n",
       " 'этой',\n",
       " 'этом',\n",
       " 'этому',\n",
       " 'этот',\n",
       " 'этою',\n",
       " 'эту',\n",
       " 'эх',\n",
       " 'я'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(100000)\n",
    "def lemmatize(s):\n",
    "    s = str(s).lower()\n",
    "    return morph.parse(s)[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'кошка'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse('кошки')[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 7696/7696 [00:35<00:00, 214.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.2 s, sys: 391 ms, total: 35.6 s\n",
      "Wall time: 35.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "texts_tokenized_1 = [[lemmatize(tt) for tt in t if len(tt) > 1] \n",
    "                     for t in tqdm(texts_tokenized)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_tokenized_1 = [[tt for tt in t if tt not in stop_words_1] \n",
    "                     for t in texts_tokenized_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['международный',\n",
       " 'группа',\n",
       " 'исследователь',\n",
       " 'разработать',\n",
       " 'метод',\n",
       " 'аутентификация',\n",
       " 'помощь',\n",
       " 'данные',\n",
       " 'использование',\n",
       " 'смартфон',\n",
       " 'статья',\n",
       " 'опубликовать',\n",
       " 'acm',\n",
       " 'digital',\n",
       " 'library',\n",
       " 'система',\n",
       " 'получить',\n",
       " 'имя',\n",
       " 'activpass',\n",
       " 'анализировать',\n",
       " 'телефон',\n",
       " 'пользователь',\n",
       " 'история',\n",
       " 'браузер',\n",
       " 'пост',\n",
       " 'facebook',\n",
       " 'sms',\n",
       " 'сообщение',\n",
       " 'использовать',\n",
       " 'получить',\n",
       " 'дать',\n",
       " 'задавать',\n",
       " 'вопрос',\n",
       " 'аутентификация',\n",
       " 'некоторый',\n",
       " 'сервис',\n",
       " 'система',\n",
       " 'поинтересоваться',\n",
       " 'первый',\n",
       " 'отправить',\n",
       " 'sms',\n",
       " 'телефон',\n",
       " 'успешный',\n",
       " 'логин',\n",
       " 'нужно',\n",
       " 'ответить',\n",
       " 'вопрос',\n",
       " 'связанный',\n",
       " 'недавний',\n",
       " 'действие',\n",
       " 'пользователь',\n",
       " 'смартфон',\n",
       " 'делать',\n",
       " 'смартфон',\n",
       " 'известно',\n",
       " 'телефон',\n",
       " 'именно',\n",
       " 'поэтому',\n",
       " 'дать',\n",
       " 'использовать',\n",
       " 'аутентификация',\n",
       " 'объяснять',\n",
       " 'рой',\n",
       " 'чоудхурить',\n",
       " 'соавтор',\n",
       " 'исследование']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tokenized_1[-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'получить'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize('полученные')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = texts_tokenized_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phrases(docs, min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['международный',\n",
       " 'группа',\n",
       " 'исследователь',\n",
       " 'разработать',\n",
       " 'метод',\n",
       " 'аутентификация',\n",
       " 'помощь',\n",
       " 'данные',\n",
       " 'использование',\n",
       " 'смартфон',\n",
       " 'статья',\n",
       " 'опубликовать',\n",
       " 'acm',\n",
       " 'digital',\n",
       " 'library',\n",
       " 'система',\n",
       " 'получить',\n",
       " 'имя',\n",
       " 'activpass',\n",
       " 'анализировать',\n",
       " 'телефон',\n",
       " 'пользователь',\n",
       " 'история',\n",
       " 'браузер',\n",
       " 'пост',\n",
       " 'facebook',\n",
       " 'sms',\n",
       " 'сообщение',\n",
       " 'использовать',\n",
       " 'получить',\n",
       " 'дать',\n",
       " 'задавать',\n",
       " 'вопрос',\n",
       " 'аутентификация',\n",
       " 'некоторый',\n",
       " 'сервис',\n",
       " 'система',\n",
       " 'поинтересоваться',\n",
       " 'первый',\n",
       " 'отправить',\n",
       " 'sms',\n",
       " 'телефон',\n",
       " 'успешный',\n",
       " 'логин',\n",
       " 'нужно',\n",
       " 'ответить',\n",
       " 'вопрос',\n",
       " 'связанный',\n",
       " 'недавний',\n",
       " 'действие',\n",
       " 'пользователь',\n",
       " 'смартфон',\n",
       " 'делать',\n",
       " 'смартфон',\n",
       " 'известно',\n",
       " 'телефон',\n",
       " 'именно',\n",
       " 'поэтому',\n",
       " 'дать',\n",
       " 'использовать',\n",
       " 'аутентификация',\n",
       " 'объяснять',\n",
       " 'рой',\n",
       " 'чоудхурить',\n",
       " 'соавтор',\n",
       " 'исследование',\n",
       " 'международный_группа',\n",
       " 'разработать_метод',\n",
       " 'статья_опубликовать',\n",
       " 'получить_имя',\n",
       " 'получить_дать',\n",
       " 'ответить_вопрос']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nМеждународная группа исследователей разработала метод аутентификации при помощи данных об использовании смартфона.\\nСтатья опубликована в ACM Digital Library.\\nСистема,\\nполучившая имя ActivPass, анализирует на\\nтелефоне пользователя историю браузера,\\nпосты на facebook и SMS-сообщения и использует\\nполученные данные для того, чтобы\\nзадавать вопросы при аутентификации\\nна некоторых сервисах и сайтах. Например,\\nсистема может поинтересоваться, кому\\nпервому сегодня отправлено SMS с телефона.\\nВсего для успешного логина нужно ответить\\nна три вопроса, связанных с недавними\\nдействиями пользователя в смартфоне.\\n        «Когда вы что-то делаете через свой смартфон, это известно только вам и телефону, именно поэтому такие данные можно использовать для аутентификации»,— объясняет Рой Чоудхури, один из соавторов исследования.\\n    \\n'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=10, no_above=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token2id': {'boeing': 0,\n",
       "  'defense': 1,\n",
       "  'kc': 2,\n",
       "  'news': 3,\n",
       "  'pegasus': 4,\n",
       "  'август': 5,\n",
       "  'август_год': 6,\n",
       "  'американский': 7,\n",
       "  'аппарат': 8,\n",
       "  'аэродром': 9,\n",
       "  'база': 10,\n",
       "  'близкий': 11,\n",
       "  'ввс': 12,\n",
       "  'ввс_сша': 13,\n",
       "  'вестись': 14,\n",
       "  'вечером': 15,\n",
       "  'влияние': 16,\n",
       "  'воздух': 17,\n",
       "  'впервые': 18,\n",
       "  'выпускать': 19,\n",
       "  'гражданский': 20,\n",
       "  'график': 21,\n",
       "  'грузовой': 22,\n",
       "  'грузовой_самолёт': 23,\n",
       "  'дать': 24,\n",
       "  'двигатель': 25,\n",
       "  'действовать': 26,\n",
       "  'декабрь': 27,\n",
       "  'декабрь_год': 28,\n",
       "  'дозаправка': 29,\n",
       "  'ещё': 30,\n",
       "  'ещё_несколько': 31,\n",
       "  'заниматься': 32,\n",
       "  'заниматься_разработка': 33,\n",
       "  'заправочный': 34,\n",
       "  'заправочный_штанга': 35,\n",
       "  'заправщик': 36,\n",
       "  'искусственный': 37,\n",
       "  'использование': 38,\n",
       "  'испытание': 39,\n",
       "  'испытание_прототип': 40,\n",
       "  'испытательный': 41,\n",
       "  'испытательный_полёт': 42,\n",
       "  'июнь': 43,\n",
       "  'июнь_год': 44,\n",
       "  'кабина': 45,\n",
       "  'кабина_пилот': 46,\n",
       "  'километр': 47,\n",
       "  'климат': 48,\n",
       "  'конец': 49,\n",
       "  'конец_год': 50,\n",
       "  'концерн': 51,\n",
       "  'концерн_boeing': 52,\n",
       "  'летательный': 53,\n",
       "  'летательный_аппарат': 54,\n",
       "  'либо': 55,\n",
       "  'место': 56,\n",
       "  'намеренный': 57,\n",
       "  'несколько': 58,\n",
       "  'оборудование': 59,\n",
       "  'общий': 60,\n",
       "  'оператор': 61,\n",
       "  'оснащение': 62,\n",
       "  'отсек': 63,\n",
       "  'первый_полёт': 64,\n",
       "  'перевозить': 65,\n",
       "  'передать': 66,\n",
       "  'перспективный': 67,\n",
       "  'пилот': 68,\n",
       "  'планер': 69,\n",
       "  'подняться': 70,\n",
       "  'полностью': 71,\n",
       "  'полёт': 72,\n",
       "  'полёт_расстояние': 73,\n",
       "  'поскольку': 74,\n",
       "  'правильный': 75,\n",
       "  'предварительный': 76,\n",
       "  'предусмотреть': 77,\n",
       "  'проверить': 78,\n",
       "  'проверка': 79,\n",
       "  'проверяться': 80,\n",
       "  'провести': 81,\n",
       "  'продолжительность': 82,\n",
       "  'продолжительность_полёт': 83,\n",
       "  'проект': 84,\n",
       "  'прототип': 85,\n",
       "  'развивать': 86,\n",
       "  'разный': 87,\n",
       "  'разработка': 88,\n",
       "  'рамка': 89,\n",
       "  'рамка_проект': 90,\n",
       "  'расстояние': 91,\n",
       "  'самолёт': 92,\n",
       "  'самолёт_заправщик': 93,\n",
       "  'сентябрь': 94,\n",
       "  'сентябрь_год': 95,\n",
       "  'сентябрьский': 96,\n",
       "  'система_управление': 97,\n",
       "  'сиэтл': 98,\n",
       "  'скорость': 99,\n",
       "  'скорость_километр': 100,\n",
       "  'следовать': 101,\n",
       "  'смочь': 102,\n",
       "  'смочь_перевозить': 103,\n",
       "  'смочь_развивать': 104,\n",
       "  'собранный': 105,\n",
       "  'совершать': 106,\n",
       "  'совершить': 107,\n",
       "  'совершить_первый': 108,\n",
       "  'создание': 109,\n",
       "  'сообщать_defense': 110,\n",
       "  'составить': 111,\n",
       "  'состояться': 112,\n",
       "  'специальный': 113,\n",
       "  'строительство': 114,\n",
       "  'существующий': 115,\n",
       "  'считать': 116,\n",
       "  'сша': 117,\n",
       "  'танкер': 118,\n",
       "  'технология': 119,\n",
       "  'тонна': 120,\n",
       "  'топливо': 121,\n",
       "  'транспортник': 122,\n",
       "  'тысяча': 123,\n",
       "  'тысяча_километр': 124,\n",
       "  'управление': 125,\n",
       "  'управляемость': 126,\n",
       "  'установить': 127,\n",
       "  'участвовать': 128,\n",
       "  'ход': 129,\n",
       "  'цифровой': 130,\n",
       "  'час': 131,\n",
       "  'час_совершать': 132,\n",
       "  'четыре': 133,\n",
       "  'четыре_час': 134,\n",
       "  'шланг': 135,\n",
       "  'штанга': 136,\n",
       "  'applied': 137,\n",
       "  'letters': 138,\n",
       "  'physics': 139,\n",
       "  'автор': 140,\n",
       "  'акустический': 141,\n",
       "  'благодаря': 142,\n",
       "  'борозда': 143,\n",
       "  'вещество': 144,\n",
       "  'возникать': 145,\n",
       "  'волна': 146,\n",
       "  'глубина': 147,\n",
       "  'гребень': 148,\n",
       "  'диод': 149,\n",
       "  'единый': 150,\n",
       "  'журнал': 151,\n",
       "  'журнал_applied': 152,\n",
       "  'зависеть': 153,\n",
       "  'звук': 154,\n",
       "  'звуковой': 155,\n",
       "  'звуковой_волна': 156,\n",
       "  'инженер': 157,\n",
       "  'исследование_опубликовать': 158,\n",
       "  'каждый': 159,\n",
       "  'канал': 160,\n",
       "  'класс': 161,\n",
       "  'ключевой': 162,\n",
       "  'ключевой_особенность': 163,\n",
       "  'лишь': 164,\n",
       "  'материал': 165,\n",
       "  'метаматериал': 166,\n",
       "  'напечатать': 167,\n",
       "  'направление': 168,\n",
       "  'недавно': 169,\n",
       "  'обратный': 170,\n",
       "  'объединить': 171,\n",
       "  'обычный': 172,\n",
       "  'особенность': 173,\n",
       "  'очередь': 174,\n",
       "  'первый_очередь': 175,\n",
       "  'передаваться': 176,\n",
       "  'постепенно': 177,\n",
       "  'представлять': 178,\n",
       "  'принтер': 179,\n",
       "  'прозрачный': 180,\n",
       "  'пропускать': 181,\n",
       "  'прямой': 182,\n",
       "  'равный': 183,\n",
       "  'различаться': 184,\n",
       "  'различие': 185,\n",
       "  'разработать': 186,\n",
       "  'сантиметр': 187,\n",
       "  'свет': 188,\n",
       "  'свободно': 189,\n",
       "  'свойство': 190,\n",
       "  'сделать': 191,\n",
       "  'соответственно': 192,\n",
       "  'состоять': 193,\n",
       "  'тепло': 194,\n",
       "  'увеличиваться': 195,\n",
       "  'университет': 196,\n",
       "  'устройство': 197,\n",
       "  'фиксировать': 198,\n",
       "  'форма': 199,\n",
       "  'часть': 200,\n",
       "  'являться': 201,\n",
       "  'cubesat': 202,\n",
       "  'lightsail': 203,\n",
       "  'автоматизировать': 204,\n",
       "  'активность': 205,\n",
       "  'аналогичный': 206,\n",
       "  'батарея': 207,\n",
       "  'блог': 208,\n",
       "  'бортовый': 209,\n",
       "  'бортовый_компьютер': 210,\n",
       "  'версия': 211,\n",
       "  'внесение': 212,\n",
       "  'вновь': 213,\n",
       "  'внутренний': 214,\n",
       "  'возможность': 215,\n",
       "  'восточный': 216,\n",
       "  'всё': 217,\n",
       "  'вызвать': 218,\n",
       "  'выполнить': 219,\n",
       "  'выпуск': 220,\n",
       "  'высокоэнергетичный': 221,\n",
       "  'гигабайт': 222,\n",
       "  'главный': 223,\n",
       "  'группа': 224,\n",
       "  'данные': 225,\n",
       "  'данный': 226,\n",
       "  'данный_момент': 227,\n",
       "  'день': 228,\n",
       "  'джейсон': 229,\n",
       "  'дэвис': 230,\n",
       "  'единственный': 231,\n",
       "  'загрузка': 232,\n",
       "  'записываться': 233,\n",
       "  'запланировать': 234,\n",
       "  'запуск': 235,\n",
       "  'запустить': 236,\n",
       "  'заряд': 237,\n",
       "  'заряд_батарея': 238,\n",
       "  'земля': 239,\n",
       "  'зонд': 240,\n",
       "  'имя': 241,\n",
       "  'информация': 242,\n",
       "  'исследовательский': 243,\n",
       "  'исследовательский_группа': 244,\n",
       "  'июль': 245,\n",
       "  'июль_год': 246,\n",
       "  'калифорнийский': 247,\n",
       "  'клон': 248,\n",
       "  'компьютер': 249,\n",
       "  'корректировка': 250,\n",
       "  'космический': 251,\n",
       "  'космос': 252,\n",
       "  'линкольн': 253,\n",
       "  'май': 254,\n",
       "  'мегабайт': 255,\n",
       "  'миссия': 256,\n",
       "  'модуль': 257,\n",
       "  'момент': 258,\n",
       "  'наблюдаться': 259,\n",
       "  'набор': 260,\n",
       "  'набор_данные': 261,\n",
       "  'надежда': 262,\n",
       "  'наземный': 263,\n",
       "  'наземный_станция': 264,\n",
       "  'наступать': 265,\n",
       "  'находиться': 266,\n",
       "  'начать': 267,\n",
       "  'неделя': 268,\n",
       "  'некоторый': 269,\n",
       "  'немедленно': 270,\n",
       "  'необходимый': 271,\n",
       "  'неудача': 272,\n",
       "  'обеспечение': 273,\n",
       "  'обнаружить': 274,\n",
       "  'обнаружиться': 275,\n",
       "  'обновить': 276,\n",
       "  'обновление': 277,\n",
       "  'оболочка': 278,\n",
       "  'общество': 279,\n",
       "  'ожидание': 280,\n",
       "  'организация': 281,\n",
       "  'орегон': 282,\n",
       "  'основа': 283,\n",
       "  'основный': 284,\n",
       "  'основный_часть': 285,\n",
       "  'отклик': 286,\n",
       "  'отправлять': 287,\n",
       "  'отправляться': 288,\n",
       "  'ошибка': 289,\n",
       "  'пакет': 290,\n",
       "  'парус': 291,\n",
       "  'перейти': 292,\n",
       "  'перестать': 293,\n",
       "  'период': 294,\n",
       "  'планетарный': 295,\n",
       "  'подать': 296,\n",
       "  'подготовить': 297,\n",
       "  'политехнический': 298,\n",
       "  'положение': 299,\n",
       "  'попадание': 300,\n",
       "  'попытка': 301,\n",
       "  'порядок': 302,\n",
       "  'последний': 303,\n",
       "  'потеря': 304,\n",
       "  'превышение': 305,\n",
       "  'прежде': 306,\n",
       "  'прибор': 307,\n",
       "  'привести': 308,\n",
       "  'принять': 309,\n",
       "  'причина': 310,\n",
       "  'программа': 311,\n",
       "  'программист': 312,\n",
       "  'программный': 313,\n",
       "  'программный_обеспечение': 314,\n",
       "  'произойти': 315,\n",
       "  'происходить': 316,\n",
       "  'пролёт': 317,\n",
       "  'протестировать': 318,\n",
       "  'протяжение': 319,\n",
       "  'протяжение_последний': 320,\n",
       "  'прохождение': 321,\n",
       "  'процесс': 322,\n",
       "  'пытаться': 323,\n",
       "  'пятница': 324,\n",
       "  'пять': 325,\n",
       "  'пять_день': 326,\n",
       "  'работать': 327,\n",
       "  'радиопередатчик': 328,\n",
       "  'радиостанция': 329,\n",
       "  'разговаривать': 330,\n",
       "  'различный': 331,\n",
       "  'размер': 332,\n",
       "  'разумеется': 333,\n",
       "  'ранний': 334,\n",
       "  'редактор': 335,\n",
       "  'редактор_планетарный': 336,\n",
       "  'режим': 337,\n",
       "  'ручной': 338,\n",
       "  'связанный': 339,\n",
       "  'связь': 340,\n",
       "  'североамериканский': 341,\n",
       "  'секунда': 342,\n",
       "  'серия': 343,\n",
       "  'сигнал': 344,\n",
       "  'следующий': 345,\n",
       "  'слово': 346,\n",
       "  'собирать': 347,\n",
       "  'собрат': 348,\n",
       "  'собрать': 349,\n",
       "  'событие': 350,\n",
       "  'совместно': 351,\n",
       "  'сожаление': 352,\n",
       "  'солнечный': 353,\n",
       "  'солнечный_парус': 354,\n",
       "  'сообщать_блог': 355,\n",
       "  'состояние': 356,\n",
       "  'сотрудник': 357,\n",
       "  'сотрудник_калифорнийский': 358,\n",
       "  'спонтанный': 359,\n",
       "  'спустя': 360,\n",
       "  'спустя_неделя': 361,\n",
       "  'спутник': 362,\n",
       "  'среднее': 363,\n",
       "  'станция': 364,\n",
       "  'стать': 365,\n",
       "  'стать_первый': 366,\n",
       "  'сумма': 367,\n",
       "  'тестовый': 368,\n",
       "  'требовать': 369,\n",
       "  'третий': 370,\n",
       "  'тщательно': 371,\n",
       "  'тяга': 372,\n",
       "  'удаться': 373,\n",
       "  'уровень': 374,\n",
       "  'услышать': 375,\n",
       "  'успешно': 376,\n",
       "  'успешный': 377,\n",
       "  'уточнять': 378,\n",
       "  'учесть': 379,\n",
       "  'файл': 380,\n",
       "  'функционировать': 381,\n",
       "  'частица': 382,\n",
       "  'часто': 383,\n",
       "  'штат': 384,\n",
       "  'cd': 385,\n",
       "  'lancet': 386,\n",
       "  'агрессивный': 387,\n",
       "  'атаковать': 388,\n",
       "  'атрофия': 389,\n",
       "  'аутоиммунный': 390,\n",
       "  'больной': 391,\n",
       "  'вернуться': 392,\n",
       "  'вид': 393,\n",
       "  'видимый': 394,\n",
       "  'возраст': 395,\n",
       "  'возраст_год': 396,\n",
       "  'волокно': 397,\n",
       "  'воспалительный': 398,\n",
       "  'восстановить': 399,\n",
       "  'выжить': 400,\n",
       "  'вызывающий': 401,\n",
       "  'выявить': 402,\n",
       "  'дальнейший': 403,\n",
       "  'двигательный': 404,\n",
       "  'движение': 405,\n",
       "  'диагноз': 406,\n",
       "  'длительный': 407,\n",
       "  'длиться': 408,\n",
       "  'доброволец': 409,\n",
       "  'дополнительный': 410,\n",
       "  'заболевание': 411,\n",
       "  'забрать': 412,\n",
       "  'здоровый': 413,\n",
       "  'зрение': 414,\n",
       "  'иммунитет': 415,\n",
       "  'иммунный': 416,\n",
       "  'иммунный_клетка': 417,\n",
       "  'институт': 418,\n",
       "  'интенсивный': 419,\n",
       "  'инфекционный': 420,\n",
       "  'исследователь': 421,\n",
       "  'исследовательский_институт': 422,\n",
       "  'канадский': 423,\n",
       "  'клетка': 424,\n",
       "  'клетка_предшественница': 425,\n",
       "  'клинический': 426,\n",
       "  'клинический_испытание': 427,\n",
       "  'коллега': 428,\n",
       "  'конечный': 429,\n",
       "  'конечный_точка': 430,\n",
       "  'координация': 431,\n",
       "  'лечение': 432,\n",
       "  'лихорадка': 433,\n",
       "  'лищука': 434,\n",
       "  'максимум': 435,\n",
       "  'методика': 436,\n",
       "  'мозг': 437,\n",
       "  'мозговой': 438,\n",
       "  'мозговой_ткань': 439,\n",
       "  'мрт': 440,\n",
       "  'мышечный': 441,\n",
       "  'наблюдение': 442,\n",
       "  'нарушение': 443,\n",
       "  'научно': 444,\n",
       "  'необходимо': 445,\n",
       "  'нервный': 446,\n",
       "  'нервный_волокно': 447,\n",
       "  'нервный_система': 448,\n",
       "  'несмотря': 449,\n",
       "  'низкий': 450,\n",
       "  'олег': 451,\n",
       "  'олег_лищука': 452,\n",
       "  'опубликовать_журнал': 453,\n",
       "  'организм': 454,\n",
       "  'органический': 455,\n",
       "  'осложнение': 456,\n",
       "  'отдел': 457,\n",
       "  'отделение': 458,\n",
       "  'открытый': 459,\n",
       "  'отмечать': 460,\n",
       "  'отчёт': 461,\n",
       "  'отчёт_работа': 462,\n",
       "  'пациент': 463,\n",
       "  'первичный': 464,\n",
       "  'передача': 465,\n",
       "  'печень': 466,\n",
       "  'писать': 467,\n",
       "  'плохой': 468,\n",
       "  'повод': 469,\n",
       "  'повреждение': 470,\n",
       "  'подобный': 471,\n",
       "  'польза': 472,\n",
       "  'понадобиться': 473,\n",
       "  'популяция': 474,\n",
       "  'поражение': 475,\n",
       "  'постановка': 476,\n",
       "  'потребность': 477,\n",
       "  'предшественница': 478,\n",
       "  'прекратить': 479,\n",
       "  'приводить': 480,\n",
       "  'приводить_нарушение': 481,\n",
       "  'признак': 482,\n",
       "  'принести': 483,\n",
       "  'принять_участие': 484,\n",
       "  'проведение': 485,\n",
       "  'прогноз': 486,\n",
       "  'прогрессирование': 487,\n",
       "  'процент': 488,\n",
       "  'проявление': 489,\n",
       "  'рассеянный': 490,\n",
       "  'рассеянный_склероз': 491,\n",
       "  'расширить': 492,\n",
       "  'результат': 493,\n",
       "  'сенсорный': 494,\n",
       "  'склероз': 495,\n",
       "  'слабость': 496,\n",
       "  'собственный': 497,\n",
       "  'сообщить': 498,\n",
       "  'соответствующий': 499,\n",
       "  'специфический': 500,\n",
       "  'стволовой': 501,\n",
       "  'стволовой_клетка': 502,\n",
       "  'структура': 503,\n",
       "  'суммарно': 504,\n",
       "  'терапия': 505,\n",
       "  'течение': 506,\n",
       "  'ткань': 507,\n",
       "  'точка': 508,\n",
       "  'трансплантация': 509,\n",
       "  'тяжёлый': 510,\n",
       "  'уменьшиться': 511,\n",
       "  'умереть': 512,\n",
       "  'уничтожение': 513,\n",
       "  'условие': 514,\n",
       "  'успех': 515,\n",
       "  'устойчивый': 516,\n",
       "  'уточнить': 517,\n",
       "  'утрата': 518,\n",
       "  'ухудшение': 519,\n",
       "  'ухудшение_зрение': 520,\n",
       "  'участие': 521,\n",
       "  'участник': 522,\n",
       "  'функция': 523,\n",
       "  'характерный': 524,\n",
       "  'хронический': 525,\n",
       "  'цель': 526,\n",
       "  'центр': 527,\n",
       "  'центральный': 528,\n",
       "  'центральный_нервный': 529,\n",
       "  'шкала': 530,\n",
       "  'экспериментальный': 531,\n",
       "  'of': 532,\n",
       "  'times': 533,\n",
       "  'world': 534,\n",
       "  'аббревиатура': 535,\n",
       "  'аспирант': 536,\n",
       "  'бизнес': 537,\n",
       "  'биотехнология': 538,\n",
       "  'великий': 539,\n",
       "  'всероссийский': 540,\n",
       "  'встретиться': 541,\n",
       "  'вуз': 542,\n",
       "  'входящий': 543,\n",
       "  'выведение': 544,\n",
       "  'гибкий': 545,\n",
       "  'государственный': 546,\n",
       "  'государственный_университет': 547,\n",
       "  'дмитрий': 548,\n",
       "  'допускаться': 549,\n",
       "  'европа': 550,\n",
       "  'естественно': 551,\n",
       "  'задача': 552,\n",
       "  'закрытый': 553,\n",
       "  'заявка': 554,\n",
       "  'иванов': 555,\n",
       "  'издание': 556,\n",
       "  'именно': 557,\n",
       "  'инженерный': 558,\n",
       "  'инновация': 559,\n",
       "  'информационный': 560,\n",
       "  'информационный_технология': 561,\n",
       "  'качество': 562,\n",
       "  'колледж': 563,\n",
       "  'комитет': 564,\n",
       "  'комната': 565,\n",
       "  'композитный': 566,\n",
       "  'композитный_материал': 567,\n",
       "  'конкурс': 568,\n",
       "  'крупный': 569,\n",
       "  'лаборатория': 570,\n",
       "  'механика': 571,\n",
       "  'минимум': 572,\n",
       "  'мировой': 573,\n",
       "  'московский': 574,\n",
       "  'найти': 575,\n",
       "  'найти_применение': 576,\n",
       "  'направить': 577,\n",
       "  'научный': 578,\n",
       "  'национальный': 579,\n",
       "  'область': 580,\n",
       "  'образование': 581,\n",
       "  'образовательный': 582,\n",
       "  'обучаться': 583,\n",
       "  'оптика': 584,\n",
       "  'организовать': 585,\n",
       "  'петербургский': 586,\n",
       "  'печать': 587,\n",
       "  'победитель': 588,\n",
       "  'повысить': 589,\n",
       "  'подаваться': 590,\n",
       "  'подать_заявка': 591,\n",
       "  'подготовка': 592,\n",
       "  'поддержка': 593,\n",
       "  'покрытие': 594,\n",
       "  'посещение': 595,\n",
       "  'предлагаться': 596,\n",
       "  'представитель': 597,\n",
       "  'престижный': 598,\n",
       "  'применение': 599,\n",
       "  'присоединиться': 600,\n",
       "  'приём': 601,\n",
       "  'проводить': 602,\n",
       "  'производство': 603,\n",
       "  'пройти': 604,\n",
       "  'пётр': 605,\n",
       "  'разрыв': 606,\n",
       "  'рейтинг': 607,\n",
       "  'решить': 608,\n",
       "  'российский': 609,\n",
       "  'руководитель': 610,\n",
       "  'санкт': 611,\n",
       "  'санкт_петербургский': 612,\n",
       "  'соревнование': 613,\n",
       "  'сотня': 614,\n",
       "  'сплав': 615,\n",
       "  'среди': 616,\n",
       "  'студент': 617,\n",
       "  'счёт': 618,\n",
       "  'теоретический': 619,\n",
       "  'технологический': 620,\n",
       "  'технология_печать': 621,\n",
       "  'тур': 622,\n",
       "  'устранить': 623,\n",
       "  'фонд': 624,\n",
       "  'число': 625,\n",
       "  'чистый': 626,\n",
       "  'электроника': 627,\n",
       "  'amazon': 628,\n",
       "  'авиация': 629,\n",
       "  'беспилотный': 630,\n",
       "  'беспилотный_летательный': 631,\n",
       "  'близлежащий': 632,\n",
       "  'большой': 633,\n",
       "  'быстрый': 634,\n",
       "  'ведомство': 635,\n",
       "  'внимание': 636,\n",
       "  'возвращаться': 637,\n",
       "  'воздушный': 638,\n",
       "  'выдать': 639,\n",
       "  'высота': 640,\n",
       "  'груз': 641,\n",
       "  'дирижабль': 642,\n",
       "  'документ': 643,\n",
       "  'доставить': 644,\n",
       "  'доставка': 645,\n",
       "  'доставка_груз': 646,\n",
       "  'доставлять': 647,\n",
       "  'дрон': 648,\n",
       "  'ежедневный': 649,\n",
       "  'житель': 650,\n",
       "  'запас': 651,\n",
       "  'запатентовать': 652,\n",
       "  'иной': 653,\n",
       "  'коммерческий': 654,\n",
       "  'компания': 655,\n",
       "  'компания_amazon': 656,\n",
       "  'компания_планировать': 657,\n",
       "  'курсировать': 658,\n",
       "  'маленький': 659,\n",
       "  'метр': 660,\n",
       "  'мешать': 661,\n",
       "  'населить': 662,\n",
       "  'населить_пункт': 663,\n",
       "  'обеспечивать': 664,\n",
       "  'обратить': 665,\n",
       "  'обратить_внимание': 666,\n",
       "  'около': 667,\n",
       "  'около_метр': 668,\n",
       "  'оптимизировать': 669,\n",
       "  'патент': 670,\n",
       "  'патентный': 671,\n",
       "  'планировать': 672,\n",
       "  'поднимать': 673,\n",
       "  'пользователь': 674,\n",
       "  'помещение': 675,\n",
       "  'посылка': 676,\n",
       "  'предлагать': 677,\n",
       "  'предположительно': 678,\n",
       "  'продукт': 679,\n",
       "  'пункт': 680,\n",
       "  'разместить': 681,\n",
       "  'размещать': 682,\n",
       "  'расти': 683,\n",
       "  'склад': 684,\n",
       "  'служить': 685,\n",
       "  'специалист': 686,\n",
       "  'спрос': 687,\n",
       "  'стационарный': 688,\n",
       "  'судить': 689,\n",
       "  'текст': 690,\n",
       "  'товар': 691,\n",
       "  'хранить': 692,\n",
       "  'храниться': 693,\n",
       "  'cdc': 694,\n",
       "  'martin': 695,\n",
       "  'new': 696,\n",
       "  'анализ': 697,\n",
       "  'антибиотик': 698,\n",
       "  'антимикробный': 699,\n",
       "  'бактерия': 700,\n",
       "  'бедренный': 701,\n",
       "  'бесполезный': 702,\n",
       "  'бета': 703,\n",
       "  'больница': 704,\n",
       "  'борьба': 705,\n",
       "  'вводить': 706,\n",
       "  'вич': 707,\n",
       "  'вич_инфекция': 708,\n",
       "  'включая': 709,\n",
       "  'вмешательство': 710,\n",
       "  'внедрять': 711,\n",
       "  'внутрь': 712,\n",
       "  'вода': 713,\n",
       "  'возбудитель': 714,\n",
       "  'воспаление': 715,\n",
       "  'восприимчивость': 716,\n",
       "  'выделить': 717,\n",
       "  'вырабатывать': 718,\n",
       "  'выявлять': 719,\n",
       "  'ген': 720,\n",
       "  'генеральный': 721,\n",
       "  'глава': 722,\n",
       "  'госпитализация': 723,\n",
       "  'дальнейший_исследование': 724,\n",
       "  'действие': 725,\n",
       "  'деятельность': 726,\n",
       "  'договориться': 727,\n",
       "  'доза': 728,\n",
       "  'доступ': 729,\n",
       "  'ежегодно': 730,\n",
       "  'женщина': 731,\n",
       "  'жидкость': 732,\n",
       "  'зарегистрировать': 733,\n",
       "  'здравоохранение': 734,\n",
       "  'иметь': 735,\n",
       "  'иметься': 736,\n",
       "  'индия': 737,\n",
       "  'инфекционный_заболевание': 738,\n",
       "  'инфекция': 739,\n",
       "  'использоваться': 740,\n",
       "  'история': 741,\n",
       "  'кодировать': 742,\n",
       "  'кожа': 743,\n",
       "  'комиссия': 744,\n",
       "  'контроль': 745,\n",
       "  'костный': 746,\n",
       "  'костный_мозг': 747,\n",
       "  'кость': 748,\n",
       "  'лидер': 749,\n",
       "  'лишний': 750,\n",
       "  'любой': 751,\n",
       "  'мартин': 752,\n",
       "  'медицина': 753,\n",
       "  'менее': 754,\n",
       "  'мера': 755,\n",
       "  'местный': 756,\n",
       "  'месяц': 757,\n",
       "  'микроорганизм': 758,\n",
       "  'миллиард': 759,\n",
       "  'мир': 760,\n",
       "  'мониторинг': 761,\n",
       "  'назначение': 762,\n",
       "  'наличие': 763,\n",
       "  'население': 764,\n",
       "  'начало': 765,\n",
       "  'наш': 766,\n",
       "  'невад': 767,\n",
       "  'неоднократно': 768,\n",
       "  'неэффективный': 769,\n",
       "  'обмениваться': 770,\n",
       "  'образец': 771,\n",
       "  'обсуждаться': 772,\n",
       "  'обсуждение': 773,\n",
       "  'оказаться': 774,\n",
       "  'около_миллиард': 775,\n",
       "  'около_процент': 776,\n",
       "  'оон': 777,\n",
       "  'операция': 778,\n",
       "  'описывать': 779,\n",
       "  'осложнить': 780,\n",
       "  'оставаться': 781,\n",
       "  'острый': 782,\n",
       "  'отмечаться': 783,\n",
       "  'относительно': 784,\n",
       "  'относительный': 785,\n",
       "  'очередной': 786,\n",
       "  'перелом': 787,\n",
       "  'повсеместный': 788,\n",
       "  'подвергаться': 789,\n",
       "  'подробный': 790,\n",
       "  'пожилой': 791,\n",
       "  'постоянно': 792,\n",
       "  'поступить': 793,\n",
       "  'почва': 794,\n",
       "  'почитать': 795,\n",
       "  'почитать_наш': 796,\n",
       "  'правило': 797,\n",
       "  'правый': 798,\n",
       "  'практически': 799,\n",
       "  'президент': 800,\n",
       "  'президент_сша': 801,\n",
       "  'препарат': 802,\n",
       "  'присутствие': 803,\n",
       "  'проблема': 804,\n",
       "  'профилактика': 805,\n",
       "  'развитие': 806,\n",
       "  'развиться': 807,\n",
       "  'разрушать': 808,\n",
       "  'ранее': 809,\n",
       "  'распространение': 810,\n",
       "  'реакция': 811,\n",
       "  'ряд': 812,\n",
       "  'сельский': 813,\n",
       "  'сельский_хозяйство': 814,\n",
       "  'синдром': 815,\n",
       "  'системный': 816,\n",
       "  'скопление': 817,\n",
       "  'случай': 818,\n",
       "  'смерть': 819,\n",
       "  'сообщение': 820,\n",
       "  'спектр': 821,\n",
       "  'средство': 822,\n",
       "  'становиться': 823,\n",
       "  'страна': 824,\n",
       "  'существенный': 825,\n",
       "  'сфера': 826,\n",
       "  'тип': 827,\n",
       "  'тысяча_тонна': 828,\n",
       "  'умеренно': 829,\n",
       "  'усилить': 830,\n",
       "  'устойчивость': 831,\n",
       "  'устойчивость_антибиотик': 832,\n",
       "  'фермент': 833,\n",
       "  'хирургический': 834,\n",
       "  'хирургический_вмешательство': 835,\n",
       "  'хирургический_операция': 836,\n",
       "  'хозяйство': 837,\n",
       "  'хотя': 838,\n",
       "  'четвёртый': 839,\n",
       "  'широко': 840,\n",
       "  'шок': 841,\n",
       "  'эбола': 842,\n",
       "  'экспертный': 843,\n",
       "  'эффективно': 844,\n",
       "  'ab': 845,\n",
       "  'al': 846,\n",
       "  'letters_кратко': 847,\n",
       "  'physical': 848,\n",
       "  'physical_review': 849,\n",
       "  'review': 850,\n",
       "  'si': 851,\n",
       "  'александр': 852,\n",
       "  'александр_ершовый': 853,\n",
       "  'атом': 854,\n",
       "  'атом_водород': 855,\n",
       "  'белок': 856,\n",
       "  'верный': 857,\n",
       "  'вероятность': 858,\n",
       "  'весьма': 859,\n",
       "  'включать': 860,\n",
       "  'внутри': 861,\n",
       "  'водород': 862,\n",
       "  'возможно': 863,\n",
       "  'возникновение': 864,\n",
       "  'вокруг': 865,\n",
       "  'вроде': 866,\n",
       "  'выглядеть': 867,\n",
       "  'вызывать': 868,\n",
       "  'вызываться': 869,\n",
       "  'высокий': 870,\n",
       "  'высокий_энергия': 871,\n",
       "  'грань': 872,\n",
       "  'данный_случай': 873,\n",
       "  'диаметр': 874,\n",
       "  'диапазон': 875,\n",
       "  'дипольный': 876,\n",
       "  'дипольный_момент': 877,\n",
       "  'длина': 878,\n",
       "  'доказательство': 879,\n",
       "  'ершовый': 880,\n",
       "  'замечать': 881,\n",
       "  'зарядить': 882,\n",
       "  'зафиксировать': 883,\n",
       "  'интенсивность': 884,\n",
       "  'ионный': 885,\n",
       "  'ионный_канал': 886,\n",
       "  'испарение': 887,\n",
       "  'камера': 888,\n",
       "  'квантовый': 889,\n",
       "  'квантовый_состояние': 890,\n",
       "  'кислород': 891,\n",
       "  'копия': 892,\n",
       "  'кратко': 893,\n",
       "  'кристалл': 894,\n",
       "  'кроме': 895,\n",
       "  'макроскопический': 896,\n",
       "  'мембрана': 897,\n",
       "  'метод': 898,\n",
       "  'механизм': 899,\n",
       "  'минерал': 900,\n",
       "  'многие': 901,\n",
       "  'моделирование': 902,\n",
       "  'молекула': 903,\n",
       "  'молекула_вода': 904,\n",
       "  'наблюдать': 905,\n",
       "  'наблюдать_поведение': 906,\n",
       "  'нагревание': 907,\n",
       "  'нанометр': 908,\n",
       "  'наноразмерный': 909,\n",
       "  'напрямую': 910,\n",
       "  'национальный_лаборатория': 911,\n",
       "  'начальный': 912,\n",
       "  'невозможно': 913,\n",
       "  'нейтронный': 914,\n",
       "  'немой': 915,\n",
       "  'необычно': 916,\n",
       "  'новый_работа': 917,\n",
       "  'образ': 918,\n",
       "  'образовать': 919,\n",
       "  'обычно': 920,\n",
       "  'обязательно': 921,\n",
       "  'одинаково': 922,\n",
       "  'оказываться': 923,\n",
       "  'ориентация': 924,\n",
       "  'отличие': 925,\n",
       "  'отрицательно': 926,\n",
       "  'отрицательно_зарядить': 927,\n",
       "  'падать': 928,\n",
       "  'падение': 929,\n",
       "  'пара': 930,\n",
       "  'параллельно': 931,\n",
       "  'перенести': 932,\n",
       "  'переход': 933,\n",
       "  'пик': 934,\n",
       "  'плотность': 935,\n",
       "  'побывать': 936,\n",
       "  'поведение': 937,\n",
       "  'поворот': 938,\n",
       "  'подвид': 939,\n",
       "  'показать': 940,\n",
       "  'положительно': 941,\n",
       "  'поменять': 942,\n",
       "  'поместиться': 943,\n",
       "  'понимание': 944,\n",
       "  'понимание_механизм': 945,\n",
       "  'пора': 946,\n",
       "  'появление': 947,\n",
       "  'превращаться': 948,\n",
       "  'предсказать': 949,\n",
       "  'предыдущий': 950,\n",
       "  'привязать': 951,\n",
       "  'принцип': 952,\n",
       "  'пропадать': 953,\n",
       "  'пространство': 954,\n",
       "  'протяжённый': 955,\n",
       "  'прочитать': 956,\n",
       "  'проявляться': 957,\n",
       "  'рассчитывать': 958,\n",
       "  'раствор': 959,\n",
       "  'рост': 960,\n",
       "  'руководство': 961,\n",
       "  'сей': 962,\n",
       "  'сей_пора': 963,\n",
       "  'сильный': 964,\n",
       "  'след': 965,\n",
       "  'следующий_образ': 966,\n",
       "  'слишком': 967,\n",
       "  'смотреть': 968,\n",
       "  'согласно': 969,\n",
       "  'спектроскопия': 970,\n",
       "  'способность': 971,\n",
       "  'статья': 972,\n",
       "  'стенка': 973,\n",
       "  'сторона': 974,\n",
       "  'странный': 975,\n",
       "  'сужение': 976,\n",
       "  'существовать': 977,\n",
       "  'температура': 978,\n",
       "  'терагерцовый': 979,\n",
       "  'терять': 980,\n",
       "  'тонкий': 981,\n",
       "  'точка_зрение': 982,\n",
       "  'точно': 983,\n",
       "  'туннелирование': 984,\n",
       "  'увидеть': 985,\n",
       "  'узкий': 986,\n",
       "  'фактически': 987,\n",
       "  'физик': 988,\n",
       "  'физика': 989,\n",
       "  'физический': 990,\n",
       "  'физический_общество': 991,\n",
       "  'формула': 992,\n",
       "  'химический': 993,\n",
       "  'частично': 994,\n",
       "  'шесть': 995,\n",
       "  'эквивалентный': 996,\n",
       "  'эксперимент': 997,\n",
       "  'энергетический': 998,\n",
       "  'энергия': 999,\n",
       "  ...},\n",
       " 'id2token': {},\n",
       " 'cfs': {71: 722,\n",
       "  85: 737,\n",
       "  67: 916,\n",
       "  7: 2332,\n",
       "  92: 3487,\n",
       "  36: 60,\n",
       "  2: 87,\n",
       "  4: 13,\n",
       "  107: 322,\n",
       "  72: 2464,\n",
       "  1: 330,\n",
       "  3: 195,\n",
       "  112: 512,\n",
       "  15: 19,\n",
       "  94: 275,\n",
       "  9: 87,\n",
       "  51: 279,\n",
       "  0: 316,\n",
       "  98: 17,\n",
       "  17: 1049,\n",
       "  78: 386,\n",
       "  25: 1748,\n",
       "  125: 1716,\n",
       "  109: 1323,\n",
       "  37: 500,\n",
       "  48: 173,\n",
       "  63: 201,\n",
       "  60: 1302,\n",
       "  82: 376,\n",
       "  111: 903,\n",
       "  133: 1114,\n",
       "  131: 1766,\n",
       "  11: 920,\n",
       "  32: 693,\n",
       "  88: 2395,\n",
       "  57: 55,\n",
       "  81: 1816,\n",
       "  30: 1535,\n",
       "  58: 2897,\n",
       "  41: 145,\n",
       "  118: 46,\n",
       "  129: 898,\n",
       "  19: 227,\n",
       "  34: 32,\n",
       "  136: 35,\n",
       "  135: 26,\n",
       "  80: 45,\n",
       "  16: 474,\n",
       "  121: 472,\n",
       "  126: 38,\n",
       "  24: 1895,\n",
       "  76: 281,\n",
       "  39: 2927,\n",
       "  66: 273,\n",
       "  12: 668,\n",
       "  117: 2684,\n",
       "  122: 108,\n",
       "  128: 483,\n",
       "  79: 462,\n",
       "  29: 66,\n",
       "  53: 887,\n",
       "  8: 3345,\n",
       "  14: 646,\n",
       "  10: 835,\n",
       "  20: 350,\n",
       "  22: 191,\n",
       "  127: 1257,\n",
       "  130: 184,\n",
       "  45: 126,\n",
       "  68: 263,\n",
       "  56: 1228,\n",
       "  61: 482,\n",
       "  59: 662,\n",
       "  102: 1731,\n",
       "  86: 515,\n",
       "  99: 2310,\n",
       "  47: 2282,\n",
       "  106: 210,\n",
       "  91: 1084,\n",
       "  123: 2267,\n",
       "  65: 196,\n",
       "  120: 715,\n",
       "  26: 415,\n",
       "  21: 33,\n",
       "  77: 127,\n",
       "  114: 229,\n",
       "  5: 272,\n",
       "  74: 809,\n",
       "  38: 1452,\n",
       "  115: 430,\n",
       "  119: 1613,\n",
       "  89: 924,\n",
       "  84: 2456,\n",
       "  87: 1856,\n",
       "  62: 34,\n",
       "  27: 333,\n",
       "  18: 790,\n",
       "  70: 110,\n",
       "  69: 94,\n",
       "  55: 987,\n",
       "  113: 1113,\n",
       "  49: 980,\n",
       "  43: 310,\n",
       "  75: 162,\n",
       "  101: 301,\n",
       "  116: 565,\n",
       "  96: 16,\n",
       "  105: 207,\n",
       "  93: 43,\n",
       "  108: 108,\n",
       "  110: 264,\n",
       "  64: 179,\n",
       "  95: 130,\n",
       "  52: 101,\n",
       "  97: 226,\n",
       "  83: 67,\n",
       "  134: 41,\n",
       "  33: 116,\n",
       "  31: 73,\n",
       "  42: 64,\n",
       "  35: 15,\n",
       "  40: 30,\n",
       "  13: 404,\n",
       "  54: 487,\n",
       "  23: 24,\n",
       "  46: 58,\n",
       "  104: 115,\n",
       "  100: 258,\n",
       "  132: 27,\n",
       "  73: 68,\n",
       "  124: 305,\n",
       "  103: 51,\n",
       "  6: 139,\n",
       "  90: 115,\n",
       "  28: 143,\n",
       "  50: 252,\n",
       "  44: 144,\n",
       "  157: 428,\n",
       "  196: 3046,\n",
       "  167: 225,\n",
       "  172: 1123,\n",
       "  179: 375,\n",
       "  141: 108,\n",
       "  160: 411,\n",
       "  154: 406,\n",
       "  176: 187,\n",
       "  164: 911,\n",
       "  168: 586,\n",
       "  140: 3769,\n",
       "  169: 408,\n",
       "  186: 2063,\n",
       "  166: 63,\n",
       "  162: 347,\n",
       "  173: 430,\n",
       "  161: 425,\n",
       "  165: 1572,\n",
       "  201: 2017,\n",
       "  190: 709,\n",
       "  153: 380,\n",
       "  174: 522,\n",
       "  144: 1190,\n",
       "  191: 1181,\n",
       "  199: 1010,\n",
       "  151: 2195,\n",
       "  137: 44,\n",
       "  139: 157,\n",
       "  138: 261,\n",
       "  197: 2439,\n",
       "  193: 1007,\n",
       "  171: 231,\n",
       "  150: 252,\n",
       "  180: 115,\n",
       "  188: 937,\n",
       "  194: 192,\n",
       "  189: 73,\n",
       "  181: 72,\n",
       "  159: 1604,\n",
       "  178: 1537,\n",
       "  148: 14,\n",
       "  198: 133,\n",
       "  143: 23,\n",
       "  177: 168,\n",
       "  195: 130,\n",
       "  147: 284,\n",
       "  200: 2057,\n",
       "  149: 24,\n",
       "  184: 86,\n",
       "  183: 245,\n",
       "  192: 222,\n",
       "  187: 434,\n",
       "  142: 1156,\n",
       "  145: 501,\n",
       "  185: 126,\n",
       "  182: 449,\n",
       "  170: 257,\n",
       "  155: 180,\n",
       "  146: 871,\n",
       "  163: 16,\n",
       "  175: 178,\n",
       "  158: 729,\n",
       "  152: 11,\n",
       "  156: 37,\n",
       "  229: 21,\n",
       "  230: 23,\n",
       "  335: 72,\n",
       "  295: 61,\n",
       "  279: 317,\n",
       "  208: 286,\n",
       "  310: 779,\n",
       "  304: 232,\n",
       "  340: 1399,\n",
       "  236: 438,\n",
       "  362: 849,\n",
       "  353: 795,\n",
       "  291: 84,\n",
       "  203: 28,\n",
       "  346: 2430,\n",
       "  360: 246,\n",
       "  228: 1108,\n",
       "  235: 716,\n",
       "  293: 50,\n",
       "  287: 70,\n",
       "  290: 90,\n",
       "  242: 1406,\n",
       "  356: 1158,\n",
       "  254: 340,\n",
       "  325: 955,\n",
       "  253: 12,\n",
       "  384: 370,\n",
       "  282: 23,\n",
       "  225: 2119,\n",
       "  342: 788,\n",
       "  239: 1264,\n",
       "  299: 446,\n",
       "  374: 1156,\n",
       "  237: 263,\n",
       "  207: 514,\n",
       "  331: 1792,\n",
       "  307: 409,\n",
       "  371: 32,\n",
       "  347: 180,\n",
       "  217: 2006,\n",
       "  309: 861,\n",
       "  263: 384,\n",
       "  329: 23,\n",
       "  349: 534,\n",
       "  367: 225,\n",
       "  260: 499,\n",
       "  312: 84,\n",
       "  274: 2808,\n",
       "  289: 323,\n",
       "  339: 485,\n",
       "  214: 538,\n",
       "  380: 90,\n",
       "  313: 556,\n",
       "  278: 223,\n",
       "  350: 380,\n",
       "  233: 26,\n",
       "  205: 965,\n",
       "  328: 13,\n",
       "  311: 1135,\n",
       "  379: 59,\n",
       "  334: 664,\n",
       "  211: 1136,\n",
       "  305: 21,\n",
       "  332: 1278,\n",
       "  255: 20,\n",
       "  308: 421,\n",
       "  209: 352,\n",
       "  249: 808,\n",
       "  266: 1744,\n",
       "  275: 59,\n",
       "  324: 17,\n",
       "  302: 347,\n",
       "  297: 85,\n",
       "  277: 177,\n",
       "  234: 301,\n",
       "  232: 88,\n",
       "  345: 459,\n",
       "  321: 105,\n",
       "  364: 847,\n",
       "  352: 21,\n",
       "  276: 88,\n",
       "  373: 1386,\n",
       "  303: 1128,\n",
       "  341: 11,\n",
       "  216: 205,\n",
       "  292: 119,\n",
       "  337: 908,\n",
       "  231: 249,\n",
       "  215: 1058,\n",
       "  319: 414,\n",
       "  357: 623,\n",
       "  247: 188,\n",
       "  298: 52,\n",
       "  323: 251,\n",
       "  271: 763,\n",
       "  344: 925,\n",
       "  226: 601,\n",
       "  258: 1038,\n",
       "  322: 1531,\n",
       "  204: 23,\n",
       "  317: 88,\n",
       "  288: 35,\n",
       "  265: 44,\n",
       "  294: 788,\n",
       "  280: 51,\n",
       "  286: 25,\n",
       "  369: 493,\n",
       "  269: 1610,\n",
       "  306: 209,\n",
       "  213: 138,\n",
       "  267: 687,\n",
       "  223: 380,\n",
       "  262: 51,\n",
       "  359: 52,\n",
       "  218: 339,\n",
       "  300: 110,\n",
       "  221: 19,\n",
       "  251: 1299,\n",
       "  382: 1202,\n",
       "  383: 426,\n",
       "  259: 611,\n",
       "  206: 447,\n",
       "  257: 650,\n",
       "  202: 18,\n",
       "  363: 384,\n",
       "  316: 1027,\n",
       "  268: 453,\n",
       "  378: 86,\n",
       "  330: 13,\n",
       "  243: 471,\n",
       "  224: 2687,\n",
       "  327: 1369,\n",
       "  283: 1251,\n",
       "  315: 501,\n",
       "  375: 38,\n",
       "  270: 10,\n",
       "  296: 64,\n",
       "  338: 82,\n",
       "  220: 163,\n",
       "  219: 575,\n",
       "  284: 641,\n",
       "  368: 170,\n",
       "  256: 425,\n",
       "  365: 2041,\n",
       "  377: 406,\n",
       "  281: 404,\n",
       "  343: 395,\n",
       "  381: 85,\n",
       "  212: 45,\n",
       "  250: 48,\n",
       "  333: 13,\n",
       "  348: 25,\n",
       "  245: 314,\n",
       "  273: 576,\n",
       "  318: 123,\n",
       "  240: 259,\n",
       "  248: 12,\n",
       "  376: 403,\n",
       "  222: 89,\n",
       "  370: 388,\n",
       "  272: 39,\n",
       "  372: 226,\n",
       "  301: 299,\n",
       "  252: 277,\n",
       "  351: 309,\n",
       "  241: 402,\n",
       "  336: 11,\n",
       "  355: 30,\n",
       "  354: 27,\n",
       "  238: 25,\n",
       "  261: 26,\n",
       "  210: 42,\n",
       "  264: 42,\n",
       "  320: 51,\n",
       "  326: 28,\n",
       "  358: 16,\n",
       "  227: 329,\n",
       "  361: 17,\n",
       "  244: 41,\n",
       "  285: 29,\n",
       "  366: 133,\n",
       "  246: 149,\n",
       "  314: 380,\n",
       "  423: 130,\n",
       "  421: 3726,\n",
       "  498: 351,\n",
       "  515: 152,\n",
       "  426: 223,\n",
       "  505: 234,\n",
       "  490: 58,\n",
       "  495: 25,\n",
       "  501: 162,\n",
       "  424: 2063,\n",
       "  461: 174,\n",
       "  386: 18,\n",
       "  459: 444,\n",
       "  418: 985,\n",
       "  428: 307,\n",
       "  444: 205,\n",
       "  527: 1047,\n",
       "  521: 599,\n",
       "  463: 581,\n",
       "  395: 795,\n",
       "  516: 268,\n",
       "  387: 56,\n",
       "  506: 838,\n",
       "  468: 220,\n",
       "  486: 82,\n",
       "  476: 72,\n",
       "  406: 43,\n",
       "  485: 295,\n",
       "  509: 45,\n",
       "  504: 28,\n",
       "  411: 630,\n",
       "  402: 230,\n",
       "  524: 351,\n",
       "  470: 356,\n",
       "  438: 110,\n",
       "  507: 662,\n",
       "  440: 67,\n",
       "  531: 356,\n",
       "  432: 343,\n",
       "  522: 848,\n",
       "  412: 36,\n",
       "  478: 23,\n",
       "  385: 38,\n",
       "  513: 76,\n",
       "  416: 167,\n",
       "  454: 613,\n",
       "  415: 94,\n",
       "  399: 163,\n",
       "  497: 616,\n",
       "  526: 1096,\n",
       "  474: 347,\n",
       "  388: 40,\n",
       "  397: 169,\n",
       "  503: 1047,\n",
       "  446: 322,\n",
       "  391: 124,\n",
       "  442: 955,\n",
       "  408: 68,\n",
       "  464: 111,\n",
       "  429: 133,\n",
       "  508: 873,\n",
       "  488: 2031,\n",
       "  409: 375,\n",
       "  482: 307,\n",
       "  487: 12,\n",
       "  437: 1516,\n",
       "  394: 281,\n",
       "  400: 60,\n",
       "  477: 83,\n",
       "  500: 101,\n",
       "  389: 17,\n",
       "  511: 55,\n",
       "  413: 263,\n",
       "  489: 90,\n",
       "  492: 172,\n",
       "  530: 116,\n",
       "  455: 202,\n",
       "  443: 352,\n",
       "  519: 53,\n",
       "  414: 413,\n",
       "  441: 96,\n",
       "  496: 24,\n",
       "  431: 40,\n",
       "  405: 1446,\n",
       "  392: 112,\n",
       "  449: 443,\n",
       "  510: 465,\n",
       "  456: 38,\n",
       "  512: 66,\n",
       "  420: 37,\n",
       "  475: 133,\n",
       "  466: 67,\n",
       "  493: 3109,\n",
       "  469: 109,\n",
       "  473: 53,\n",
       "  514: 1247,\n",
       "  458: 91,\n",
       "  419: 127,\n",
       "  433: 108,\n",
       "  467: 768,\n",
       "  436: 273,\n",
       "  393: 1883,\n",
       "  479: 47,\n",
       "  398: 42,\n",
       "  528: 397,\n",
       "  407: 210,\n",
       "  410: 682,\n",
       "  460: 930,\n",
       "  403: 294,\n",
       "  445: 636,\n",
       "  517: 160,\n",
       "  471: 1278,\n",
       "  483: 62,\n",
       "  435: 64,\n",
       "  472: 136,\n",
       "  450: 544,\n",
       "  525: 90,\n",
       "  390: 22,\n",
       "  401: 60,\n",
       "  457: 154,\n",
       "  480: 840,\n",
       "  465: 484,\n",
       "  518: 25,\n",
       "  499: 199,\n",
       "  523: 593,\n",
       "  494: 134,\n",
       "  404: 67,\n",
       "  451: 470,\n",
       "  434: 437,\n",
       "  427: 132,\n",
       "  491: 18,\n",
       "  502: 133,\n",
       "  462: 62,\n",
       "  453: 699,\n",
       "  422: 40,\n",
       "  484: 188,\n",
       "  396: 138,\n",
       "  439: 14,\n",
       "  425: 17,\n",
       "  417: 19,\n",
       "  448: 111,\n",
       "  430: 12,\n",
       "  520: 13,\n",
       "  529: 24,\n",
       "  447: 21,\n",
       "  481: 16,\n",
       "  452: 437,\n",
       "  597: 900,\n",
       "  609: 577,\n",
       "  543: 96,\n",
       "  546: 150,\n",
       "  574: 236,\n",
       "  615: 120,\n",
       "  611: 37,\n",
       "  586: 30,\n",
       "  605: 33,\n",
       "  539: 81,\n",
       "  579: 463,\n",
       "  560: 145,\n",
       "  571: 67,\n",
       "  584: 36,\n",
       "  554: 71,\n",
       "  568: 176,\n",
       "  556: 194,\n",
       "  564: 68,\n",
       "  540: 16,\n",
       "  558: 77,\n",
       "  557: 1049,\n",
       "  535: 11,\n",
       "  580: 1006,\n",
       "  602: 697,\n",
       "  624: 126,\n",
       "  582: 26,\n",
       "  549: 11,\n",
       "  617: 156,\n",
       "  536: 12,\n",
       "  583: 51,\n",
       "  551: 14,\n",
       "  578: 576,\n",
       "  590: 96,\n",
       "  610: 197,\n",
       "  601: 148,\n",
       "  553: 127,\n",
       "  600: 35,\n",
       "  542: 23,\n",
       "  596: 118,\n",
       "  608: 512,\n",
       "  552: 840,\n",
       "  575: 1213,\n",
       "  599: 671,\n",
       "  603: 1001,\n",
       "  613: 128,\n",
       "  623: 58,\n",
       "  606: 137,\n",
       "  619: 200,\n",
       "  592: 234,\n",
       "  604: 526,\n",
       "  566: 39,\n",
       "  587: 496,\n",
       "  545: 211,\n",
       "  627: 170,\n",
       "  538: 12,\n",
       "  594: 250,\n",
       "  588: 104,\n",
       "  585: 94,\n",
       "  620: 357,\n",
       "  622: 18,\n",
       "  569: 847,\n",
       "  550: 367,\n",
       "  559: 31,\n",
       "  595: 20,\n",
       "  570: 580,\n",
       "  626: 106,\n",
       "  565: 95,\n",
       "  541: 12,\n",
       "  537: 67,\n",
       "  616: 692,\n",
       "  577: 288,\n",
       "  593: 218,\n",
       "  589: 213,\n",
       "  562: 1387,\n",
       "  581: 534,\n",
       "  625: 1542,\n",
       "  618: 506,\n",
       "  544: 25,\n",
       "  572: 164,\n",
       "  614: 231,\n",
       "  573: 130,\n",
       "  598: 10,\n",
       "  607: 49,\n",
       "  563: 134,\n",
       "  533: 64,\n",
       "  532: 887,\n",
       "  534: 55,\n",
       "  548: 34,\n",
       "  555: 11,\n",
       "  547: 29,\n",
       "  612: 14,\n",
       "  561: 22,\n",
       "  591: 19,\n",
       "  576: 79,\n",
       "  567: 11,\n",
       "  621: 19,\n",
       "  655: 4352,\n",
       "  628: 149,\n",
       "  652: 37,\n",
       "  638: 701,\n",
       "  684: 33,\n",
       "  645: 368,\n",
       "  641: 429,\n",
       "  630: 1373,\n",
       "  685: 332,\n",
       "  648: 848,\n",
       "  664: 497,\n",
       "  634: 632,\n",
       "  674: 941,\n",
       "  670: 120,\n",
       "  639: 63,\n",
       "  665: 149,\n",
       "  636: 400,\n",
       "  686: 819,\n",
       "  690: 427,\n",
       "  643: 166,\n",
       "  671: 15,\n",
       "  635: 77,\n",
       "  689: 186,\n",
       "  672: 724,\n",
       "  669: 72,\n",
       "  693: 96,\n",
       "  651: 139,\n",
       "  691: 57,\n",
       "  673: 93,\n",
       "  675: 163,\n",
       "  633: 2223,\n",
       "  642: 35,\n",
       "  688: 60,\n",
       "  682: 36,\n",
       "  683: 211,\n",
       "  687: 22,\n",
       "  653: 433,\n",
       "  692: 58,\n",
       "  679: 386,\n",
       "  649: 20,\n",
       "  650: 251,\n",
       "  632: 19,\n",
       "  662: 60,\n",
       "  680: 143,\n",
       "  677: 282,\n",
       "  681: 200,\n",
       "  640: 902,\n",
       "  667: 2225,\n",
       "  660: 1894,\n",
       "  661: 91,\n",
       "  654: 174,\n",
       "  629: 282,\n",
       "  678: 232,\n",
       "  658: 12,\n",
       "  659: 967,\n",
       "  647: 69,\n",
       "  644: 159,\n",
       "  676: 31,\n",
       "  637: 110,\n",
       "  656: 23,\n",
       "  646: 65,\n",
       "  631: 345,\n",
       "  666: 107,\n",
       "  657: 55,\n",
       "  663: 31,\n",
       "  668: 57,\n",
       "  745: 310,\n",
       "  805: 56,\n",
       "  694: 14,\n",
       "  818: 2103,\n",
       "  819: 270,\n",
       "  791: 80,\n",
       "  739: 251,\n",
       "  799: 594,\n",
       "  736: 201,\n",
       "  824: 755,\n",
       "  698: 182,\n",
       "  804: 534,\n",
       "  823: 366,\n",
       "  782: 88,\n",
       "  758: 141,\n",
       "  792: 204,\n",
       "  718: 130,\n",
       "  827: 1612,\n",
       "  831: 245,\n",
       "  844: 218,\n",
       "  770: 109,\n",
       "  720: 1101,\n",
       "  821: 395,\n",
       "  725: 1094,\n",
       "  802: 493,\n",
       "  702: 12,\n",
       "  699: 18,\n",
       "  822: 528,\n",
       "  753: 132,\n",
       "  813: 66,\n",
       "  837: 63,\n",
       "  794: 106,\n",
       "  713: 1410,\n",
       "  722: 215,\n",
       "  843: 23,\n",
       "  744: 89,\n",
       "  705: 262,\n",
       "  700: 733,\n",
       "  800: 84,\n",
       "  752: 28,\n",
       "  695: 235,\n",
       "  730: 93,\n",
       "  760: 794,\n",
       "  740: 2030,\n",
       "  759: 487,\n",
       "  728: 123,\n",
       "  749: 54,\n",
       "  762: 125,\n",
       "  806: 872,\n",
       "  737: 158,\n",
       "  825: 178,\n",
       "  764: 187,\n",
       "  735: 1863,\n",
       "  729: 343,\n",
       "  779: 229,\n",
       "  767: 16,\n",
       "  750: 54,\n",
       "  768: 67,\n",
       "  789: 84,\n",
       "  834: 57,\n",
       "  778: 400,\n",
       "  787: 12,\n",
       "  798: 141,\n",
       "  701: 18,\n",
       "  748: 368,\n",
       "  780: 13,\n",
       "  715: 71,\n",
       "  746: 91,\n",
       "  786: 65,\n",
       "  723: 22,\n",
       "  757: 484,\n",
       "  793: 197,\n",
       "  756: 187,\n",
       "  704: 63,\n",
       "  815: 84,\n",
       "  816: 25,\n",
       "  811: 592,\n",
       "  803: 168,\n",
       "  807: 30,\n",
       "  817: 179,\n",
       "  732: 355,\n",
       "  743: 303,\n",
       "  710: 100,\n",
       "  774: 1889,\n",
       "  769: 17,\n",
       "  765: 883,\n",
       "  731: 656,\n",
       "  841: 19,\n",
       "  697: 1278,\n",
       "  714: 71,\n",
       "  709: 680,\n",
       "  829: 16,\n",
       "  784: 439,\n",
       "  812: 560,\n",
       "  785: 81,\n",
       "  716: 11,\n",
       "  733: 222,\n",
       "  712: 82,\n",
       "  706: 124,\n",
       "  763: 515,\n",
       "  696: 289,\n",
       "  742: 132,\n",
       "  833: 291,\n",
       "  703: 165,\n",
       "  808: 58,\n",
       "  751: 622,\n",
       "  797: 521,\n",
       "  754: 860,\n",
       "  783: 41,\n",
       "  820: 557,\n",
       "  771: 835,\n",
       "  717: 275,\n",
       "  809: 1926,\n",
       "  781: 566,\n",
       "  838: 510,\n",
       "  719: 37,\n",
       "  788: 12,\n",
       "  810: 307,\n",
       "  773: 45,\n",
       "  721: 115,\n",
       "  777: 19,\n",
       "  741: 350,\n",
       "  839: 159,\n",
       "  734: 84,\n",
       "  772: 25,\n",
       "  707: 95,\n",
       "  842: 46,\n",
       "  727: 29,\n",
       "  830: 38,\n",
       "  761: 112,\n",
       "  826: 169,\n",
       "  726: 120,\n",
       "  840: 153,\n",
       "  711: 18,\n",
       "  755: 396,\n",
       "  790: 482,\n",
       "  795: 27,\n",
       "  766: 736,\n",
       "  814: 39,\n",
       "  801: 15,\n",
       "  828: 18,\n",
       "  775: 51,\n",
       "  836: 13,\n",
       "  747: 20,\n",
       "  835: 16,\n",
       "  724: 32,\n",
       "  776: 101,\n",
       "  708: 15,\n",
       "  738: 22,\n",
       "  832: 30,\n",
       "  796: 11,\n",
       "  989: 757,\n",
       "  961: 253,\n",
       "  852: 281,\n",
       "  909: 34,\n",
       "  894: 292,\n",
       "  939: 50,\n",
       "  940: 1823,\n",
       "  997: 2009,\n",
       "  902: 335,\n",
       "  903: 927,\n",
       "  889: 852,\n",
       "  984: 30,\n",
       "  948: 94,\n",
       "  892: 171,\n",
       "  980: 108,\n",
       "  876: 40,\n",
       "  848: 181,\n",
       "  850: 276,\n",
       "  893: 678,\n",
       "  915: 776,\n",
       "  956: 361,\n",
       "  990: 397,\n",
       "  900: 100,\n",
       "  993: 551,\n",
       "  992: 58,\n",
       "  846: 26,\n",
       "  851: 33,\n",
       "  919: 237,\n",
       "  981: 318,\n",
       "  955: 24,\n",
       "  977: 888,\n",
       "  976: 11,\n",
       "  888: 1372,\n",
       "  874: 420,\n",
       "  878: 1118,\n",
       "  908: 185,\n",
       "  943: 15,\n",
       "  950: 478,\n",
       "  970: 83,\n",
       "  979: 29,\n",
       "  875: 471,\n",
       "  861: 552,\n",
       "  863: 454,\n",
       "  879: 146,\n",
       "  944: 151,\n",
       "  899: 828,\n",
       "  988: 232,\n",
       "  962: 588,\n",
       "  946: 760,\n",
       "  905: 557,\n",
       "  937: 801,\n",
       "  914: 88,\n",
       "  931: 123,\n",
       "  958: 261,\n",
       "  898: 1541,\n",
       "  845: 19,\n",
       "  952: 305,\n",
       "  860: 365,\n",
       "  1000: 1004,\n",
       "  972: 1109,\n",
       "  949: 196,\n",
       "  947: 342,\n",
       "  934: 100,\n",
       "  983: 300,\n",
       "  999: 1024,\n",
       "  933: 302,\n",
       "  924: 94,\n",
       "  883: 248,\n",
       "  895: 2006,\n",
       "  985: 288,\n",
       "  929: 268,\n",
       "  884: 206,\n",
       "  960: 588,\n",
       "  978: 1113,\n",
       "  857: 56,\n",
       "  858: 429,\n",
       "  928: 175,\n",
       "  907: 42,\n",
       "  925: 523,\n",
       "  969: 1116,\n",
       "  867: 169,\n",
       "  918: 1357,\n",
       "  995: 622,\n",
       "  872: 45,\n",
       "  854: 850,\n",
       "  891: 390,\n",
       "  930: 561,\n",
       "  862: 358,\n",
       "  973: 136,\n",
       "  998: 147,\n",
       "  967: 230,\n",
       "  986: 101,\n",
       "  957: 136,\n",
       "  965: 399,\n",
       "  881: 80,\n",
       "  923: 278,\n",
       "  942: 32,\n",
       "  936: 38,\n",
       "  912: 103,\n",
       "  938: 113,\n",
       "  996: 47,\n",
       "  922: 61,\n",
       "  987: 137,\n",
       "  954: 638,\n",
       "  866: 66,\n",
       "  935: 242,\n",
       "  865: 512,\n",
       "  975: 30,\n",
       "  868: 468,\n",
       "  896: 27,\n",
       "  953: 18,\n",
       "  920: 458,\n",
       "  869: 31,\n",
       "  882: 139,\n",
       "  994: 177,\n",
       "  941: 59,\n",
       "  968: 192,\n",
       "  974: 770,\n",
       "  926: 25,\n",
       "  901: 381,\n",
       "  870: 1528,\n",
       "  887: 53,\n",
       "  971: 632,\n",
       "  910: 201,\n",
       "  859: 89,\n",
       "  916: 27,\n",
       "  913: 166,\n",
       "  932: 139,\n",
       "  959: 265,\n",
       "  921: 48,\n",
       "  951: 59,\n",
       "  864: 351,\n",
       "  964: 534,\n",
       "  885: 150,\n",
       "  856: 904,\n",
       "  897: 195,\n",
       "  880: 51,\n",
       "  911: 46,\n",
       "  877: 18,\n",
       "  849: 51,\n",
       "  847: 19,\n",
       "  991: 14,\n",
       "  904: 35,\n",
       "  890: 55,\n",
       "  945: 14,\n",
       "  873: 120,\n",
       "  963: 574,\n",
       "  917: 464,\n",
       "  906: 16,\n",
       "  966: 72,\n",
       "  982: 155,\n",
       "  855: 54,\n",
       "  927: 19,\n",
       "  871: 36,\n",
       "  886: 20,\n",
       "  ...},\n",
       " 'dfs': {71: 617,\n",
       "  85: 515,\n",
       "  67: 611,\n",
       "  7: 1738,\n",
       "  92: 780,\n",
       "  36: 27,\n",
       "  2: 23,\n",
       "  4: 10,\n",
       "  107: 273,\n",
       "  72: 1038,\n",
       "  1: 317,\n",
       "  3: 193,\n",
       "  112: 434,\n",
       "  15: 17,\n",
       "  94: 240,\n",
       "  9: 67,\n",
       "  51: 196,\n",
       "  0: 158,\n",
       "  98: 15,\n",
       "  17: 663,\n",
       "  78: 351,\n",
       "  25: 656,\n",
       "  125: 1043,\n",
       "  109: 1010,\n",
       "  37: 303,\n",
       "  48: 119,\n",
       "  63: 138,\n",
       "  60: 1031,\n",
       "  82: 240,\n",
       "  111: 730,\n",
       "  133: 935,\n",
       "  131: 1160,\n",
       "  11: 789,\n",
       "  32: 614,\n",
       "  88: 1559,\n",
       "  57: 51,\n",
       "  81: 1486,\n",
       "  30: 1289,\n",
       "  58: 2155,\n",
       "  41: 126,\n",
       "  118: 22,\n",
       "  129: 741,\n",
       "  19: 207,\n",
       "  34: 18,\n",
       "  136: 16,\n",
       "  135: 19,\n",
       "  80: 43,\n",
       "  16: 372,\n",
       "  121: 263,\n",
       "  126: 34,\n",
       "  24: 1365,\n",
       "  76: 259,\n",
       "  39: 1300,\n",
       "  66: 234,\n",
       "  12: 338,\n",
       "  117: 1584,\n",
       "  122: 45,\n",
       "  128: 412,\n",
       "  79: 363,\n",
       "  29: 38,\n",
       "  53: 592,\n",
       "  8: 1164,\n",
       "  14: 567,\n",
       "  10: 646,\n",
       "  20: 231,\n",
       "  22: 127,\n",
       "  127: 1023,\n",
       "  130: 144,\n",
       "  45: 106,\n",
       "  68: 176,\n",
       "  56: 882,\n",
       "  61: 303,\n",
       "  59: 488,\n",
       "  102: 1272,\n",
       "  86: 457,\n",
       "  99: 1408,\n",
       "  47: 1265,\n",
       "  106: 194,\n",
       "  91: 801,\n",
       "  123: 1503,\n",
       "  65: 157,\n",
       "  120: 475,\n",
       "  26: 369,\n",
       "  21: 32,\n",
       "  77: 120,\n",
       "  114: 164,\n",
       "  5: 232,\n",
       "  74: 724,\n",
       "  38: 1119,\n",
       "  115: 395,\n",
       "  119: 985,\n",
       "  89: 788,\n",
       "  84: 1283,\n",
       "  87: 1289,\n",
       "  62: 27,\n",
       "  27: 282,\n",
       "  18: 725,\n",
       "  70: 92,\n",
       "  69: 60,\n",
       "  55: 650,\n",
       "  113: 896,\n",
       "  49: 836,\n",
       "  43: 270,\n",
       "  75: 123,\n",
       "  101: 275,\n",
       "  116: 507,\n",
       "  96: 13,\n",
       "  105: 198,\n",
       "  93: 23,\n",
       "  108: 98,\n",
       "  110: 264,\n",
       "  64: 124,\n",
       "  95: 125,\n",
       "  52: 91,\n",
       "  97: 176,\n",
       "  83: 55,\n",
       "  134: 34,\n",
       "  33: 114,\n",
       "  31: 72,\n",
       "  42: 54,\n",
       "  35: 11,\n",
       "  40: 28,\n",
       "  13: 214,\n",
       "  54: 328,\n",
       "  23: 12,\n",
       "  46: 54,\n",
       "  104: 111,\n",
       "  100: 243,\n",
       "  132: 27,\n",
       "  73: 67,\n",
       "  124: 243,\n",
       "  103: 43,\n",
       "  6: 131,\n",
       "  90: 106,\n",
       "  28: 138,\n",
       "  50: 246,\n",
       "  44: 138,\n",
       "  157: 323,\n",
       "  196: 2266,\n",
       "  167: 130,\n",
       "  172: 851,\n",
       "  179: 198,\n",
       "  141: 59,\n",
       "  160: 285,\n",
       "  154: 188,\n",
       "  176: 162,\n",
       "  164: 741,\n",
       "  168: 420,\n",
       "  140: 2172,\n",
       "  169: 384,\n",
       "  186: 1663,\n",
       "  166: 31,\n",
       "  162: 316,\n",
       "  173: 365,\n",
       "  161: 337,\n",
       "  165: 868,\n",
       "  201: 1582,\n",
       "  190: 453,\n",
       "  153: 331,\n",
       "  174: 476,\n",
       "  144: 683,\n",
       "  191: 999,\n",
       "  199: 718,\n",
       "  151: 2077,\n",
       "  137: 43,\n",
       "  139: 156,\n",
       "  138: 258,\n",
       "  197: 1180,\n",
       "  193: 861,\n",
       "  171: 204,\n",
       "  150: 200,\n",
       "  180: 99,\n",
       "  188: 469,\n",
       "  194: 122,\n",
       "  189: 67,\n",
       "  181: 63,\n",
       "  159: 1199,\n",
       "  178: 1329,\n",
       "  148: 11,\n",
       "  198: 124,\n",
       "  143: 14,\n",
       "  177: 151,\n",
       "  195: 121,\n",
       "  147: 207,\n",
       "  200: 1518,\n",
       "  149: 13,\n",
       "  184: 83,\n",
       "  183: 213,\n",
       "  192: 207,\n",
       "  187: 320,\n",
       "  142: 997,\n",
       "  145: 401,\n",
       "  185: 103,\n",
       "  182: 384,\n",
       "  170: 206,\n",
       "  155: 106,\n",
       "  146: 396,\n",
       "  163: 16,\n",
       "  175: 174,\n",
       "  158: 729,\n",
       "  152: 11,\n",
       "  156: 27,\n",
       "  229: 19,\n",
       "  230: 22,\n",
       "  335: 52,\n",
       "  295: 39,\n",
       "  279: 262,\n",
       "  208: 268,\n",
       "  310: 608,\n",
       "  304: 184,\n",
       "  340: 844,\n",
       "  236: 385,\n",
       "  362: 327,\n",
       "  353: 450,\n",
       "  291: 26,\n",
       "  203: 14,\n",
       "  346: 1795,\n",
       "  360: 216,\n",
       "  228: 815,\n",
       "  235: 423,\n",
       "  293: 49,\n",
       "  287: 65,\n",
       "  290: 60,\n",
       "  242: 931,\n",
       "  356: 663,\n",
       "  254: 310,\n",
       "  325: 819,\n",
       "  253: 11,\n",
       "  384: 294,\n",
       "  282: 21,\n",
       "  225: 1499,\n",
       "  342: 529,\n",
       "  239: 773,\n",
       "  299: 345,\n",
       "  374: 714,\n",
       "  237: 174,\n",
       "  207: 315,\n",
       "  331: 1434,\n",
       "  307: 272,\n",
       "  371: 31,\n",
       "  347: 162,\n",
       "  217: 1587,\n",
       "  309: 746,\n",
       "  263: 305,\n",
       "  329: 16,\n",
       "  349: 458,\n",
       "  367: 192,\n",
       "  260: 384,\n",
       "  312: 69,\n",
       "  274: 1783,\n",
       "  289: 201,\n",
       "  339: 410,\n",
       "  214: 420,\n",
       "  380: 65,\n",
       "  313: 356,\n",
       "  278: 171,\n",
       "  350: 233,\n",
       "  233: 26,\n",
       "  205: 470,\n",
       "  328: 12,\n",
       "  311: 678,\n",
       "  379: 57,\n",
       "  334: 525,\n",
       "  211: 768,\n",
       "  305: 17,\n",
       "  332: 894,\n",
       "  255: 17,\n",
       "  308: 362,\n",
       "  209: 273,\n",
       "  249: 440,\n",
       "  266: 1382,\n",
       "  275: 54,\n",
       "  324: 13,\n",
       "  302: 297,\n",
       "  297: 83,\n",
       "  277: 108,\n",
       "  234: 279,\n",
       "  232: 71,\n",
       "  345: 418,\n",
       "  321: 93,\n",
       "  364: 457,\n",
       "  352: 20,\n",
       "  276: 79,\n",
       "  373: 1093,\n",
       "  303: 967,\n",
       "  341: 10,\n",
       "  216: 142,\n",
       "  292: 111,\n",
       "  337: 631,\n",
       "  231: 239,\n",
       "  215: 906,\n",
       "  319: 375,\n",
       "  357: 572,\n",
       "  247: 172,\n",
       "  298: 47,\n",
       "  323: 228,\n",
       "  271: 674,\n",
       "  344: 466,\n",
       "  226: 531,\n",
       "  258: 851,\n",
       "  322: 1008,\n",
       "  204: 22,\n",
       "  317: 69,\n",
       "  288: 35,\n",
       "  265: 43,\n",
       "  294: 539,\n",
       "  280: 47,\n",
       "  286: 19,\n",
       "  369: 434,\n",
       "  269: 1304,\n",
       "  306: 192,\n",
       "  213: 123,\n",
       "  267: 606,\n",
       "  223: 335,\n",
       "  262: 50,\n",
       "  359: 27,\n",
       "  218: 288,\n",
       "  300: 95,\n",
       "  221: 16,\n",
       "  251: 681,\n",
       "  382: 475,\n",
       "  383: 382,\n",
       "  259: 475,\n",
       "  206: 421,\n",
       "  257: 311,\n",
       "  202: 12,\n",
       "  363: 312,\n",
       "  316: 817,\n",
       "  268: 357,\n",
       "  378: 84,\n",
       "  330: 12,\n",
       "  243: 422,\n",
       "  224: 1518,\n",
       "  327: 1082,\n",
       "  283: 997,\n",
       "  315: 382,\n",
       "  375: 26,\n",
       "  270: 10,\n",
       "  296: 59,\n",
       "  338: 64,\n",
       "  220: 139,\n",
       "  219: 474,\n",
       "  284: 573,\n",
       "  368: 135,\n",
       "  256: 221,\n",
       "  365: 1581,\n",
       "  377: 356,\n",
       "  281: 316,\n",
       "  343: 341,\n",
       "  381: 81,\n",
       "  212: 38,\n",
       "  250: 42,\n",
       "  333: 13,\n",
       "  348: 23,\n",
       "  245: 275,\n",
       "  273: 398,\n",
       "  318: 113,\n",
       "  240: 138,\n",
       "  248: 10,\n",
       "  376: 351,\n",
       "  222: 53,\n",
       "  370: 334,\n",
       "  272: 30,\n",
       "  372: 127,\n",
       "  301: 243,\n",
       "  252: 179,\n",
       "  351: 299,\n",
       "  241: 344,\n",
       "  336: 11,\n",
       "  355: 30,\n",
       "  354: 15,\n",
       "  238: 24,\n",
       "  261: 21,\n",
       "  210: 37,\n",
       "  264: 37,\n",
       "  320: 51,\n",
       "  326: 27,\n",
       "  358: 16,\n",
       "  227: 303,\n",
       "  361: 16,\n",
       "  244: 40,\n",
       "  285: 29,\n",
       "  366: 129,\n",
       "  246: 142,\n",
       "  314: 252,\n",
       "  423: 99,\n",
       "  421: 2200,\n",
       "  498: 323,\n",
       "  515: 129,\n",
       "  426: 150,\n",
       "  505: 136,\n",
       "  490: 35,\n",
       "  495: 17,\n",
       "  501: 68,\n",
       "  424: 566,\n",
       "  461: 153,\n",
       "  386: 18,\n",
       "  459: 367,\n",
       "  418: 796,\n",
       "  428: 272,\n",
       "  444: 189,\n",
       "  527: 773,\n",
       "  521: 521,\n",
       "  463: 257,\n",
       "  395: 502,\n",
       "  516: 209,\n",
       "  387: 43,\n",
       "  506: 693,\n",
       "  468: 183,\n",
       "  486: 49,\n",
       "  476: 63,\n",
       "  406: 28,\n",
       "  485: 254,\n",
       "  509: 34,\n",
       "  504: 28,\n",
       "  411: 353,\n",
       "  402: 191,\n",
       "  524: 298,\n",
       "  470: 224,\n",
       "  438: 70,\n",
       "  507: 325,\n",
       "  440: 50,\n",
       "  531: 291,\n",
       "  432: 206,\n",
       "  522: 425,\n",
       "  412: 33,\n",
       "  478: 15,\n",
       "  385: 16,\n",
       "  513: 66,\n",
       "  416: 96,\n",
       "  454: 382,\n",
       "  415: 56,\n",
       "  399: 133,\n",
       "  497: 510,\n",
       "  526: 757,\n",
       "  474: 157,\n",
       "  388: 34,\n",
       "  397: 110,\n",
       "  503: 593,\n",
       "  446: 171,\n",
       "  391: 84,\n",
       "  442: 664,\n",
       "  408: 64,\n",
       "  464: 85,\n",
       "  429: 114,\n",
       "  508: 638,\n",
       "  488: 1087,\n",
       "  409: 233,\n",
       "  482: 232,\n",
       "  487: 10,\n",
       "  437: 453,\n",
       "  394: 240,\n",
       "  400: 52,\n",
       "  477: 77,\n",
       "  500: 87,\n",
       "  389: 15,\n",
       "  511: 49,\n",
       "  413: 185,\n",
       "  489: 79,\n",
       "  492: 156,\n",
       "  530: 85,\n",
       "  455: 135,\n",
       "  443: 222,\n",
       "  519: 50,\n",
       "  414: 309,\n",
       "  441: 66,\n",
       "  496: 21,\n",
       "  431: 35,\n",
       "  405: 893,\n",
       "  392: 98,\n",
       "  449: 419,\n",
       "  510: 341,\n",
       "  456: 30,\n",
       "  512: 61,\n",
       "  420: 29,\n",
       "  475: 121,\n",
       "  466: 39,\n",
       "  493: 2076,\n",
       "  469: 103,\n",
       "  473: 51,\n",
       "  514: 909,\n",
       "  458: 70,\n",
       "  419: 118,\n",
       "  433: 40,\n",
       "  467: 739,\n",
       "  436: 208,\n",
       "  393: 1128,\n",
       "  479: 41,\n",
       "  398: 31,\n",
       "  528: 334,\n",
       "  407: 190,\n",
       "  410: 584,\n",
       "  460: 830,\n",
       "  403: 280,\n",
       "  445: 570,\n",
       "  517: 149,\n",
       "  471: 1044,\n",
       "  483: 58,\n",
       "  435: 50,\n",
       "  472: 115,\n",
       "  450: 426,\n",
       "  525: 66,\n",
       "  390: 12,\n",
       "  401: 54,\n",
       "  457: 120,\n",
       "  480: 689,\n",
       "  465: 311,\n",
       "  518: 23,\n",
       "  499: 186,\n",
       "  523: 424,\n",
       "  494: 91,\n",
       "  404: 58,\n",
       "  451: 464,\n",
       "  434: 437,\n",
       "  427: 92,\n",
       "  491: 10,\n",
       "  502: 63,\n",
       "  462: 62,\n",
       "  453: 696,\n",
       "  422: 38,\n",
       "  484: 179,\n",
       "  396: 121,\n",
       "  439: 10,\n",
       "  425: 11,\n",
       "  417: 14,\n",
       "  448: 69,\n",
       "  430: 10,\n",
       "  520: 13,\n",
       "  529: 20,\n",
       "  447: 13,\n",
       "  481: 15,\n",
       "  452: 437,\n",
       "  597: 703,\n",
       "  609: 414,\n",
       "  543: 86,\n",
       "  546: 132,\n",
       "  574: 195,\n",
       "  615: 57,\n",
       "  611: 29,\n",
       "  586: 27,\n",
       "  605: 20,\n",
       "  539: 57,\n",
       "  579: 401,\n",
       "  560: 118,\n",
       "  571: 47,\n",
       "  584: 31,\n",
       "  554: 50,\n",
       "  568: 67,\n",
       "  556: 161,\n",
       "  564: 46,\n",
       "  540: 11,\n",
       "  558: 66,\n",
       "  557: 918,\n",
       "  535: 11,\n",
       "  580: 723,\n",
       "  602: 587,\n",
       "  624: 85,\n",
       "  582: 26,\n",
       "  549: 11,\n",
       "  617: 91,\n",
       "  536: 11,\n",
       "  583: 47,\n",
       "  551: 14,\n",
       "  578: 431,\n",
       "  590: 84,\n",
       "  610: 179,\n",
       "  601: 113,\n",
       "  553: 114,\n",
       "  600: 34,\n",
       "  542: 19,\n",
       "  596: 110,\n",
       "  608: 481,\n",
       "  552: 589,\n",
       "  575: 791,\n",
       "  599: 563,\n",
       "  603: 679,\n",
       "  613: 70,\n",
       "  623: 52,\n",
       "  606: 77,\n",
       "  619: 157,\n",
       "  592: 174,\n",
       "  604: 476,\n",
       "  566: 26,\n",
       "  587: 223,\n",
       "  545: 124,\n",
       "  627: 129,\n",
       "  538: 10,\n",
       "  594: 124,\n",
       "  588: 66,\n",
       "  585: 91,\n",
       "  620: 327,\n",
       "  622: 14,\n",
       "  569: 659,\n",
       "  550: 208,\n",
       "  559: 21,\n",
       "  595: 17,\n",
       "  570: 451,\n",
       "  626: 89,\n",
       "  565: 62,\n",
       "  541: 12,\n",
       "  537: 57,\n",
       "  616: 566,\n",
       "  577: 253,\n",
       "  593: 163,\n",
       "  589: 198,\n",
       "  562: 1121,\n",
       "  581: 381,\n",
       "  625: 1082,\n",
       "  618: 433,\n",
       "  544: 24,\n",
       "  572: 143,\n",
       "  614: 219,\n",
       "  573: 108,\n",
       "  598: 10,\n",
       "  607: 20,\n",
       "  563: 118,\n",
       "  533: 53,\n",
       "  532: 657,\n",
       "  534: 44,\n",
       "  548: 28,\n",
       "  555: 10,\n",
       "  547: 27,\n",
       "  612: 12,\n",
       "  561: 21,\n",
       "  591: 18,\n",
       "  576: 78,\n",
       "  567: 10,\n",
       "  621: 17,\n",
       "  655: 2127,\n",
       "  628: 66,\n",
       "  652: 35,\n",
       "  638: 405,\n",
       "  684: 18,\n",
       "  645: 212,\n",
       "  641: 284,\n",
       "  630: 611,\n",
       "  685: 294,\n",
       "  648: 285,\n",
       "  664: 422,\n",
       "  634: 478,\n",
       "  674: 478,\n",
       "  670: 54,\n",
       "  639: 58,\n",
       "  665: 136,\n",
       "  636: 334,\n",
       "  686: 644,\n",
       "  690: 217,\n",
       "  643: 114,\n",
       "  671: 13,\n",
       "  635: 65,\n",
       "  689: 174,\n",
       "  672: 639,\n",
       "  669: 63,\n",
       "  693: 88,\n",
       "  651: 124,\n",
       "  691: 34,\n",
       "  673: 86,\n",
       "  675: 130,\n",
       "  633: 1629,\n",
       "  642: 20,\n",
       "  688: 53,\n",
       "  682: 35,\n",
       "  683: 175,\n",
       "  687: 21,\n",
       "  653: 361,\n",
       "  692: 49,\n",
       "  679: 264,\n",
       "  649: 18,\n",
       "  650: 182,\n",
       "  632: 18,\n",
       "  662: 50,\n",
       "  680: 120,\n",
       "  677: 244,\n",
       "  681: 184,\n",
       "  640: 640,\n",
       "  667: 1694,\n",
       "  660: 1077,\n",
       "  661: 87,\n",
       "  654: 145,\n",
       "  629: 203,\n",
       "  678: 214,\n",
       "  658: 11,\n",
       "  659: 770,\n",
       "  647: 56,\n",
       "  644: 124,\n",
       "  676: 17,\n",
       "  637: 104,\n",
       "  656: 20,\n",
       "  646: 56,\n",
       "  631: 313,\n",
       "  666: 104,\n",
       "  657: 54,\n",
       "  663: 25,\n",
       "  668: 55,\n",
       "  745: 262,\n",
       "  805: 50,\n",
       "  694: 10,\n",
       "  818: 1423,\n",
       "  819: 153,\n",
       "  791: 49,\n",
       "  739: 128,\n",
       "  799: 543,\n",
       "  736: 188,\n",
       "  824: 511,\n",
       "  698: 56,\n",
       "  804: 431,\n",
       "  823: 325,\n",
       "  782: 71,\n",
       "  758: 80,\n",
       "  792: 191,\n",
       "  718: 110,\n",
       "  827: 1120,\n",
       "  831: 139,\n",
       "  844: 199,\n",
       "  770: 94,\n",
       "  720: 351,\n",
       "  821: 261,\n",
       "  725: 764,\n",
       "  802: 210,\n",
       "  702: 12,\n",
       "  699: 12,\n",
       "  822: 404,\n",
       "  753: 112,\n",
       "  813: 50,\n",
       "  837: 42,\n",
       "  794: 71,\n",
       "  713: 638,\n",
       "  722: 206,\n",
       "  843: 18,\n",
       "  744: 60,\n",
       "  705: 200,\n",
       "  700: 219,\n",
       "  800: 67,\n",
       "  752: 21,\n",
       "  695: 149,\n",
       "  730: 86,\n",
       "  760: 659,\n",
       "  740: 1553,\n",
       "  759: 318,\n",
       "  728: 81,\n",
       "  749: 38,\n",
       "  762: 111,\n",
       "  806: 563,\n",
       "  737: 92,\n",
       "  825: 164,\n",
       "  764: 130,\n",
       "  735: 1411,\n",
       "  729: 251,\n",
       "  779: 200,\n",
       "  767: 15,\n",
       "  750: 49,\n",
       "  768: 65,\n",
       "  789: 81,\n",
       "  834: 43,\n",
       "  778: 260,\n",
       "  787: 11,\n",
       "  798: 104,\n",
       "  701: 13,\n",
       "  748: 164,\n",
       "  780: 11,\n",
       "  715: 51,\n",
       "  746: 50,\n",
       "  786: 63,\n",
       "  723: 10,\n",
       "  757: 395,\n",
       "  793: 191,\n",
       "  756: 141,\n",
       "  704: 51,\n",
       "  815: 41,\n",
       "  816: 22,\n",
       "  811: 355,\n",
       "  803: 149,\n",
       "  807: 28,\n",
       "  817: 89,\n",
       "  732: 181,\n",
       "  743: 163,\n",
       "  710: 82,\n",
       "  774: 1441,\n",
       "  769: 17,\n",
       "  765: 758,\n",
       "  731: 248,\n",
       "  841: 12,\n",
       "  697: 868,\n",
       "  714: 41,\n",
       "  709: 591,\n",
       "  829: 12,\n",
       "  784: 385,\n",
       "  812: 477,\n",
       "  785: 70,\n",
       "  716: 10,\n",
       "  733: 181,\n",
       "  712: 71,\n",
       "  706: 103,\n",
       "  763: 445,\n",
       "  696: 162,\n",
       "  742: 99,\n",
       "  833: 142,\n",
       "  703: 76,\n",
       "  808: 53,\n",
       "  751: 549,\n",
       "  797: 424,\n",
       "  754: 742,\n",
       "  783: 40,\n",
       "  820: 435,\n",
       "  771: 497,\n",
       "  717: 239,\n",
       "  809: 1666,\n",
       "  781: 490,\n",
       "  838: 464,\n",
       "  719: 36,\n",
       "  788: 12,\n",
       "  810: 218,\n",
       "  773: 30,\n",
       "  721: 102,\n",
       "  777: 14,\n",
       "  741: 290,\n",
       "  839: 140,\n",
       "  734: 71,\n",
       "  772: 23,\n",
       "  707: 28,\n",
       "  842: 11,\n",
       "  727: 28,\n",
       "  830: 36,\n",
       "  761: 83,\n",
       "  826: 131,\n",
       "  726: 108,\n",
       "  840: 146,\n",
       "  711: 18,\n",
       "  755: 363,\n",
       "  790: 470,\n",
       "  795: 27,\n",
       "  766: 482,\n",
       "  814: 31,\n",
       "  801: 12,\n",
       "  828: 18,\n",
       "  775: 48,\n",
       "  836: 13,\n",
       "  747: 12,\n",
       "  835: 16,\n",
       "  724: 32,\n",
       "  776: 95,\n",
       "  708: 10,\n",
       "  738: 18,\n",
       "  832: 17,\n",
       "  796: 11,\n",
       "  989: 420,\n",
       "  961: 242,\n",
       "  852: 264,\n",
       "  909: 32,\n",
       "  894: 114,\n",
       "  939: 31,\n",
       "  940: 1324,\n",
       "  997: 1062,\n",
       "  902: 255,\n",
       "  903: 370,\n",
       "  889: 190,\n",
       "  984: 12,\n",
       "  948: 84,\n",
       "  892: 106,\n",
       "  980: 97,\n",
       "  876: 19,\n",
       "  848: 175,\n",
       "  850: 267,\n",
       "  893: 675,\n",
       "  915: 723,\n",
       "  956: 344,\n",
       "  990: 286,\n",
       "  900: 60,\n",
       "  993: 386,\n",
       "  992: 42,\n",
       "  846: 16,\n",
       "  851: 18,\n",
       "  919: 201,\n",
       "  981: 269,\n",
       "  955: 23,\n",
       "  977: 749,\n",
       "  976: 10,\n",
       "  888: 720,\n",
       "  874: 311,\n",
       "  878: 826,\n",
       "  908: 130,\n",
       "  943: 15,\n",
       "  950: 421,\n",
       "  970: 65,\n",
       "  979: 15,\n",
       "  875: 338,\n",
       "  861: 439,\n",
       "  863: 417,\n",
       "  879: 111,\n",
       "  944: 126,\n",
       "  899: 570,\n",
       "  988: 192,\n",
       "  962: 535,\n",
       "  946: 651,\n",
       "  905: 451,\n",
       "  937: 453,\n",
       "  914: 46,\n",
       "  931: 117,\n",
       "  958: 247,\n",
       "  898: 963,\n",
       "  845: 12,\n",
       "  952: 261,\n",
       "  860: 339,\n",
       "  1000: 591,\n",
       "  972: 894,\n",
       "  949: 168,\n",
       "  947: 280,\n",
       "  934: 71,\n",
       "  983: 282,\n",
       "  999: 548,\n",
       "  933: 206,\n",
       "  924: 69,\n",
       "  883: 202,\n",
       "  895: 1710,\n",
       "  985: 245,\n",
       "  929: 172,\n",
       "  884: 167,\n",
       "  960: 348,\n",
       "  978: 566,\n",
       "  857: 50,\n",
       "  858: 306,\n",
       "  928: 146,\n",
       "  907: 36,\n",
       "  925: 477,\n",
       "  969: 953,\n",
       "  867: 158,\n",
       "  918: 1133,\n",
       "  995: 546,\n",
       "  872: 38,\n",
       "  854: 278,\n",
       "  891: 201,\n",
       "  930: 361,\n",
       "  862: 172,\n",
       "  973: 114,\n",
       "  998: 113,\n",
       "  967: 204,\n",
       "  986: 86,\n",
       "  957: 121,\n",
       "  965: 255,\n",
       "  881: 76,\n",
       "  923: 245,\n",
       "  942: 28,\n",
       "  936: 33,\n",
       "  912: 91,\n",
       "  938: 85,\n",
       "  996: 44,\n",
       "  922: 57,\n",
       "  987: 132,\n",
       "  954: 451,\n",
       "  866: 64,\n",
       "  935: 171,\n",
       "  865: 377,\n",
       "  975: 27,\n",
       "  868: 360,\n",
       "  896: 24,\n",
       "  953: 15,\n",
       "  920: 411,\n",
       "  869: 27,\n",
       "  882: 107,\n",
       "  994: 165,\n",
       "  941: 50,\n",
       "  968: 147,\n",
       "  974: 598,\n",
       "  926: 20,\n",
       "  901: 339,\n",
       "  870: 1137,\n",
       "  887: 41,\n",
       "  971: 450,\n",
       "  910: 184,\n",
       "  859: 78,\n",
       "  916: 27,\n",
       "  913: 159,\n",
       "  932: 109,\n",
       "  959: 171,\n",
       "  921: 47,\n",
       "  951: 49,\n",
       "  864: 288,\n",
       "  964: 445,\n",
       "  885: 100,\n",
       "  856: 364,\n",
       "  897: 99,\n",
       "  880: 51,\n",
       "  911: 43,\n",
       "  877: 10,\n",
       "  849: 50,\n",
       "  847: 19,\n",
       "  991: 14,\n",
       "  904: 23,\n",
       "  890: 35,\n",
       "  945: 13,\n",
       "  873: 117,\n",
       "  963: 523,\n",
       "  917: 437,\n",
       "  906: 16,\n",
       "  966: 71,\n",
       "  982: 146,\n",
       "  855: 37,\n",
       "  927: 16,\n",
       "  871: 31,\n",
       "  886: 16,\n",
       "  ...},\n",
       " 'num_docs': 7696,\n",
       " 'num_pos': 1443014,\n",
       " 'num_nnz': 1043839,\n",
       " 'lifecycle_events': [{'msg': \"built Dictionary<58163 unique tokens: ['boeing', 'defense', 'kc', 'news', 'pegasus']...> from 7696 documents (total 1443014 corpus positions)\",\n",
       "   'datetime': '2023-11-15T21:21:10.905034',\n",
       "   'gensim': '4.3.1',\n",
       "   'python': '3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]',\n",
       "   'platform': 'Linux-6.2.0-36-generic-x86_64-with-glibc2.35',\n",
       "   'event': 'created'}]}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 2),\n",
       " (38, 1),\n",
       " (140, 1),\n",
       " (207, 3),\n",
       " (224, 1),\n",
       " (243, 1),\n",
       " (303, 1),\n",
       " (322, 1),\n",
       " (353, 2),\n",
       " (369, 1),\n",
       " (374, 1),\n",
       " (418, 1),\n",
       " (421, 1),\n",
       " (488, 1),\n",
       " (503, 1),\n",
       " (565, 1),\n",
       " (603, 2),\n",
       " (620, 1),\n",
       " (626, 1),\n",
       " (681, 1),\n",
       " (722, 1),\n",
       " (735, 1),\n",
       " (915, 1),\n",
       " (959, 2),\n",
       " (992, 1),\n",
       " (1014, 1),\n",
       " (1169, 1),\n",
       " (1173, 1),\n",
       " (1190, 1),\n",
       " (1205, 1),\n",
       " (1206, 1),\n",
       " (1207, 1),\n",
       " (1208, 1),\n",
       " (1209, 1),\n",
       " (1210, 1),\n",
       " (1211, 1),\n",
       " (1212, 1),\n",
       " (1213, 1),\n",
       " (1214, 1),\n",
       " (1215, 1),\n",
       " (1216, 1),\n",
       " (1217, 1),\n",
       " (1218, 1),\n",
       " (1219, 2),\n",
       " (1220, 1),\n",
       " (1221, 1),\n",
       " (1222, 1),\n",
       " (1223, 1),\n",
       " (1224, 1),\n",
       " (1225, 1),\n",
       " (1226, 1),\n",
       " (1227, 1),\n",
       " (1228, 1),\n",
       " (1229, 1),\n",
       " (1230, 1),\n",
       " (1231, 1),\n",
       " (1232, 1),\n",
       " (1233, 1),\n",
       " (1234, 1),\n",
       " (1235, 2),\n",
       " (1236, 1),\n",
       " (1237, 1),\n",
       " (1238, 1),\n",
       " (1239, 1),\n",
       " (1240, 1)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 12788\n",
      "Number of documents: 7696\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(gensim.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model.\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LdaModel in module gensim.models.ldamodel:\n",
      "\n",
      "class LdaModel(gensim.interfaces.TransformationABC, gensim.models.basemodel.BaseTopicModel)\n",
      " |  LdaModel(corpus=None, num_topics=100, id2word=None, distributed=False, chunksize=2000, passes=1, update_every=1, alpha='symmetric', eta=None, decay=0.5, offset=1.0, eval_every=10, iterations=50, gamma_threshold=0.001, minimum_probability=0.01, random_state=None, ns_conf=None, minimum_phi_value=0.01, per_word_topics=False, callbacks=None, dtype=<class 'numpy.float32'>)\n",
      " |  \n",
      " |  Train and use Online Latent Dirichlet Allocation model as presented in\n",
      " |  `'Online Learning for LDA' by Hoffman et al.`_\n",
      " |  \n",
      " |  Examples\n",
      " |  -------\n",
      " |  Initialize a model using a Gensim corpus\n",
      " |  \n",
      " |  .. sourcecode:: pycon\n",
      " |  \n",
      " |      >>> from gensim.test.utils import common_corpus\n",
      " |      >>>\n",
      " |      >>> lda = LdaModel(common_corpus, num_topics=10)\n",
      " |  \n",
      " |  You can then infer topic distributions on new, unseen documents.\n",
      " |  \n",
      " |  .. sourcecode:: pycon\n",
      " |  \n",
      " |      >>> doc_bow = [(1, 0.3), (2, 0.1), (0, 0.09)]\n",
      " |      >>> doc_lda = lda[doc_bow]\n",
      " |  \n",
      " |  The model can be updated (trained) with new documents.\n",
      " |  \n",
      " |  .. sourcecode:: pycon\n",
      " |  \n",
      " |      >>> # In practice (corpus =/= initial training corpus), but we use the same here for simplicity.\n",
      " |      >>> other_corpus = common_corpus\n",
      " |      >>>\n",
      " |      >>> lda.update(other_corpus)\n",
      " |  \n",
      " |  Model persistency is achieved through :meth:`~gensim.models.ldamodel.LdaModel.load` and\n",
      " |  :meth:`~gensim.models.ldamodel.LdaModel.save` methods.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LdaModel\n",
      " |      gensim.interfaces.TransformationABC\n",
      " |      gensim.utils.SaveLoad\n",
      " |      gensim.models.basemodel.BaseTopicModel\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, bow, eps=None)\n",
      " |      Get the topic distribution for the given document.\n",
      " |      \n",
      " |      Wraps :meth:`~gensim.models.ldamodel.LdaModel.get_document_topics` to support an operator style call.\n",
      " |      Uses the model's current state (set using constructor arguments) to fill in the additional arguments of the\n",
      " |      wrapper method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ---------\n",
      " |      bow : list of (int, float)\n",
      " |          The document in BOW format.\n",
      " |      eps : float, optional\n",
      " |          Topics with an assigned probability lower than this threshold will be discarded.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, float)\n",
      " |          Topic distribution for the given document. Each topic is represented as a pair of its ID and the probability\n",
      " |          assigned to it.\n",
      " |  \n",
      " |  __init__(self, corpus=None, num_topics=100, id2word=None, distributed=False, chunksize=2000, passes=1, update_every=1, alpha='symmetric', eta=None, decay=0.5, offset=1.0, eval_every=10, iterations=50, gamma_threshold=0.001, minimum_probability=0.01, random_state=None, ns_conf=None, minimum_phi_value=0.01, per_word_topics=False, callbacks=None, dtype=<class 'numpy.float32'>)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : iterable of list of (int, float), optional\n",
      " |          Stream of document vectors or sparse matrix of shape (`num_documents`, `num_terms`).\n",
      " |          If you have a CSC in-memory matrix, you can convert it to a\n",
      " |          streamed corpus with the help of gensim.matutils.Sparse2Corpus.\n",
      " |          If not given, the model is left untrained (presumably because you want to call\n",
      " |          :meth:`~gensim.models.ldamodel.LdaModel.update` manually).\n",
      " |      num_topics : int, optional\n",
      " |          The number of requested latent topics to be extracted from the training corpus.\n",
      " |      id2word : {dict of (int, str), :class:`gensim.corpora.dictionary.Dictionary`}\n",
      " |          Mapping from word IDs to words. It is used to determine the vocabulary size, as well as for\n",
      " |          debugging and topic printing.\n",
      " |      distributed : bool, optional\n",
      " |          Whether distributed computing should be used to accelerate training.\n",
      " |      chunksize :  int, optional\n",
      " |          Number of documents to be used in each training chunk.\n",
      " |      passes : int, optional\n",
      " |          Number of passes through the corpus during training.\n",
      " |      update_every : int, optional\n",
      " |          Number of documents to be iterated through for each update.\n",
      " |          Set to 0 for batch learning, > 1 for online iterative learning.\n",
      " |      alpha : {float, numpy.ndarray of float, list of float, str}, optional\n",
      " |          A-priori belief on document-topic distribution, this can be:\n",
      " |              * scalar for a symmetric prior over document-topic distribution,\n",
      " |              * 1D array of length equal to num_topics to denote an asymmetric user defined prior for each topic.\n",
      " |      \n",
      " |          Alternatively default prior selecting strategies can be employed by supplying a string:\n",
      " |              * 'symmetric': (default) Uses a fixed symmetric prior of `1.0 / num_topics`,\n",
      " |              * 'asymmetric': Uses a fixed normalized asymmetric prior of `1.0 / (topic_index + sqrt(num_topics))`,\n",
      " |              * 'auto': Learns an asymmetric prior from the corpus (not available if `distributed==True`).\n",
      " |      eta : {float, numpy.ndarray of float, list of float, str}, optional\n",
      " |          A-priori belief on topic-word distribution, this can be:\n",
      " |              * scalar for a symmetric prior over topic-word distribution,\n",
      " |              * 1D array of length equal to num_words to denote an asymmetric user defined prior for each word,\n",
      " |              * matrix of shape (num_topics, num_words) to assign a probability for each word-topic combination.\n",
      " |      \n",
      " |          Alternatively default prior selecting strategies can be employed by supplying a string:\n",
      " |              * 'symmetric': (default) Uses a fixed symmetric prior of `1.0 / num_topics`,\n",
      " |              * 'auto': Learns an asymmetric prior from the corpus.\n",
      " |      decay : float, optional\n",
      " |          A number between (0.5, 1] to weight what percentage of the previous lambda value is forgotten\n",
      " |          when each new document is examined.\n",
      " |          Corresponds to :math:`\\kappa` from `'Online Learning for LDA' by Hoffman et al.`_\n",
      " |      offset : float, optional\n",
      " |          Hyper-parameter that controls how much we will slow down the first steps the first few iterations.\n",
      " |          Corresponds to :math:`\\tau_0` from `'Online Learning for LDA' by Hoffman et al.`_\n",
      " |      eval_every : int, optional\n",
      " |          Log perplexity is estimated every that many updates. Setting this to one slows down training by ~2x.\n",
      " |      iterations : int, optional\n",
      " |          Maximum number of iterations through the corpus when inferring the topic distribution of a corpus.\n",
      " |      gamma_threshold : float, optional\n",
      " |          Minimum change in the value of the gamma parameters to continue iterating.\n",
      " |      minimum_probability : float, optional\n",
      " |          Topics with a probability lower than this threshold will be filtered out.\n",
      " |      random_state : {np.random.RandomState, int}, optional\n",
      " |          Either a randomState object or a seed to generate one. Useful for reproducibility.\n",
      " |      ns_conf : dict of (str, object), optional\n",
      " |          Key word parameters propagated to :func:`gensim.utils.getNS` to get a Pyro4 nameserver.\n",
      " |          Only used if `distributed` is set to True.\n",
      " |      minimum_phi_value : float, optional\n",
      " |          if `per_word_topics` is True, this represents a lower bound on the term probabilities.\n",
      " |      per_word_topics : bool\n",
      " |          If True, the model also computes a list of topics, sorted in descending order of most likely topics for\n",
      " |          each word, along with their phi values multiplied by the feature length (i.e. word count).\n",
      " |      callbacks : list of :class:`~gensim.models.callbacks.Callback`\n",
      " |          Metric callbacks to log and visualize evaluation metrics of the model during training.\n",
      " |      dtype : {numpy.float16, numpy.float32, numpy.float64}, optional\n",
      " |          Data-type to use during calculations inside model. All inputs are also converted.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Get a string representation of the current object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Human readable representation of the most important model parameters.\n",
      " |  \n",
      " |  bound(self, corpus, gamma=None, subsample_ratio=1.0)\n",
      " |      Estimate the variational bound of documents from the corpus as E_q[log p(corpus)] - E_q[log q(corpus)].\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : iterable of list of (int, float), optional\n",
      " |          Stream of document vectors or sparse matrix of shape (`num_documents`, `num_terms`) used to estimate the\n",
      " |          variational bounds.\n",
      " |      gamma : numpy.ndarray, optional\n",
      " |          Topic weight variational parameters for each document. If not supplied, it will be inferred from the model.\n",
      " |      subsample_ratio : float, optional\n",
      " |          Percentage of the whole corpus represented by the passed `corpus` argument (in case this was a sample).\n",
      " |          Set to 1.0 if the whole corpus was passed.This is used as a multiplicative factor to scale the likelihood\n",
      " |          appropriately.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The variational bound score calculated for each document.\n",
      " |  \n",
      " |  clear(self)\n",
      " |      Clear the model's state to free some memory. Used in the distributed implementation.\n",
      " |  \n",
      " |  diff(self, other, distance='kullback_leibler', num_words=100, n_ann_terms=10, diagonal=False, annotation=True, normed=True)\n",
      " |      Calculate the difference in topic distributions between two models: `self` and `other`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : :class:`~gensim.models.ldamodel.LdaModel`\n",
      " |          The model which will be compared against the current object.\n",
      " |      distance : {'kullback_leibler', 'hellinger', 'jaccard', 'jensen_shannon'}\n",
      " |          The distance metric to calculate the difference with.\n",
      " |      num_words : int, optional\n",
      " |          The number of most relevant words used if `distance == 'jaccard'`. Also used for annotating topics.\n",
      " |      n_ann_terms : int, optional\n",
      " |          Max number of words in intersection/symmetric difference between topics. Used for annotation.\n",
      " |      diagonal : bool, optional\n",
      " |          Whether we need the difference between identical topics (the diagonal of the difference matrix).\n",
      " |      annotation : bool, optional\n",
      " |          Whether the intersection or difference of words between two topics should be returned.\n",
      " |      normed : bool, optional\n",
      " |          Whether the matrix should be normalized or not.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          A difference matrix. Each element corresponds to the difference between the two topics,\n",
      " |          shape (`self.num_topics`, `other.num_topics`)\n",
      " |      numpy.ndarray, optional\n",
      " |          Annotation matrix where for each pair we include the word from the intersection of the two topics,\n",
      " |          and the word from the symmetric difference of the two topics. Only included if `annotation == True`.\n",
      " |          Shape (`self.num_topics`, `other_model.num_topics`, 2).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Get the differences between each pair of topics inferred by two models\n",
      " |      \n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.models.ldamulticore import LdaMulticore\n",
      " |          >>> from gensim.test.utils import datapath\n",
      " |          >>>\n",
      " |          >>> m1 = LdaMulticore.load(datapath(\"lda_3_0_1_model\"))\n",
      " |          >>> m2 = LdaMulticore.load(datapath(\"ldamodel_python_3_5\"))\n",
      " |          >>> mdiff, annotation = m1.diff(m2)\n",
      " |          >>> topic_diff = mdiff  # get matrix with difference for each topic pair from `m1` and `m2`\n",
      " |  \n",
      " |  do_estep(self, chunk, state=None)\n",
      " |      Perform inference on a chunk of documents, and accumulate the collected sufficient statistics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      chunk : list of list of (int, float)\n",
      " |          The corpus chunk on which the inference step will be performed.\n",
      " |      state : :class:`~gensim.models.ldamodel.LdaState`, optional\n",
      " |          The state to be updated with the newly accumulated sufficient statistics. If none, the models\n",
      " |          `self.state` is updated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          Gamma parameters controlling the topic weights, shape (`len(chunk)`, `self.num_topics`).\n",
      " |  \n",
      " |  do_mstep(self, rho, other, extra_pass=False)\n",
      " |      Maximization step: use linear interpolation between the existing topics and\n",
      " |      collected sufficient statistics in `other` to update the topics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rho : float\n",
      " |          Learning rate.\n",
      " |      other : :class:`~gensim.models.ldamodel.LdaModel`\n",
      " |          The model whose sufficient statistics will be used to update the topics.\n",
      " |      extra_pass : bool, optional\n",
      " |          Whether this step required an additional pass over the corpus.\n",
      " |  \n",
      " |  get_document_topics(self, bow, minimum_probability=None, minimum_phi_value=None, per_word_topics=False)\n",
      " |      Get the topic distribution for the given document.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      bow : corpus : list of (int, float)\n",
      " |          The document in BOW format.\n",
      " |      minimum_probability : float\n",
      " |          Topics with an assigned probability lower than this threshold will be discarded.\n",
      " |      minimum_phi_value : float\n",
      " |          If `per_word_topics` is True, this represents a lower bound on the term probabilities that are included.\n",
      " |           If set to None, a value of 1e-8 is used to prevent 0s.\n",
      " |      per_word_topics : bool\n",
      " |          If True, this function will also return two extra lists as explained in the \"Returns\" section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, float)\n",
      " |          Topic distribution for the whole document. Each element in the list is a pair of a topic's id, and\n",
      " |          the probability that was assigned to it.\n",
      " |      list of (int, list of (int, float), optional\n",
      " |          Most probable topics per word. Each element in the list is a pair of a word's id, and a list of\n",
      " |          topics sorted by their relevance to this word. Only returned if `per_word_topics` was set to True.\n",
      " |      list of (int, list of float), optional\n",
      " |          Phi relevance values, multiplied by the feature length, for each word-topic combination.\n",
      " |          Each element in the list is a pair of a word's id and a list of the phi values between this word and\n",
      " |          each topic. Only returned if `per_word_topics` was set to True.\n",
      " |  \n",
      " |  get_term_topics(self, word_id, minimum_probability=None)\n",
      " |      Get the most relevant topics to the given word.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      word_id : int\n",
      " |          The word for which the topic distribution will be computed.\n",
      " |      minimum_probability : float, optional\n",
      " |          Topics with an assigned probability below this threshold will be discarded.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, float)\n",
      " |          The relevant topics represented as pairs of their ID and their assigned probability, sorted\n",
      " |          by relevance to the given word.\n",
      " |  \n",
      " |  get_topic_terms(self, topicid, topn=10)\n",
      " |      Get the representation for a single topic. Words the integer IDs, in constrast to\n",
      " |      :meth:`~gensim.models.ldamodel.LdaModel.show_topic` that represents words by the actual strings.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      topicid : int\n",
      " |          The ID of the topic to be returned\n",
      " |      topn : int, optional\n",
      " |          Number of the most significant words that are associated with the topic.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, float)\n",
      " |          Word ID - probability pairs for the most relevant words generated by the topic.\n",
      " |  \n",
      " |  get_topics(self)\n",
      " |      Get the term-topic matrix learned during inference.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The probability for each word in each topic, shape (`num_topics`, `vocabulary_size`).\n",
      " |  \n",
      " |  inference(self, chunk, collect_sstats=False)\n",
      " |      Given a chunk of sparse document vectors, estimate gamma (parameters controlling the topic weights)\n",
      " |      for each document in the chunk.\n",
      " |      \n",
      " |      This function does not modify the model. The whole input chunk of document is assumed to fit in RAM;\n",
      " |      chunking of a large corpus must be done earlier in the pipeline. Avoids computing the `phi` variational\n",
      " |      parameter directly using the optimization presented in\n",
      " |      `Lee, Seung: Algorithms for non-negative matrix factorization\"\n",
      " |      <https://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization.pdf>`_.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      chunk : list of list of (int, float)\n",
      " |          The corpus chunk on which the inference step will be performed.\n",
      " |      collect_sstats : bool, optional\n",
      " |          If set to True, also collect (and return) sufficient statistics needed to update the model's topic-word\n",
      " |          distributions.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (numpy.ndarray, {numpy.ndarray, None})\n",
      " |          The first element is always returned and it corresponds to the states gamma matrix. The second element is\n",
      " |          only returned if `collect_sstats` == True and corresponds to the sufficient statistics for the M step.\n",
      " |  \n",
      " |  init_dir_prior(self, prior, name)\n",
      " |      Initialize priors for the Dirichlet distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prior : {float, numpy.ndarray of float, list of float, str}\n",
      " |          A-priori belief on document-topic distribution. If `name` == 'alpha', then the prior can be:\n",
      " |              * scalar for a symmetric prior over document-topic distribution,\n",
      " |              * 1D array of length equal to num_topics to denote an asymmetric user defined prior for each topic.\n",
      " |      \n",
      " |          Alternatively default prior selecting strategies can be employed by supplying a string:\n",
      " |              * 'symmetric': (default) Uses a fixed symmetric prior of `1.0 / num_topics`,\n",
      " |              * 'asymmetric': Uses a fixed normalized asymmetric prior of `1.0 / (topic_index + sqrt(num_topics))`,\n",
      " |              * 'auto': Learns an asymmetric prior from the corpus (not available if `distributed==True`).\n",
      " |      \n",
      " |          A-priori belief on topic-word distribution. If `name` == 'eta' then the prior can be:\n",
      " |              * scalar for a symmetric prior over topic-word distribution,\n",
      " |              * 1D array of length equal to num_words to denote an asymmetric user defined prior for each word,\n",
      " |              * matrix of shape (num_topics, num_words) to assign a probability for each word-topic combination.\n",
      " |      \n",
      " |          Alternatively default prior selecting strategies can be employed by supplying a string:\n",
      " |              * 'symmetric': (default) Uses a fixed symmetric prior of `1.0 / num_topics`,\n",
      " |              * 'auto': Learns an asymmetric prior from the corpus.\n",
      " |      name : {'alpha', 'eta'}\n",
      " |          Whether the `prior` is parameterized by the alpha vector (1 parameter per topic)\n",
      " |          or by the eta (1 parameter per unique term in the vocabulary).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      init_prior: numpy.ndarray\n",
      " |          Initialized Dirichlet prior:\n",
      " |          If 'alpha' was provided as `name` the shape is (self.num_topics, ).\n",
      " |          If 'eta' was provided as `name` the shape is (len(self.id2word), ).\n",
      " |      is_auto: bool\n",
      " |          Flag that shows if hyperparameter optimization should be used or not.\n",
      " |  \n",
      " |  log_perplexity(self, chunk, total_docs=None)\n",
      " |      Calculate and return per-word likelihood bound, using a chunk of documents as evaluation corpus.\n",
      " |      \n",
      " |      Also output the calculated statistics, including the perplexity=2^(-bound), to log at INFO level.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      chunk : list of list of (int, float)\n",
      " |          The corpus chunk on which the inference step will be performed.\n",
      " |      total_docs : int, optional\n",
      " |          Number of docs used for evaluation of the perplexity.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The variational bound score calculated for each word.\n",
      " |  \n",
      " |  save(self, fname, ignore=('state', 'dispatcher'), separately=None, *args, **kwargs)\n",
      " |      Save the model to a file.\n",
      " |      \n",
      " |      Large internal arrays may be stored into separate files, with `fname` as prefix.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If you intend to use models across Python 2/3 versions there are a few things to\n",
      " |      keep in mind:\n",
      " |      \n",
      " |        1. The pickled Python dictionaries will not work across Python versions\n",
      " |        2. The `save` method does not automatically save all numpy arrays separately, only\n",
      " |           those ones that exceed `sep_limit` set in :meth:`~gensim.utils.SaveLoad.save`. The main\n",
      " |           concern here is the `alpha` array if for instance using `alpha='auto'`.\n",
      " |      \n",
      " |      Please refer to the `wiki recipes section\n",
      " |      <https://github.com/RaRe-Technologies/gensim/wiki/\n",
      " |      Recipes-&-FAQ#q9-how-do-i-load-a-model-in-python-3-that-was-trained-and-saved-using-python-2>`_\n",
      " |      for an example on how to work around these issues.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.models.ldamodel.LdaModel.load`\n",
      " |          Load model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to the system file where the model will be persisted.\n",
      " |      ignore : tuple of str, optional\n",
      " |          The named attributes in the tuple will be left out of the pickled model. The reason why\n",
      " |          the internal `state` is ignored by default is that it uses its own serialisation rather than the one\n",
      " |          provided by this method.\n",
      " |      separately : {list of str, None}, optional\n",
      " |          If None -  automatically detect large numpy/scipy.sparse arrays in the object being stored, and store\n",
      " |          them into separate files. This avoids pickle memory errors and allows `mmap`'ing large arrays\n",
      " |          back on load efficiently. If list of str - this attributes will be stored in separate files,\n",
      " |          the automatic check is not performed in this case.\n",
      " |      *args\n",
      " |          Positional arguments propagated to :meth:`~gensim.utils.SaveLoad.save`.\n",
      " |      **kwargs\n",
      " |          Key word arguments propagated to :meth:`~gensim.utils.SaveLoad.save`.\n",
      " |  \n",
      " |  show_topic(self, topicid, topn=10)\n",
      " |      Get the representation for a single topic. Words here are the actual strings, in constrast to\n",
      " |      :meth:`~gensim.models.ldamodel.LdaModel.get_topic_terms` that represents words by their vocabulary ID.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      topicid : int\n",
      " |          The ID of the topic to be returned\n",
      " |      topn : int, optional\n",
      " |          Number of the most significant words that are associated with the topic.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (str, float)\n",
      " |          Word - probability pairs for the most relevant words generated by the topic.\n",
      " |  \n",
      " |  show_topics(self, num_topics=10, num_words=10, log=False, formatted=True)\n",
      " |      Get a representation for selected topics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          Number of topics to be returned. Unlike LSA, there is no natural ordering between the topics in LDA.\n",
      " |          The returned topics subset of all topics is therefore arbitrary and may change between two LDA\n",
      " |          training runs.\n",
      " |      num_words : int, optional\n",
      " |          Number of words to be presented for each topic. These will be the most relevant words (assigned the highest\n",
      " |          probability for each topic).\n",
      " |      log : bool, optional\n",
      " |          Whether the output is also logged, besides being returned.\n",
      " |      formatted : bool, optional\n",
      " |          Whether the topic representations should be formatted as strings. If False, they are returned as\n",
      " |          2 tuples of (word, probability).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of {str, tuple of (str, float)}\n",
      " |          a list of topics, each represented either as a string (when `formatted` == True) or word-probability\n",
      " |          pairs.\n",
      " |  \n",
      " |  sync_state(self, current_Elogbeta=None)\n",
      " |      Propagate the states topic probabilities to the inner object's attribute.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      current_Elogbeta: numpy.ndarray\n",
      " |          Posterior probabilities for each topic, optional.\n",
      " |          If omitted, it will get Elogbeta from state.\n",
      " |  \n",
      " |  top_topics(self, corpus=None, texts=None, dictionary=None, window_size=None, coherence='u_mass', topn=20, processes=-1)\n",
      " |      Get the topics with the highest coherence score the coherence for each topic.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : iterable of list of (int, float), optional\n",
      " |          Corpus in BoW format.\n",
      " |      texts : list of list of str, optional\n",
      " |          Tokenized texts, needed for coherence models that use sliding window based (i.e. coherence=`c_something`)\n",
      " |          probability estimator .\n",
      " |      dictionary : :class:`~gensim.corpora.dictionary.Dictionary`, optional\n",
      " |          Gensim dictionary mapping of id word to create corpus.\n",
      " |          If `model.id2word` is present, this is not needed. If both are provided, passed `dictionary` will be used.\n",
      " |      window_size : int, optional\n",
      " |          Is the size of the window to be used for coherence measures using boolean sliding window as their\n",
      " |          probability estimator. For 'u_mass' this doesn't matter.\n",
      " |          If None - the default window sizes are used which are: 'c_v' - 110, 'c_uci' - 10, 'c_npmi' - 10.\n",
      " |      coherence : {'u_mass', 'c_v', 'c_uci', 'c_npmi'}, optional\n",
      " |          Coherence measure to be used.\n",
      " |          Fastest method - 'u_mass', 'c_uci' also known as `c_pmi`.\n",
      " |          For 'u_mass' corpus should be provided, if texts is provided, it will be converted to corpus\n",
      " |          using the dictionary. For 'c_v', 'c_uci' and 'c_npmi' `texts` should be provided (`corpus` isn't needed)\n",
      " |      topn : int, optional\n",
      " |          Integer corresponding to the number of top words to be extracted from each topic.\n",
      " |      processes : int, optional\n",
      " |          Number of processes to use for probability estimation phase, any value less than 1 will be interpreted as\n",
      " |          num_cpus - 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (list of (int, str), float)\n",
      " |          Each element in the list is a pair of a topic representation and its coherence score. Topic representations\n",
      " |          are distributions of words, represented as a list of pairs of word IDs and their probabilities.\n",
      " |  \n",
      " |  update(self, corpus, chunksize=None, decay=None, offset=None, passes=None, update_every=None, eval_every=None, iterations=None, gamma_threshold=None, chunks_as_numpy=False)\n",
      " |      Train the model with new documents, by EM-iterating over the corpus until the topics converge, or until\n",
      " |      the maximum number of allowed iterations is reached. `corpus` must be an iterable.\n",
      " |      \n",
      " |      In distributed mode, the E step is distributed over a cluster of machines.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This update also supports updating an already trained model (`self`) with new documents from `corpus`;\n",
      " |      the two models are then merged in proportion to the number of old vs. new documents.\n",
      " |      This feature is still experimental for non-stationary input streams.\n",
      " |      \n",
      " |      For stationary input (no topic drift in new documents), on the other hand,\n",
      " |      this equals the online update of `'Online Learning for LDA' by Hoffman et al.`_\n",
      " |      and is guaranteed to converge for any `decay` in (0.5, 1].\n",
      " |      Additionally, for smaller corpus sizes,\n",
      " |      an increasing `offset` may be beneficial (see Table 1 in the same paper).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : iterable of list of (int, float), optional\n",
      " |          Stream of document vectors or sparse matrix of shape (`num_documents`, `num_terms`) used to update the\n",
      " |          model.\n",
      " |      chunksize :  int, optional\n",
      " |          Number of documents to be used in each training chunk.\n",
      " |      decay : float, optional\n",
      " |          A number between (0.5, 1] to weight what percentage of the previous lambda value is forgotten\n",
      " |          when each new document is examined. Corresponds to :math:`\\kappa` from\n",
      " |          `'Online Learning for LDA' by Hoffman et al.`_\n",
      " |      offset : float, optional\n",
      " |          Hyper-parameter that controls how much we will slow down the first steps the first few iterations.\n",
      " |          Corresponds to :math:`\\tau_0` from `'Online Learning for LDA' by Hoffman et al.`_\n",
      " |      passes : int, optional\n",
      " |          Number of passes through the corpus during training.\n",
      " |      update_every : int, optional\n",
      " |          Number of documents to be iterated through for each update.\n",
      " |          Set to 0 for batch learning, > 1 for online iterative learning.\n",
      " |      eval_every : int, optional\n",
      " |          Log perplexity is estimated every that many updates. Setting this to one slows down training by ~2x.\n",
      " |      iterations : int, optional\n",
      " |          Maximum number of iterations through the corpus when inferring the topic distribution of a corpus.\n",
      " |      gamma_threshold : float, optional\n",
      " |          Minimum change in the value of the gamma parameters to continue iterating.\n",
      " |      chunks_as_numpy : bool, optional\n",
      " |          Whether each chunk passed to the inference step should be a numpy.ndarray or not. Numpy can in some settings\n",
      " |          turn the term IDs into floats, these will be converted back into integers in inference, which incurs a\n",
      " |          performance hit. For distributed computing it may be desirable to keep the chunks as `numpy.ndarray`.\n",
      " |  \n",
      " |  update_alpha(self, gammat, rho)\n",
      " |      Update parameters for the Dirichlet prior on the per-document topic weights.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      gammat : numpy.ndarray\n",
      " |          Previous topic weight parameters.\n",
      " |      rho : float\n",
      " |          Learning rate.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          Sequence of alpha parameters.\n",
      " |  \n",
      " |  update_eta(self, lambdat, rho)\n",
      " |      Update parameters for the Dirichlet prior on the per-topic word weights.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lambdat : numpy.ndarray\n",
      " |          Previous lambda parameters.\n",
      " |      rho : float\n",
      " |          Learning rate.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The updated eta parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  load(fname, *args, **kwargs) from builtins.type\n",
      " |      Load a previously saved :class:`gensim.models.ldamodel.LdaModel` from file.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.models.ldamodel.LdaModel.save`\n",
      " |          Save model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to the file where the model is stored.\n",
      " |      *args\n",
      " |          Positional arguments propagated to :meth:`~gensim.utils.SaveLoad.load`.\n",
      " |      **kwargs\n",
      " |          Key word arguments propagated to :meth:`~gensim.utils.SaveLoad.load`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Large arrays can be memmap'ed back as read-only (shared memory) by setting `mmap='r'`:\n",
      " |      \n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.test.utils import datapath\n",
      " |          >>>\n",
      " |          >>> fname = datapath(\"lda_3_0_1_model\")\n",
      " |          >>> lda = LdaModel.load(fname, mmap='r')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  add_lifecycle_event(self, event_name, log_level=20, **event)\n",
      " |      Append an event into the `lifecycle_events` attribute of this object, and also\n",
      " |      optionally log the event at `log_level`.\n",
      " |      \n",
      " |      Events are important moments during the object's life, such as \"model created\",\n",
      " |      \"model saved\", \"model loaded\", etc.\n",
      " |      \n",
      " |      The `lifecycle_events` attribute is persisted across object's :meth:`~gensim.utils.SaveLoad.save`\n",
      " |      and :meth:`~gensim.utils.SaveLoad.load` operations. It has no impact on the use of the model,\n",
      " |      but is useful during debugging and support.\n",
      " |      \n",
      " |      Set `self.lifecycle_events = None` to disable this behaviour. Calls to `add_lifecycle_event()`\n",
      " |      will not record events into `self.lifecycle_events` then.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      event_name : str\n",
      " |          Name of the event. Can be any label, e.g. \"created\", \"stored\" etc.\n",
      " |      event : dict\n",
      " |          Key-value mapping to append to `self.lifecycle_events`. Should be JSON-serializable, so keep it simple.\n",
      " |          Can be empty.\n",
      " |      \n",
      " |          This method will automatically add the following key-values to `event`, so you don't have to specify them:\n",
      " |      \n",
      " |          - `datetime`: the current date & time\n",
      " |          - `gensim`: the current Gensim version\n",
      " |          - `python`: the current Python version\n",
      " |          - `platform`: the current platform\n",
      " |          - `event`: the name of this event\n",
      " |      log_level : int\n",
      " |          Also log the complete event dict, at the specified log level. Set to False to not log at all.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.models.basemodel.BaseTopicModel:\n",
      " |  \n",
      " |  print_topic(self, topicno, topn=10)\n",
      " |      Get a single topic as a formatted string.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      topicno : int\n",
      " |          Topic id.\n",
      " |      topn : int\n",
      " |          Number of words from topic that will be used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          String representation of topic, like '-0.340 * \"category\" + 0.298 * \"$M$\" + 0.183 * \"algebra\" + ... '.\n",
      " |  \n",
      " |  print_topics(self, num_topics=20, num_words=10)\n",
      " |      Get the most significant topics (alias for `show_topics()` method).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          The number of topics to be selected, if -1 - all topics will be in result (ordered by significance).\n",
      " |      num_words : int, optional\n",
      " |          The number of words to be included per topics (ordered by significance).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, list of (str, float))\n",
      " |          Sequence with (topic_id, [(word, value), ... ]).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LdaModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters.\n",
    "num_topics = 20\n",
    "chunksize = 4000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 8.03 s, total: 1min 56s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = gensim.models.ldamulticore.LdaMulticore(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every,\n",
    "    workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = model.top_topics(corpus, topn=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.009388572, 'животное'),\n",
       "  (0.009366363, 'вид'),\n",
       "  (0.008939142, 'группа'),\n",
       "  (0.006167194, 'автор'),\n",
       "  (0.0052563064, 'исследователь'),\n",
       "  (0.004864744, 'самец'),\n",
       "  (0.0044457125, 'самка'),\n",
       "  (0.004400223, 'поведение'),\n",
       "  (0.004369414, 'оказаться'),\n",
       "  (0.004333529, 'птица'),\n",
       "  (0.0039903056, 'показать'),\n",
       "  (0.0037715235, 'журнал'),\n",
       "  (0.0036913317, 'эксперимент'),\n",
       "  (0.0035604218, 'процент'),\n",
       "  (0.0033899765, 'статья'),\n",
       "  (0.0033501445, 'рыба'),\n",
       "  (0.0033367102, 'университет'),\n",
       "  (0.0033168292, 'разный'),\n",
       "  (0.0032850013, 'большой'),\n",
       "  (0.0032712186, 'пища'),\n",
       "  (0.0032168317, 'обнаружить'),\n",
       "  (0.0031740027, 'друг'),\n",
       "  (0.0031048711, 'случай'),\n",
       "  (0.0030867446, 'результат'),\n",
       "  (0.0030642047, 'собака'),\n",
       "  (0.0028918143, 'растение'),\n",
       "  (0.0028632795, 'особь'),\n",
       "  (0.0027550326, 'шимпанзе'),\n",
       "  (0.0027445056, 'of'),\n",
       "  (0.0027265442, 'всё'),\n",
       "  (0.0025962626, 'количество'),\n",
       "  (0.0025851778, 'некоторый'),\n",
       "  (0.0025117865, 'звук'),\n",
       "  (0.0024331536, 'несколько'),\n",
       "  (0.0023590983, 'насекомое'),\n",
       "  (0.0023507194, 'образ'),\n",
       "  (0.0023282978, 'популяция'),\n",
       "  (0.002301691, 'способность'),\n",
       "  (0.002299956, 'слово'),\n",
       "  (0.0022035807, 'обезьяна')],\n",
       " -2.104204966051973)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.45042276), (4, 0.010448395), (5, 0.21714069), (9, 0.31626222)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model[corpus[300]]\n",
    "\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9953092932701111"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([t[1] for t in vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Первый аппарат миссии «Экзомарс» успешно стартовал с российского космодрома Байконур. Ракета-носитель «Протон-М» отработала штатно, произошло отделение первой и второй ступени, а также головного обтекателя. Первый сигнал ожидается 15 марта в 00:29 по московскому времени. Запуск транслировался в прямом эфире.На первом этапе полета — первые шесть недель — зонд будет вводиться в эксплуатацию, будут проводиться тесты оборудования. Затем в июле модуль Trace Gas Orbiter скорректирует свою траекторию. Аппарат достигнет красной планеты примерно 19 октября.По достижении орбиты планеты аппарат освободит крепления спускаемого модуля «Скиапарелли» и выйдет на орбиту высотой несколько сотен километров. Главная задача Trace Gas Orbiter — спектроскопический анализ атмосферы и поиск в ней следов метана. Задача же «Скиапарелли» — отработка технологии посадки. На поверхности планеты он проработает всего несколько дней, впервые сделав замеры электрических полей, чтобы определить их роль в пылевых бурях.Выбор даты обусловлен минимальным расстоянием между Землей и Марсом. Второй аппарат миссии отправится с Земли в 2018 году, во время великого противостояния, когда расстояние между планетами составит около 58 миллионов километров.Владимир Королёв\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(texts[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.012502011, 'компьютер'),\n",
       "  (0.009208937, 'raspberry_pi'),\n",
       "  (0.008691674, 'квантовый_компьютер'),\n",
       "  (0.008122121, 'cas'),\n",
       "  (0.007926604, 'crispr'),\n",
       "  (0.0077464515, 'crispr_cas'),\n",
       "  (0.0062066875, 'система_crispr'),\n",
       "  (0.0056438358, 'геном'),\n",
       "  (0.0053471248, 'pi'),\n",
       "  (0.005282883, 'технология'),\n",
       "  (0.0052618147, 'редактирование_геном'),\n",
       "  (0.0050939517, 'процессор'),\n",
       "  (0.004581097, 'квантовый'),\n",
       "  (0.0041720015, 'raspberry'),\n",
       "  (0.0039178357, 'компания'),\n",
       "  (0.0038469962, 'память'),\n",
       "  (0.003811892, 'рнк'),\n",
       "  (0.0037756753, 'вич'),\n",
       "  (0.0035278471, 'технология_crispr'),\n",
       "  (0.0033364177, 'позволять'),\n",
       "  (0.003318232, 'операционный_система'),\n",
       "  (0.0032609154, 'редактирование'),\n",
       "  (0.0032008851, 'закрылок'),\n",
       "  (0.0029810097, 'гигабайт'),\n",
       "  (0.0027460563, 'сша'),\n",
       "  (0.0026905527, 'гигабайт_оперативный'),\n",
       "  (0.0025756522, 'кубит'),\n",
       "  (0.0025112345, 'вычислительный'),\n",
       "  (0.0025065271, 'днк'),\n",
       "  (0.0024225686, 'оперативный_память'),\n",
       "  (0.0024026486, 'несколько'),\n",
       "  (0.0023924743, 'работать'),\n",
       "  (0.0023725051, 'задача'),\n",
       "  (0.0023678844, 'алгоритм'),\n",
       "  (0.0022628822, 'рнк_интерференция'),\n",
       "  (0.0022564067, 'нуклеаз_cas'),\n",
       "  (0.002246906, 'использоваться'),\n",
       "  (0.0021280115, 'вычислительный_система'),\n",
       "  (0.0020897288, 'человеческий_эмбрион'),\n",
       "  (0.0020482626, 'число')],\n",
       " -8.615381085589096)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LDA_model.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.11 s, sys: 17.8 s, total: 26.9 s\n",
      "Wall time: 6.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model_lsi = gensim.models.LsiModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LsiModel in module gensim.models.lsimodel:\n",
      "\n",
      "class LsiModel(gensim.interfaces.TransformationABC, gensim.models.basemodel.BaseTopicModel)\n",
      " |  LsiModel(corpus=None, num_topics=200, id2word=None, chunksize=20000, decay=1.0, distributed=False, onepass=True, power_iters=2, extra_samples=100, dtype=<class 'numpy.float64'>)\n",
      " |  \n",
      " |  Model for `Latent Semantic Indexing\n",
      " |  <https://en.wikipedia.org/wiki/Latent_semantic_analysis#Latent_semantic_indexing>`_.\n",
      " |  \n",
      " |  The decomposition algorithm is described in `\"Fast and Faster: A Comparison of Two Streamed\n",
      " |  Matrix Decomposition Algorithms\" <https://nlp.fi.muni.cz/~xrehurek/nips/rehurek_nips.pdf>`_.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  * :attr:`gensim.models.lsimodel.LsiModel.projection.u` - left singular vectors,\n",
      " |  * :attr:`gensim.models.lsimodel.LsiModel.projection.s` - singular values,\n",
      " |  * ``model[training_corpus]`` - right singular vectors (can be reconstructed if needed).\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  `FAQ about LSI matrices\n",
      " |  <https://github.com/piskvorky/gensim/wiki/Recipes-&-FAQ#q4-how-do-you-output-the-u-s-vt-matrices-of-lsi>`_.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from gensim.test.utils import common_corpus, common_dictionary, get_tmpfile\n",
      " |  >>> from gensim.models import LsiModel\n",
      " |  >>>\n",
      " |  >>> model = LsiModel(common_corpus[:3], id2word=common_dictionary)  # train model\n",
      " |  >>> vector = model[common_corpus[4]]  # apply model to BoW document\n",
      " |  >>> model.add_documents(common_corpus[4:])  # update model with new documents\n",
      " |  >>> tmp_fname = get_tmpfile(\"lsi.model\")\n",
      " |  >>> model.save(tmp_fname)  # save model\n",
      " |  >>> loaded_model = LsiModel.load(tmp_fname)  # load model\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LsiModel\n",
      " |      gensim.interfaces.TransformationABC\n",
      " |      gensim.utils.SaveLoad\n",
      " |      gensim.models.basemodel.BaseTopicModel\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, bow, scaled=False, chunksize=512)\n",
      " |      Get the latent representation for `bow`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      bow : {list of (int, int), iterable of list of (int, int)}\n",
      " |          Document or corpus in BoW representation.\n",
      " |      scaled : bool, optional\n",
      " |          If True - topics will be scaled by the inverse of singular values.\n",
      " |      chunksize :  int, optional\n",
      " |          Number of documents to be used in each applying chunk.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, float)\n",
      " |          Latent representation of topics in BoW format for document **OR**\n",
      " |      :class:`gensim.matutils.Dense2Corpus`\n",
      " |          Latent representation of corpus in BoW format if `bow` is corpus.\n",
      " |  \n",
      " |  __init__(self, corpus=None, num_topics=200, id2word=None, chunksize=20000, decay=1.0, distributed=False, onepass=True, power_iters=2, extra_samples=100, dtype=<class 'numpy.float64'>)\n",
      " |      Construct an `LsiModel` object.\n",
      " |      \n",
      " |      Either `corpus` or `id2word` must be supplied in order to train the model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : {iterable of list of (int, float), scipy.sparse.csc}, optional\n",
      " |          Stream of document vectors or sparse matrix of shape (`num_terms`, `num_documents`).\n",
      " |      num_topics : int, optional\n",
      " |          Number of requested factors (latent dimensions)\n",
      " |      id2word : dict of {int: str}, optional\n",
      " |          ID to word mapping, optional.\n",
      " |      chunksize :  int, optional\n",
      " |          Number of documents to be used in each training chunk.\n",
      " |      decay : float, optional\n",
      " |          Weight of existing observations relatively to new ones.\n",
      " |      distributed : bool, optional\n",
      " |          If True - distributed mode (parallel execution on several machines) will be used.\n",
      " |      onepass : bool, optional\n",
      " |          Whether the one-pass algorithm should be used for training.\n",
      " |          Pass `False` to force a multi-pass stochastic algorithm.\n",
      " |      power_iters: int, optional\n",
      " |          Number of power iteration steps to be used.\n",
      " |          Increasing the number of power iterations improves accuracy, but lowers performance\n",
      " |      extra_samples : int, optional\n",
      " |          Extra samples to be used besides the rank `k`. Can improve accuracy.\n",
      " |      dtype : type, optional\n",
      " |          Enforces a type for elements of the decomposed matrix.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Get a human readable representation of model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          A human readable string of the current objects parameters.\n",
      " |  \n",
      " |  add_documents(self, corpus, chunksize=None, decay=None)\n",
      " |      Update model with new `corpus`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : {iterable of list of (int, float), scipy.sparse.csc}\n",
      " |          Stream of document vectors or sparse matrix of shape (`num_terms`, num_documents).\n",
      " |      chunksize : int, optional\n",
      " |          Number of documents to be used in each training chunk, will use `self.chunksize` if not specified.\n",
      " |      decay : float, optional\n",
      " |          Weight of existing observations relatively to new ones,  will use `self.decay` if not specified.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Training proceeds in chunks of `chunksize` documents at a time. The size of `chunksize` is a tradeoff\n",
      " |      between increased speed (bigger `chunksize`) vs. lower memory footprint (smaller `chunksize`).\n",
      " |      If the distributed mode is on, each chunk is sent to a different worker/computer.\n",
      " |  \n",
      " |  get_topics(self)\n",
      " |      Get the topic vectors.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The number of topics can actually be smaller than `self.num_topics`, if there were not enough factors\n",
      " |      in the matrix (real rank of input matrix smaller than `self.num_topics`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      np.ndarray\n",
      " |          The term topic matrix with shape (`num_topics`, `vocabulary_size`)\n",
      " |  \n",
      " |  print_debug(self, num_topics=5, num_words=10)\n",
      " |      Print (to log) the most salient words of the first `num_topics` topics.\n",
      " |      \n",
      " |      Unlike :meth:`~gensim.models.lsimodel.LsiModel.print_topics`, this looks for words that are significant for\n",
      " |      a particular topic *and* not for others. This *should* result in a\n",
      " |      more human-interpretable description of topics.\n",
      " |      \n",
      " |      Alias for :func:`~gensim.models.lsimodel.print_debug`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          The number of topics to be selected (ordered by significance).\n",
      " |      num_words : int, optional\n",
      " |          The number of words to be included per topics (ordered by significance).\n",
      " |  \n",
      " |  save(self, fname, *args, **kwargs)\n",
      " |      Save the model to a file.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Large internal arrays may be stored into separate files, with `fname` as prefix.\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      Do not save as a compressed file if you intend to load the file back with `mmap`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to output file.\n",
      " |      *args\n",
      " |          Variable length argument list, see :meth:`gensim.utils.SaveLoad.save`.\n",
      " |      **kwargs\n",
      " |          Arbitrary keyword arguments, see :meth:`gensim.utils.SaveLoad.save`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.models.lsimodel.LsiModel.load`\n",
      " |  \n",
      " |  show_topic(self, topicno, topn=10)\n",
      " |      Get the words that define a topic along with their contribution.\n",
      " |      \n",
      " |      This is actually the left singular vector of the specified topic.\n",
      " |      \n",
      " |      The most important words in defining the topic (greatest absolute value) are included\n",
      " |      in the output, along with their contribution to the topic.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      topicno : int\n",
      " |          The topics id number.\n",
      " |      topn : int\n",
      " |          Number of words to be included to the result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (str, float)\n",
      " |          Topic representation in BoW format.\n",
      " |  \n",
      " |  show_topics(self, num_topics=-1, num_words=10, log=False, formatted=True)\n",
      " |      Get the most significant topics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          The number of topics to be selected, if -1 - all topics will be in result (ordered by significance).\n",
      " |      num_words : int, optional\n",
      " |          The number of words to be included per topics (ordered by significance).\n",
      " |      log : bool, optional\n",
      " |          If True - log topics with logger.\n",
      " |      formatted : bool, optional\n",
      " |          If True - each topic represented as string, otherwise - in BoW format.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, str)\n",
      " |          If `formatted=True`, return sequence with (topic_id, string representation of topics) **OR**\n",
      " |      list of (int, list of (str, float))\n",
      " |          Otherwise, return sequence with (topic_id, [(word, value), ... ]).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  load(fname, *args, **kwargs) from builtins.type\n",
      " |      Load a previously saved object using :meth:`~gensim.models.lsimodel.LsiModel.save` from file.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Large arrays can be memmap'ed back as read-only (shared memory) by setting the `mmap='r'` parameter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to file that contains LsiModel.\n",
      " |      *args\n",
      " |          Variable length argument list, see :meth:`gensim.utils.SaveLoad.load`.\n",
      " |      **kwargs\n",
      " |          Arbitrary keyword arguments, see :meth:`gensim.utils.SaveLoad.load`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.models.lsimodel.LsiModel.save`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`~gensim.models.lsimodel.LsiModel`\n",
      " |          Loaded instance.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IOError\n",
      " |          When methods are called on instance (should be called from class).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.models.basemodel.BaseTopicModel:\n",
      " |  \n",
      " |  print_topic(self, topicno, topn=10)\n",
      " |      Get a single topic as a formatted string.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      topicno : int\n",
      " |          Topic id.\n",
      " |      topn : int\n",
      " |          Number of words from topic that will be used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          String representation of topic, like '-0.340 * \"category\" + 0.298 * \"$M$\" + 0.183 * \"algebra\" + ... '.\n",
      " |  \n",
      " |  print_topics(self, num_topics=20, num_words=10)\n",
      " |      Get the most significant topics (alias for `show_topics()` method).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          The number of topics to be selected, if -1 - all topics will be in result (ordered by significance).\n",
      " |      num_words : int, optional\n",
      " |          The number of words to be included per topics (ordered by significance).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, list of (str, float))\n",
      " |          Sequence with (topic_id, [(word, value), ... ]).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gensim.models.LsiModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alpha',\n",
       " 'batch',\n",
       " 'bound',\n",
       " 'callbacks',\n",
       " 'chunksize',\n",
       " 'clear',\n",
       " 'decay',\n",
       " 'diff',\n",
       " 'dispatcher',\n",
       " 'distributed',\n",
       " 'do_estep',\n",
       " 'do_mstep',\n",
       " 'dtype',\n",
       " 'eta',\n",
       " 'eval_every',\n",
       " 'expElogbeta',\n",
       " 'gamma_threshold',\n",
       " 'get_document_topics',\n",
       " 'get_term_topics',\n",
       " 'get_topic_terms',\n",
       " 'get_topics',\n",
       " 'id2word',\n",
       " 'inference',\n",
       " 'init_dir_prior',\n",
       " 'iterations',\n",
       " 'load',\n",
       " 'log_perplexity',\n",
       " 'minimum_phi_value',\n",
       " 'minimum_probability',\n",
       " 'num_terms',\n",
       " 'num_topics',\n",
       " 'num_updates',\n",
       " 'numworkers',\n",
       " 'offset',\n",
       " 'optimize_alpha',\n",
       " 'optimize_eta',\n",
       " 'passes',\n",
       " 'per_word_topics',\n",
       " 'print_topic',\n",
       " 'print_topics',\n",
       " 'random_state',\n",
       " 'save',\n",
       " 'show_topic',\n",
       " 'show_topics',\n",
       " 'state',\n",
       " 'sync_state',\n",
       " 'top_topics',\n",
       " 'update',\n",
       " 'update_alpha',\n",
       " 'update_eta',\n",
       " 'update_every',\n",
       " 'workers']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(model) if not m.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method add_documents in module gensim.models.lsimodel:\n",
      "\n",
      "add_documents(corpus, chunksize=None, decay=None) method of gensim.models.lsimodel.LsiModel instance\n",
      "    Update model with new `corpus`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    corpus : {iterable of list of (int, float), scipy.sparse.csc}\n",
      "        Stream of document vectors or sparse matrix of shape (`num_terms`, num_documents).\n",
      "    chunksize : int, optional\n",
      "        Number of documents to be used in each training chunk, will use `self.chunksize` if not specified.\n",
      "    decay : float, optional\n",
      "        Weight of existing observations relatively to new ones,  will use `self.decay` if not specified.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Training proceeds in chunks of `chunksize` documents at a time. The size of `chunksize` is a tradeoff\n",
      "    between increased speed (bigger `chunksize`) vs. lower memory footprint (smaller `chunksize`).\n",
      "    If the distributed mode is on, each chunk is sent to a different worker/computer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model_lsi.add_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics1 = model_lsi.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.68650808e-02,  1.25862335e-02,  4.87870830e-03, ...,\n",
       "         4.02892851e-04,  5.31587719e-04,  4.96644920e-04],\n",
       "       [ 2.99290174e-02,  1.91296458e-02,  1.05392380e-02, ...,\n",
       "        -3.87849303e-04, -4.00906358e-04, -6.45753268e-04],\n",
       "       [ 3.54510533e-02,  5.53638621e-03,  1.78147634e-02, ...,\n",
       "         5.55159598e-05, -1.39707922e-04,  1.11080362e-04],\n",
       "       ...,\n",
       "       [ 8.42724001e-03,  5.18216592e-03,  2.42144458e-03, ...,\n",
       "         3.58649287e-04,  4.01418690e-04, -7.48857402e-04],\n",
       "       [-1.40325773e-02,  6.02196192e-03, -2.67136029e-03, ...,\n",
       "         1.64826331e-04, -2.83109574e-04, -5.91737674e-04],\n",
       "       [ 1.16645596e-02,  1.90442405e-03, -2.26524293e-04, ...,\n",
       "         5.17272293e-05,  8.80020450e-04, -6.87188997e-05]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12788,)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " '0.468*\"самолёт\" + 0.299*\"клетка\" + -0.202*\"робот\" + -0.201*\"аппарат\" + 0.144*\"ген\" + -0.141*\"звезда\" + 0.136*\"мозг\" + -0.128*\"автомобиль\" + -0.123*\"планета\" + -0.115*\"беспилотник\" + -0.112*\"объект\" + 0.111*\"истребитель\" + -0.104*\"компания\" + -0.102*\"беспилотный\" + 0.098*\"мышь\" + -0.093*\"космический\" + 0.089*\"белок\" + -0.085*\"устройство\" + 0.084*\"днк\" + 0.080*\"животное\" + 0.078*\"нейрон\" + -0.076*\"орбита\" + -0.073*\"земля\" + -0.072*\"галактика\" + 0.067*\"группа\" + 0.066*\"двигатель\" + 0.066*\"активность\" + 0.066*\"геном\" + -0.065*\"спутник\" + -0.064*\"находиться\" + 0.064*\"полёт\" + -0.063*\"частица\" + -0.063*\"камера\" + -0.062*\"поверхность\" + 0.060*\"показать\" + 0.059*\"ткань\" + -0.058*\"излучение\" + 0.058*\"ввс\" + 0.058*\"сша\" + 0.055*\"развитие\"')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lsi.print_topics(-1, num_words=40)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3.039716392680883),\n",
       " (1, 0.8971408183669063),\n",
       " (2, -2.540951192683333),\n",
       " (3, 1.982005902748673),\n",
       " (4, -3.2233513933334463),\n",
       " (5, -0.05916108215865734),\n",
       " (6, -0.06217426374018147),\n",
       " (7, 0.5317891191619057),\n",
       " (8, -0.1822024307659729),\n",
       " (9, -1.1745455790207964),\n",
       " (10, 0.2683063820845864),\n",
       " (11, 1.0269118822029601),\n",
       " (12, -3.6710875663512486),\n",
       " (13, -0.36134734387814765),\n",
       " (14, 0.5843093809194457),\n",
       " (15, -0.977818972383357),\n",
       " (16, -0.6139220765660169),\n",
       " (17, 0.847282502429811),\n",
       " (18, 0.9228114264323515),\n",
       " (19, -0.5546411774634891)]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model_lsi[corpus[300]]\n",
    "\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.3209292713171243"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([t[1] for t in vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vect(corp_elem):\n",
    "    vector = model_lsi[corp_elem]\n",
    "    v = np.array([t[1] for t in vector])\n",
    "    return v / np.linalg.norm(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_vects = []\n",
    "for i in range(len(corpus)):\n",
    "    lsi_vects.append(get_vect(corpus[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7696"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lsi_vects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi_vects[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_vects_ = np.vstack(lsi_vects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7696, 20)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi_vects_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Первый аппарат миссии «Экзомарс» успешно стартовал с российского космодрома Байконур. Ракета-носитель «Протон-М» отработала штатно, произошло отделение первой и второй ступени, а также головного обтекателя. Первый сигнал ожидается 15 марта в 00:29 по московскому времени. Запуск транслировался в прямом эфире.На первом этапе полета — первые шесть недель — зонд будет вводиться в эксплуатацию, будут проводиться тесты оборудования. Затем в июле модуль Trace Gas Orbiter скорректирует свою траекторию. Аппарат достигнет красной планеты примерно 19 октября.По достижении орбиты планеты аппарат освободит крепления спускаемого модуля «Скиапарелли» и выйдет на орбиту высотой несколько сотен километров. Главная задача Trace Gas Orbiter — спектроскопический анализ атмосферы и поиск в ней следов метана. Задача же «Скиапарелли» — отработка технологии посадки. На поверхности планеты он проработает всего несколько дней, впервые сделав замеры электрических полей, чтобы определить их роль в пылевых бурях.Выбор даты обусловлен минимальным расстоянием между Землей и Марсом. Второй аппарат миссии отправится с Земли в 2018 году, во время великого противостояния, когда расстояние между планетами составит около 58 миллионов километров.Владимир Королёв\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(texts[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42644905,  0.12586202, -0.35647609,  0.27806033, -0.45221164,\n",
       "       -0.00829985, -0.00872258,  0.07460596, -0.02556161, -0.1647798 ,\n",
       "        0.03764134,  0.14406791, -0.51502562, -0.05069428,  0.08197415,\n",
       "       -0.13718055, -0.08612859,  0.11886728,  0.12946341, -0.07781193])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = get_vect(corpus[300])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.matmul(lsi_vects_, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7696,)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1794, 3110, 5429,  494, 6464, 6790, 5351, 3973, 2535, 3547])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(scores)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16953509, -0.14471357, -0.11274838, -0.09745621, -0.09502944,\n",
       "       -0.08766304, -0.07719943, -0.07542923, -0.075404  , -0.07522027])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[np.argsort(scores)[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ученые из Тайваня и Франции предложили эксперимент по созданию аналоговой черной дыры при помощи мощных лазеров и плазмы. С его помощью можно изучить излучение Хокинга и связанный с ним информационный парадокс. Исследование опубликовано в журнале Physical Review Letters, кратко о статье рассказывается на сайте журнала Physics.Излучение\n",
      "Хокинга — процесс, который приводит к испарению черной дыры. В классической\n",
      "физике это невозможно — черные дыры только поглощают материю, ничего не\n",
      "излучая. Однако в квантовой механике, из-за принципа неопределенности\n",
      "Гейзенберга, вблизи горизонта событий черной дыры постоянно рождаются и\n",
      "аннигилируют пары частица-античастица. Это происходит из-за флуктуаций физического вакуума. При этом одна из частиц проникает через\n",
      "горизонт событий и попадает внутрь черной дыры, а другая улетает, и ее можно пронаблюдать. В этом случае пара частиц становится квантово-запутанной. Однако зарегистрировать\n",
      "излучение Хокинга от реальных астрофизических объектов практически невозможно —\n",
      "оно очень слабое, причем чем массивнее черная дыра, тем оно слабее. Даже для\n",
      "черной дыры с массой в одну солнечную оно составит десятимиллионную долю\n",
      "Кельвина.С процессом испарения связан парадокс\n",
      "исчезновения информации в черной дыре, который плохо согласуется с принципами\n",
      "квантовой механики. Подробнее о нем можно почитать в нашей серии интервью с\n",
      "физиком Эмилем Ахмедовым (раз и два). Один из\n",
      "способов изучения информационного парадокса заключается в том, чтобы искать\n",
      "корреляции между вылетевшим прочь фотоном и его партнером, поглощаемым черной\n",
      "дырой. Чтобы реализовать этот способ, необходимо создать аналоговую модель черной\n",
      "дыры в лабораторных условиях, при этом излучение Хокинга можно сымитировать при\n",
      "помощи релятивистского плазменного зеркала, которое может играть роль горизонта событий черной дыры.В\n",
      "эксперименте плазменное «зеркало» с поперечным распределением плотности создается при взаимодействии оптического петаваттного лазерного импульса с однородной газовой мишенью.\n",
      "Другой импульс, созданным таким же лазером, отражается от создаваемого\n",
      "плазменного «зеркала», при этом увеличивается частота фотонов и на выходе получается\n",
      "мощный рентгеновский импульс, который попадает на твердотельную мишень с неравномерной плотностью. При взаимодействии импульса с материалом мишени образуется след из электронов, который действует в качестве движущейся отражающей границы для фотонов, выходящих из квантовых флуктуаций. Отраженные от такого «зеркала» фотоны будут аналогом излучения Хокинга, которое распространяется\n",
      "в обратном направлении. Когда «зеркало» резко останавливается, может возникнуть\n",
      "всплеск энергии или нулевые колебания, при этом излучатся неотраженные от «зеркала» фотоны — те самые партнеры\n",
      "частиц излучения Хокинга, которые «исчезают» в черной дыре. Эти частицы и колебания можно зарегистрировать при помощи фотосенсоров, конденсаторов и\n",
      "усилителей, при этом требуется хорошее временное разрешение приборов, чтобы отличить одни частицы от других.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(texts[3110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
